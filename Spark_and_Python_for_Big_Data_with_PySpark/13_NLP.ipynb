{"cells":[{"cell_type":"markdown","source":["###Initializing a SparkSession"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('NLP').getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["###Loading the dataset"],"metadata":{}},{"cell_type":"code","source":["df = spark.read.csv('/FileStore/tables/SMSSpamCollection', inferSchema=True, sep='\\t')\ndf = df.withColumnRenamed('_c0', 'class').withColumnRenamed('_c1', 'text')\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+\nclass|                text|\n+-----+--------------------+\n  ham|Go until jurong p...|\n  ham|Ok lar... Joking ...|\n spam|Free entry in 2 a...|\n  ham|U dun say so earl...|\n  ham|Nah I don&#39;t think...|\n spam|FreeMsg Hey there...|\n  ham|Even my brother i...|\n  ham|As per your reque...|\n spam|WINNER!! As a val...|\n spam|Had your mobile 1...|\n  ham|I&#39;m gonna be home...|\n spam|SIX chances to wi...|\n spam|URGENT! You have ...|\n  ham|I&#39;ve been searchi...|\n  ham|I HAVE A DATE ON ...|\n spam|XXXMobileMovieClu...|\n  ham|Oh k...i&#39;m watchi...|\n  ham|Eh u remember how...|\n  ham|Fine if thats th...|\n spam|England v Macedon...|\n+-----+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["###Feature engineering"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import length\ndf = df.withColumn('length', length(df['text']))\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+------+\nclass|                text|length|\n+-----+--------------------+------+\n  ham|Go until jurong p...|   111|\n  ham|Ok lar... Joking ...|    29|\n spam|Free entry in 2 a...|   155|\n  ham|U dun say so earl...|    49|\n  ham|Nah I don&#39;t think...|    61|\n spam|FreeMsg Hey there...|   147|\n  ham|Even my brother i...|    77|\n  ham|As per your reque...|   160|\n spam|WINNER!! As a val...|   157|\n spam|Had your mobile 1...|   154|\n  ham|I&#39;m gonna be home...|   109|\n spam|SIX chances to wi...|   136|\n spam|URGENT! You have ...|   155|\n  ham|I&#39;ve been searchi...|   196|\n  ham|I HAVE A DATE ON ...|    35|\n spam|XXXMobileMovieClu...|   149|\n  ham|Oh k...i&#39;m watchi...|    26|\n  ham|Eh u remember how...|    81|\n  ham|Fine if thats th...|    56|\n spam|England v Macedon...|   155|\n+-----+--------------------+------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["df.groupBy('class').mean().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----------------+\nclass|      avg(length)|\n+-----+-----------------+\n  ham| 71.4545266210897|\n spam|138.6706827309237|\n+-----+-----------------+\n\n</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["doc 1 'i, like, apples, i'\n\ntf-idf\n\ni = 2 -> 2 * log(2/2) -> 0\n\nlike = 1 -> 1 * log(2/1) -> 0.3 ('like' is a relatively relevent string in this doc)\n\napples = 1 -> 1 * log(2/2) -> 0\n\nhate = 0 -> 0 * log(2/1) -> 0\n\ndoc 2 'i, hate, apples'\n\ni = 1 -> 1 * log(2/2) -> 0\n\nlike = 0 -> 0 * log(2/1) -> 0\n\napples = 1 -> 1 * log(2/2) -> 0\n\nhate = 1 -> 1 * log(2/1) -> 0.3 ('hate' is a relatively relevent string in this doc)\n\nidf\n\ni = 2\n\nlike = 1\n\napples = 2\n\nhate = 1\n\nN = 2"],"metadata":{}},{"cell_type":"markdown","source":["###Formatting the text columng"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, Tokenizer, StopWordsRemover, CountVectorizer, IDF, VectorAssembler\nham_spam_to_numeric = StringIndexer(inputCol='class', outputCol='label')\n# df_1 = ham_spam_to_numeric.fit(df).transform(df)\n# df_1.show()\ntokenizer = Tokenizer(inputCol='text', outputCol='token_text')\n# df_2 = tokenizer.transform(df_1)\n# df_2.show()\nstop_remove = StopWordsRemover(inputCol='token_text', outputCol='token_stop')\n# df_3 = stop_remove.transform(df_2)\n# df_3.show()\ncount_vec = CountVectorizer(inputCol='token_stop', outputCol='count_vec')\n# df_4 = count_vec.fit(df_3).transform(df_3)\n# df_4.show()\nidf = IDF(inputCol='count_vec', outputCol='tf-idf')\n# df_5 = idf.fit(df_4).transform(df_4)\n# df_5.show()\ntransformed_df = VectorAssembler(inputCols=['length', 'tf-idf'], outputCol='features')\n# df_6 = transformed_df.transform(df_5)\n# df_6.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\nclass|                text|length|label|          token_text|          token_stop|           count_vec|              tf-idf|            features|\n+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n  ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|(13423,[7,11,31,6...|(13423,[7,11,31,6...|(13424,[0,8,12,32...|\n  ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13423,[0,24,297,...|(13423,[0,24,297,...|(13424,[0,1,25,29...|\n spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|(13423,[2,13,19,3...|(13423,[2,13,19,3...|(13424,[0,3,14,20...|\n  ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13423,[0,70,80,1...|(13423,[0,70,80,1...|(13424,[0,1,71,81...|\n  ham|Nah I don&#39;t think...|    61|  0.0|[nah, i, don&#39;t, t...|[nah, think, goes...|(13423,[36,134,31...|(13423,[36,134,31...|(13424,[0,37,135,...|\n spam|FreeMsg Hey there...|   147|  1.0|[freemsg, hey, th...|[freemsg, hey, da...|(13423,[10,60,139...|(13423,[10,60,139...|(13424,[0,11,61,1...|\n  ham|Even my brother i...|    77|  0.0|[even, my, brothe...|[even, brother, l...|(13423,[10,53,103...|(13423,[10,53,103...|(13424,[0,11,54,1...|\n  ham|As per your reque...|   160|  0.0|[as, per, your, r...|[per, request, &#39;m...|(13423,[125,184,4...|(13423,[125,184,4...|(13424,[0,126,185...|\n spam|WINNER!! As a val...|   157|  1.0|[winner!!, as, a,...|[winner!!, valued...|(13423,[1,47,118,...|(13423,[1,47,118,...|(13424,[0,2,48,11...|\n spam|Had your mobile 1...|   154|  1.0|[had, your, mobil...|[mobile, 11, mont...|(13423,[0,1,13,27...|(13423,[0,1,13,27...|(13424,[0,1,2,14,...|\n  ham|I&#39;m gonna be home...|   109|  0.0|[i&#39;m, gonna, be, ...|[gonna, home, soo...|(13423,[18,43,120...|(13423,[18,43,120...|(13424,[0,19,44,1...|\n spam|SIX chances to wi...|   136|  1.0|[six, chances, to...|[six, chances, wi...|(13423,[8,17,37,8...|(13423,[8,17,37,8...|(13424,[0,9,18,38...|\n spam|URGENT! You have ...|   155|  1.0|[urgent!, you, ha...|[urgent!, won, 1,...|(13423,[13,30,47,...|(13423,[13,30,47,...|(13424,[0,14,31,4...|\n  ham|I&#39;ve been searchi...|   196|  0.0|[i&#39;ve, been, sear...|[searching, right...|(13423,[39,96,217...|(13423,[39,96,217...|(13424,[0,40,97,2...|\n  ham|I HAVE A DATE ON ...|    35|  0.0|[i, have, a, date...|[date, sunday, wi...|(13423,[552,1697,...|(13423,[552,1697,...|(13424,[0,553,169...|\n spam|XXXMobileMovieClu...|   149|  1.0|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(13423,[30,109,11...|(13423,[30,109,11...|(13424,[0,31,110,...|\n  ham|Oh k...i&#39;m watchi...|    26|  0.0|[oh, k...i&#39;m, wat...|[oh, k...i&#39;m, wat...|(13423,[82,214,47...|(13423,[82,214,47...|(13424,[0,83,215,...|\n  ham|Eh u remember how...|    81|  0.0|[eh, u, remember,...|[eh, u, remember,...|(13423,[0,2,49,13...|(13423,[0,2,49,13...|(13424,[0,1,3,50,...|\n  ham|Fine if thats th...|    56|  0.0|[fine, if, thats...|[fine, thats, wa...|(13423,[0,74,105,...|(13423,[0,74,105,...|(13424,[0,1,75,10...|\n spam|England v Macedon...|   155|  1.0|[england, v, mace...|[england, v, mace...|(13423,[4,30,33,5...|(13423,[4,30,33,5...|(13424,[0,5,31,34...|\n+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["from pyspark.ml import Pipeline\ndf_pipe = Pipeline(stages=[ham_spam_to_numeric,\n                           tokenizer,\n                           stop_remove,\n                           count_vec,\n                           idf,\n                           transformed_df])\nfinal_df = df_pipe.fit(df).transform(df).select('label', 'features')\nfinal_df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+\nlabel|            features|\n+-----+--------------------+\n  0.0|(13424,[0,8,12,32...|\n  0.0|(13424,[0,1,25,29...|\n  1.0|(13424,[0,3,14,20...|\n  0.0|(13424,[0,1,71,81...|\n  0.0|(13424,[0,37,135,...|\n  1.0|(13424,[0,11,61,1...|\n  0.0|(13424,[0,11,54,1...|\n  0.0|(13424,[0,126,185...|\n  1.0|(13424,[0,2,48,11...|\n  1.0|(13424,[0,1,2,14,...|\n  0.0|(13424,[0,19,44,1...|\n  1.0|(13424,[0,9,18,38...|\n  1.0|(13424,[0,14,31,4...|\n  0.0|(13424,[0,40,97,2...|\n  0.0|(13424,[0,553,169...|\n  1.0|(13424,[0,31,110,...|\n  0.0|(13424,[0,83,215,...|\n  0.0|(13424,[0,1,3,50,...|\n  0.0|(13424,[0,1,75,10...|\n  1.0|(13424,[0,5,31,34...|\n+-----+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["###Splitting the dataset"],"metadata":{}},{"cell_type":"code","source":["train_data, test_data = final_df.randomSplit([0.7, 0.3])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["###Building the ML model"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes\nclassifier = NaiveBayes(featuresCol='features', labelCol='label', predictionCol='prediction')\nfittied_classifer = classifier.fit(train_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["###Predicting the test data"],"metadata":{}},{"cell_type":"code","source":["preds = fittied_classifer.transform(test_data)\npreds.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+--------------------+--------------------+----------+\nlabel|            features|       rawPrediction|         probability|prediction|\n+-----+--------------------+--------------------+--------------------+----------+\n  0.0|(13424,[0,1,2,3,8...|[-811.58126358978...|[1.0,1.1870929167...|       0.0|\n  0.0|(13424,[0,1,2,6,1...|[-1004.2536555575...|[1.0,9.9687763567...|       0.0|\n  0.0|(13424,[0,1,2,8,9...|[-886.65484041376...|[1.0,1.4573713517...|       0.0|\n  0.0|(13424,[0,1,2,8,9...|[-1169.9441674290...|[1.0,4.6484715559...|       0.0|\n  0.0|(13424,[0,1,2,8,1...|[-665.15817956926...|[1.0,6.6046593626...|       0.0|\n  0.0|(13424,[0,1,2,10,...|[-535.95986127579...|[1.0,2.9507903324...|       0.0|\n  0.0|(13424,[0,1,2,12,...|[-904.70222111608...|[1.0,3.1153084793...|       0.0|\n  0.0|(13424,[0,1,2,15,...|[-1380.1961334642...|[1.0,1.8029251227...|       0.0|\n  0.0|(13424,[0,1,2,15,...|[-217.25100994637...|[1.0,1.1390791090...|       0.0|\n  0.0|(13424,[0,1,2,21,...|[-984.99230055877...|[0.99999978426289...|       0.0|\n  0.0|(13424,[0,1,2,24,...|[-1289.4363746907...|[1.0,2.0169285296...|       0.0|\n  0.0|(13424,[0,1,2,25,...|[-340.59059890977...|[1.0,2.5697820648...|       0.0|\n  0.0|(13424,[0,1,2,32,...|[-345.21796861660...|[1.0,3.6902631427...|       0.0|\n  0.0|(13424,[0,1,2,47,...|[-1136.3575282709...|[1.20026835332069...|       1.0|\n  0.0|(13424,[0,1,2,147...|[-254.99821981792...|[0.07085331104352...|       1.0|\n  0.0|(13424,[0,1,3,4,6...|[-520.27662591988...|[0.99999999988839...|       0.0|\n  0.0|(13424,[0,1,3,4,7...|[-3297.9989953384...|[1.0,3.7847268522...|       0.0|\n  0.0|(13424,[0,1,3,5,6...|[-2494.1778078113...|[1.0,1.2129570174...|       0.0|\n  0.0|(13424,[0,1,3,5,9...|[-1306.3515943144...|[1.0,3.8393130263...|       0.0|\n  0.0|(13424,[0,1,3,5,4...|[-1929.9203135062...|[1.0,8.0264858232...|       0.0|\n+-----+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["###Evaluating the model"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\nevaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')\narea_under_curve = evaluator.evaluate(preds)\naccuracy = MulticlassClassificationEvaluator(metricName='accuracy', labelCol='label')\naccuracy = accuracy.evaluate(preds)\nprint(area_under_curve)\nprint(accuracy)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.9330873434804146\n0.9059316956261234\n</div>"]}}],"execution_count":19}],"metadata":{"name":"13_NLP","notebookId":258453867455955},"nbformat":4,"nbformat_minor":0}
