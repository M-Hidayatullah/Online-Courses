{"cells":[{"cell_type":"markdown","source":["#Part One"],"metadata":{}},{"cell_type":"markdown","source":["###Initializing SparkSession"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["spark = SparkSession.builder.appName('nlp').getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["### Creating our dataframe"],"metadata":{}},{"cell_type":"code","source":["sen_df = spark.createDataFrame([\n  (0, 'Hi I heard about Spark'),\n  (1, 'I wish java could use case classes'),\n  (2, 'Logistic,regression,models,are,neat')\n], ['id', 'sentence'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["sen_df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------------+\n id|            sentence|\n+---+--------------------+\n  0|Hi I heard about ...|\n  1|I wish java could...|\n  2|Logistic,regressi...|\n+---+--------------------+\n\n</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["### Creating Tokenizer object"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer, RegexTokenizer\ntokenizer = Tokenizer(inputCol='sentence', outputCol='words')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["regex_tokenizer = RegexTokenizer(inputCol='sentence', outputCol='words', pattern='\\\\W')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["### Creating a User Defined Function"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import col, udf\nfrom pyspark.sql.types import IntegerType\ncount_tokens = udf(lambda words:len(words), IntegerType())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["###Creating the tokenized dataframe"],"metadata":{}},{"cell_type":"code","source":["tokenized = tokenizer.transform(sen_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["tokenized.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------------+--------------------+\n id|            sentence|               words|\n+---+--------------------+--------------------+\n  0|Hi I heard about ...|[hi, i, heard, ab...|\n  1|I wish java could...|[i, wish, java, c...|\n  2|Logistic,regressi...|[logistic,regress...|\n+---+--------------------+--------------------+\n\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["tokenized.withColumn('tokens', count_tokens(col('words'))).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------------+--------------------+------+\n id|            sentence|               words|tokens|\n+---+--------------------+--------------------+------+\n  0|Hi I heard about ...|[hi, i, heard, ab...|     5|\n  1|I wish java could...|[i, wish, java, c...|     7|\n  2|Logistic,regressi...|[logistic,regress...|     1|\n+---+--------------------+--------------------+------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["### Splitting not only on white space, but in comma too"],"metadata":{}},{"cell_type":"code","source":["rg_tokenized = regex_tokenizer.transform(sen_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["rg_tokenized.withColumn('tokens', count_tokens(col('words'))).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------------+--------------------+------+\n id|            sentence|               words|tokens|\n+---+--------------------+--------------------+------+\n  0|Hi I heard about ...|[hi, i, heard, ab...|     5|\n  1|I wish java could...|[i, wish, java, c...|     7|\n  2|Logistic,regressi...|[logistic, regres...|     5|\n+---+--------------------+--------------------+------+\n\n</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["###Stop words removal"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StopWordsRemover"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"code","source":["sentence_df = spark.createDataFrame([\n  (0, ['I', 'saw', 'the', 'green', 'horse']),\n  (1, ['Mary', 'had', 'a', 'little', 'lamb'])\n], ['id', 'tokens'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["sentence_df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------------+\n id|              tokens|\n+---+--------------------+\n  0|[I, saw, the, gre...|\n  1|[Mary, had, a, li...|\n+---+--------------------+\n\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["remover = StopWordsRemover(inputCol='tokens', outputCol='filtered')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["remover.transform(sentence_df).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------------+--------------------+\n id|              tokens|            filtered|\n+---+--------------------+--------------------+\n  0|[I, saw, the, gre...| [saw, green, horse]|\n  1|[Mary, had, a, li...|[Mary, little, lamb]|\n+---+--------------------+--------------------+\n\n</div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["###n-gram (sequence of n consecutive words)"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import NGram\nword_df = spark.createDataFrame([\n  (0, ['Hi', 'I', 'heard', 'about', 'Spark']),\n  (1, ['I', 'wish', 'Java', 'could', 'use', 'case', 'classes']),\n  (2, ['Logistic', 'regression', 'models', 'are', 'neat'])\n], ['id', 'words'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["ngram = NGram(n=2, inputCol='words', outputCol='grams')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"code","source":["ngram.transform(word_df).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------------+--------------------+\n id|               words|               grams|\n+---+--------------------+--------------------+\n  0|[Hi, I, heard, ab...|[Hi I, I heard, h...|\n  1|[I, wish, Java, c...|[I wish, wish Jav...|\n  2|[Logistic, regres...|[Logistic regress...|\n+---+--------------------+--------------------+\n\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["ngram.transform(word_df).select('grams').show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------------------------------+\ngrams                                                             |\n+------------------------------------------------------------------+\n[Hi I, I heard, heard about, about Spark]                         |\n[I wish, wish Java, Java could, could use, use case, case classes]|\n[Logistic regression, regression models, models are, are neat]    |\n+------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":30},{"cell_type":"markdown","source":["#Part Two"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF, Tokenizer"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"markdown","source":["###Creating a dataset"],"metadata":{}},{"cell_type":"code","source":["sen_df = spark.createDataFrame([\n  (0.0, 'Hi I heard about Spark'),\n  (0.0, 'I wish java could use case classes'),\n  (1.0, 'Logistic regression models are neat') \n], ['label', 'sentence'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["sen_df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+\nlabel|            sentence|\n+-----+--------------------+\n  0.0|Hi I heard about ...|\n  0.0|I wish java could...|\n  1.0|Logistic regressi...|\n+-----+--------------------+\n\n</div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["###Tokenizing"],"metadata":{}},{"cell_type":"code","source":["tokenizer = Tokenizer(inputCol='sentence', outputCol='words')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":37},{"cell_type":"code","source":["words_data = tokenizer.transform(sen_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":38},{"cell_type":"code","source":["words_data.show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----------------------------------+------------------------------------------+\nlabel|sentence                           |words                                     |\n+-----+-----------------------------------+------------------------------------------+\n0.0  |Hi I heard about Spark             |[hi, i, heard, about, spark]              |\n0.0  |I wish java could use case classes |[i, wish, java, could, use, case, classes]|\n1.0  |Logistic regression models are neat|[logistic, regression, models, are, neat] |\n+-----+-----------------------------------+------------------------------------------+\n\n</div>"]}}],"execution_count":39},{"cell_type":"markdown","source":["###Getting the tf"],"metadata":{}},{"cell_type":"code","source":["hashing_tf = HashingTF(inputCol='words', outputCol='rawFeatures')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":41},{"cell_type":"code","source":["featurized_data = hashing_tf.transform(words_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":42},{"cell_type":"markdown","source":["###Getting the idf"],"metadata":{}},{"cell_type":"code","source":["idf = IDF(inputCol='rawFeatures', outputCol='features')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":44},{"cell_type":"code","source":["idf_model = idf.fit(featurized_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":45},{"cell_type":"markdown","source":["###Getting tf-idf"],"metadata":{}},{"cell_type":"code","source":["rescaled_data = idf_model.transform(featurized_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":47},{"cell_type":"code","source":["rescaled_data.select('label', 'features').show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nlabel|features                                                                                                                                                                                        |\n+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n0.0  |(262144,[24417,49304,73197,91137,234657],[0.28768207245178085,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])                                                     |\n0.0  |(262144,[20719,24417,55551,116873,147765,162369,192310],[0.6931471805599453,0.28768207245178085,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])|\n1.0  |(262144,[13671,91006,132713,167122,190884],[0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])                                                    |\n+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":48},{"cell_type":"markdown","source":["###Creating a new sample df"],"metadata":{}},{"cell_type":"code","source":["df = spark.createDataFrame([\n  (0, 'a b c'.split(' ')),\n  (1, 'a b b c a'.split(' '))\n], ['id', 'words'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":50},{"cell_type":"markdown","source":["###Using CountVectorizer which counts the number of words using a vector"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import CountVectorizer\ncv = CountVectorizer(inputCol='words', outputCol='features', vocabSize=3, minDF=2.0)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":52},{"cell_type":"code","source":["model = cv.fit(df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":53},{"cell_type":"code","source":["result = model.transform(df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":54},{"cell_type":"code","source":["result.show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---------------+-------------------------+\nid |words          |features                 |\n+---+---------------+-------------------------+\n0  |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|\n1  |[a, b, b, c, a]|(3,[0,1,2],[2.0,2.0,1.0])|\n+---+---------------+-------------------------+\n\n</div>"]}}],"execution_count":55},{"cell_type":"markdown","source":["#Part 3"],"metadata":{}},{"cell_type":"markdown","source":["##Bulding a spam detection filter"],"metadata":{}},{"cell_type":"markdown","source":["###Initializing SparkSession"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('nlp').getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":59},{"cell_type":"markdown","source":["###Importing the dataset"],"metadata":{}},{"cell_type":"code","source":["df = spark.read.csv('/FileStore/tables/SMSSpamCollection', inferSchema=True, sep='\\t')\ndf = df.withColumnRenamed('_c0', 'class').withColumnRenamed('_c1', 'text')\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+\nclass|                text|\n+-----+--------------------+\n  ham|Go until jurong p...|\n  ham|Ok lar... Joking ...|\n spam|Free entry in 2 a...|\n  ham|U dun say so earl...|\n  ham|Nah I don&#39;t think...|\n spam|FreeMsg Hey there...|\n  ham|Even my brother i...|\n  ham|As per your reque...|\n spam|WINNER!! As a val...|\n spam|Had your mobile 1...|\n  ham|I&#39;m gonna be home...|\n spam|SIX chances to wi...|\n spam|URGENT! You have ...|\n  ham|I&#39;ve been searchi...|\n  ham|I HAVE A DATE ON ...|\n spam|XXXMobileMovieClu...|\n  ham|Oh k...i&#39;m watchi...|\n  ham|Eh u remember how...|\n  ham|Fine if thats th...|\n spam|England v Macedon...|\n+-----+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":61},{"cell_type":"markdown","source":["##Formatting the data"],"metadata":{}},{"cell_type":"markdown","source":["###Creating length column (feature engineering)"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\nfrom pyspark.sql.functions import length\ndf = df.withColumn('length', length(df['text']))\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+------+\nclass|                text|length|\n+-----+--------------------+------+\n  ham|Go until jurong p...|   111|\n  ham|Ok lar... Joking ...|    29|\n spam|Free entry in 2 a...|   155|\n  ham|U dun say so earl...|    49|\n  ham|Nah I don&#39;t think...|    61|\n spam|FreeMsg Hey there...|   147|\n  ham|Even my brother i...|    77|\n  ham|As per your reque...|   160|\n spam|WINNER!! As a val...|   157|\n spam|Had your mobile 1...|   154|\n  ham|I&#39;m gonna be home...|   109|\n spam|SIX chances to wi...|   136|\n spam|URGENT! You have ...|   155|\n  ham|I&#39;ve been searchi...|   196|\n  ham|I HAVE A DATE ON ...|    35|\n spam|XXXMobileMovieClu...|   149|\n  ham|Oh k...i&#39;m watchi...|    26|\n  ham|Eh u remember how...|    81|\n  ham|Fine if thats th...|    56|\n spam|England v Macedon...|   155|\n+-----+--------------------+------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":64},{"cell_type":"markdown","source":["###Visualizing length col"],"metadata":{}},{"cell_type":"code","source":["df.groupBy('class').mean().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----------------+\nclass|      avg(length)|\n+-----+-----------------+\n  ham| 71.4545266210897|\n spam|138.6706827309237|\n+-----+-----------------+\n\n</div>"]}}],"execution_count":66},{"cell_type":"markdown","source":["###Label encoding"],"metadata":{}},{"cell_type":"code","source":["ham_spam_to_numeric = StringIndexer(inputCol='class', outputCol='label')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":68},{"cell_type":"markdown","source":["###Using tokenizer (splitting the document list)"],"metadata":{}},{"cell_type":"code","source":["tokenizer = Tokenizer(inputCol='text', outputCol='token_text')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":70},{"cell_type":"markdown","source":["###Removing irrelevant words"],"metadata":{}},{"cell_type":"code","source":["stop_remove = StopWordsRemover(inputCol='token_text', outputCol='stop_token')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":72},{"cell_type":"markdown","source":["###Counting the words"],"metadata":{}},{"cell_type":"code","source":["count_vec = CountVectorizer(inputCol='stop_token', outputCol='c_vec')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":74},{"cell_type":"markdown","source":["###Getting TF-IDF"],"metadata":{}},{"cell_type":"code","source":["idf = IDF(inputCol='c_vec', outputCol='tf_idf')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":76},{"cell_type":"markdown","source":["###Getting transformed df"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\ntransformed_df = VectorAssembler(inputCols=['tf_idf', 'length'], outputCol='features')\ntransformed_df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":78},{"cell_type":"markdown","source":["###Building a pipeline"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\ndata_prep_pipe = Pipeline(stages=[ham_spam_to_numeric,\n                                  tokenizer,\n                                  stop_remove,\n                                  count_vec,\n                                  idf,\n                                  transformed_df])\ncleaner = data_prep_pipe.fit(df)\nclean_data = cleaner.transform(df)\nclean_data = clean_data.select('label', 'features')\nclean_data.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":80},{"cell_type":"markdown","source":["##Machine Learning"],"metadata":{}},{"cell_type":"markdown","source":["###Splitting the dataset"],"metadata":{}},{"cell_type":"code","source":["training, test = clean_data.randomSplit([0.7, 0.3])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":83},{"cell_type":"markdown","source":["###Building the model"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes\nnb = NaiveBayes()\nspam_detector = nb.fit(training)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":85},{"cell_type":"code","source":["df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- class: string (nullable = true)\n-- text: string (nullable = true)\n-- length: integer (nullable = true)\n\n</div>"]}}],"execution_count":86},{"cell_type":"markdown","source":["###Making predictions"],"metadata":{}},{"cell_type":"code","source":["test_results = spam_detector.transform(test)\ntest_results.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+--------------------+--------------------+----------+\nlabel|            features|       rawPrediction|         probability|prediction|\n+-----+--------------------+--------------------+--------------------+----------+\n  0.0|(13424,[0,1,2,7,8...|[-794.09202858104...|[1.0,1.5819402899...|       0.0|\n  0.0|(13424,[0,1,2,41,...|[-1075.0666545329...|[1.0,1.9181323606...|       0.0|\n  0.0|(13424,[0,1,9,14,...|[-538.65500227806...|[1.0,8.5862349265...|       0.0|\n  0.0|(13424,[0,1,12,33...|[-449.52044523481...|[1.0,1.9906362722...|       0.0|\n  0.0|(13424,[0,1,14,31...|[-220.50651348812...|[1.0,6.5811314241...|       0.0|\n  0.0|(13424,[0,1,20,27...|[-982.73645814367...|[0.99999999880252...|       0.0|\n  0.0|(13424,[0,1,24,31...|[-339.73632804117...|[1.0,1.0158872059...|       0.0|\n  0.0|(13424,[0,1,43,69...|[-632.87798222039...|[2.42948026759760...|       1.0|\n  0.0|(13424,[0,1,46,17...|[-1138.0070755193...|[6.21793336272282...|       1.0|\n  0.0|(13424,[0,1,498,5...|[-322.96917413465...|[0.99999999992170...|       0.0|\n  0.0|(13424,[0,1,874,1...|[-95.959483454264...|[0.99999997167794...|       0.0|\n  0.0|(13424,[0,2,3,6,9...|[-3286.4438151157...|[1.0,3.4487478004...|       0.0|\n  0.0|(13424,[0,2,4,5,7...|[-988.92568290548...|[1.0,3.5735192532...|       0.0|\n  0.0|(13424,[0,2,4,7,2...|[-520.76457341955...|[1.0,2.2155758574...|       0.0|\n  0.0|(13424,[0,2,4,8,1...|[-1331.9613370160...|[1.0,2.5909866949...|       0.0|\n  0.0|(13424,[0,2,4,8,2...|[-1414.7353211374...|[1.0,1.7257045148...|       0.0|\n  0.0|(13424,[0,2,4,25,...|[-436.69577132664...|[1.0,2.9841132609...|       0.0|\n  0.0|(13424,[0,2,4,40,...|[-1586.6475764086...|[0.99938916402169...|       0.0|\n  0.0|(13424,[0,2,4,44,...|[-1922.5955545566...|[1.0,7.4076288548...|       0.0|\n  0.0|(13424,[0,2,5,8,4...|[-829.84047374545...|[1.0,2.2178490075...|       0.0|\n+-----+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":88},{"cell_type":"markdown","source":["###Evaluting the model"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nacc_eval = MulticlassClassificationEvaluator()\nacc = acc_eval.evaluate(test_results)\nprint('ACC of NB Model')\nprint(acc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ACC of NB Model\n0.9288385595770825\n</div>"]}}],"execution_count":90},{"cell_type":"markdown","source":["###Using evaluation based on my documentation"],"metadata":{}},{"cell_type":"code","source":["preds = spam_detector.transform(test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":92},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\nevaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')\narea_under_curve = evaluator.evaluate(preds)\naccuracy = MulticlassClassificationEvaluator(metricName='accuracy', labelCol='label')\naccuracy = accuracy.evaluate(preds)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":93},{"cell_type":"code","source":["print(area_under_curve)\nprint(accuracy)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.9352706299911269\n0.9229411764705883\n</div>"]}}],"execution_count":94},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":95}],"metadata":{"name":"13_NLP_Coding_Along","notebookId":3381900799839324},"nbformat":4,"nbformat_minor":0}
