{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "df = df.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_prev (l_in):\n",
    "    l_out = []\n",
    "    l_out.append(l_in[0])\n",
    "    for i in range(len(l_in)-1):\n",
    "        l_out.append(l_out[i] + l_in[i+1])\n",
    "    return [e - 1 for e in l_out]\n",
    "\n",
    "# df and X must have the same data\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "columns_to_encode = [1, 2] # Change here\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), columns_to_encode)], remainder='passthrough')\n",
    "columns_to_encode = [df.iloc[:, del_idx].nunique() for del_idx in columns_to_encode]\n",
    "columns_to_encode = sum_prev(columns_to_encode)\n",
    "X = np.array(ct.fit_transform(X))\n",
    "X = np.delete(X, columns_to_encode, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss_X = StandardScaler()\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "X_test = ss_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the DFF_NN (Using Dropout and EarlyStopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the batch size, the faster you train the model.\n",
    "\n",
    "The larger the batch size, the more likely you are to overfit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1000\n",
      "8000/8000 [==============================] - 2s 200us/sample - loss: 0.7303 - acc: 0.6064 - val_loss: 0.5947 - val_acc: 0.7570\n",
      "Epoch 2/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.6060 - acc: 0.7089 - val_loss: 0.5157 - val_acc: 0.7975\n",
      "Epoch 3/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.5540 - acc: 0.7533 - val_loss: 0.4787 - val_acc: 0.7975\n",
      "Epoch 4/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.5296 - acc: 0.7765 - val_loss: 0.4643 - val_acc: 0.7975\n",
      "Epoch 5/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.5183 - acc: 0.7806 - val_loss: 0.4560 - val_acc: 0.7975\n",
      "Epoch 6/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.5063 - acc: 0.7871 - val_loss: 0.4512 - val_acc: 0.7975\n",
      "Epoch 7/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.5026 - acc: 0.7924 - val_loss: 0.4475 - val_acc: 0.7975\n",
      "Epoch 8/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4959 - acc: 0.7918 - val_loss: 0.4438 - val_acc: 0.7975\n",
      "Epoch 9/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4860 - acc: 0.7943 - val_loss: 0.4413 - val_acc: 0.7975\n",
      "Epoch 10/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4819 - acc: 0.7951 - val_loss: 0.4372 - val_acc: 0.7975\n",
      "Epoch 11/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.4763 - acc: 0.7960 - val_loss: 0.4347 - val_acc: 0.7975\n",
      "Epoch 12/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.4772 - acc: 0.7956 - val_loss: 0.4326 - val_acc: 0.7975\n",
      "Epoch 13/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4706 - acc: 0.7962 - val_loss: 0.4312 - val_acc: 0.7975\n",
      "Epoch 14/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4712 - acc: 0.7964 - val_loss: 0.4303 - val_acc: 0.7975\n",
      "Epoch 15/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4666 - acc: 0.7977 - val_loss: 0.4283 - val_acc: 0.7975\n",
      "Epoch 16/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4639 - acc: 0.7975 - val_loss: 0.4264 - val_acc: 0.7975\n",
      "Epoch 17/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4569 - acc: 0.7987 - val_loss: 0.4222 - val_acc: 0.7975\n",
      "Epoch 18/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.4595 - acc: 0.8008 - val_loss: 0.4210 - val_acc: 0.7975\n",
      "Epoch 19/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4539 - acc: 0.8036 - val_loss: 0.4173 - val_acc: 0.7985\n",
      "Epoch 20/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4561 - acc: 0.8035 - val_loss: 0.4146 - val_acc: 0.8005\n",
      "Epoch 21/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.4473 - acc: 0.8085 - val_loss: 0.4102 - val_acc: 0.8030\n",
      "Epoch 22/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4440 - acc: 0.8092 - val_loss: 0.4075 - val_acc: 0.8045\n",
      "Epoch 23/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4560 - acc: 0.8100 - val_loss: 0.4067 - val_acc: 0.8055\n",
      "Epoch 24/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4432 - acc: 0.8076 - val_loss: 0.4041 - val_acc: 0.8060\n",
      "Epoch 25/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4378 - acc: 0.8124 - val_loss: 0.4005 - val_acc: 0.8075\n",
      "Epoch 26/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4427 - acc: 0.8136 - val_loss: 0.3995 - val_acc: 0.8105\n",
      "Epoch 27/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4412 - acc: 0.8124 - val_loss: 0.3966 - val_acc: 0.8125\n",
      "Epoch 28/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4315 - acc: 0.8150 - val_loss: 0.3923 - val_acc: 0.8185\n",
      "Epoch 29/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4388 - acc: 0.8130 - val_loss: 0.3914 - val_acc: 0.8275\n",
      "Epoch 30/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4323 - acc: 0.8181 - val_loss: 0.3887 - val_acc: 0.8295\n",
      "Epoch 31/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4326 - acc: 0.8139 - val_loss: 0.3869 - val_acc: 0.8295\n",
      "Epoch 32/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4328 - acc: 0.8149 - val_loss: 0.3860 - val_acc: 0.8355\n",
      "Epoch 33/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4287 - acc: 0.8176 - val_loss: 0.3855 - val_acc: 0.8310\n",
      "Epoch 34/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4295 - acc: 0.8174 - val_loss: 0.3846 - val_acc: 0.8310\n",
      "Epoch 35/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4228 - acc: 0.8215 - val_loss: 0.3807 - val_acc: 0.8385\n",
      "Epoch 36/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4225 - acc: 0.8216 - val_loss: 0.3795 - val_acc: 0.8440\n",
      "Epoch 37/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4260 - acc: 0.8213 - val_loss: 0.3793 - val_acc: 0.8370\n",
      "Epoch 38/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4242 - acc: 0.8225 - val_loss: 0.3784 - val_acc: 0.8400\n",
      "Epoch 39/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4198 - acc: 0.821 - 0s 36us/sample - loss: 0.4221 - acc: 0.8211 - val_loss: 0.3768 - val_acc: 0.8430\n",
      "Epoch 40/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4246 - acc: 0.8217 - val_loss: 0.3761 - val_acc: 0.8470\n",
      "Epoch 41/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4220 - acc: 0.8221 - val_loss: 0.3760 - val_acc: 0.8455\n",
      "Epoch 42/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4206 - acc: 0.8209 - val_loss: 0.3750 - val_acc: 0.8480\n",
      "Epoch 43/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4148 - acc: 0.8251 - val_loss: 0.3729 - val_acc: 0.8485\n",
      "Epoch 44/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4160 - acc: 0.8248 - val_loss: 0.3721 - val_acc: 0.8480\n",
      "Epoch 45/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4186 - acc: 0.8206 - val_loss: 0.3723 - val_acc: 0.8485\n",
      "Epoch 46/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4219 - acc: 0.8209 - val_loss: 0.3731 - val_acc: 0.8480\n",
      "Epoch 47/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4180 - acc: 0.8225 - val_loss: 0.3720 - val_acc: 0.8465\n",
      "Epoch 48/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4192 - acc: 0.8244 - val_loss: 0.3714 - val_acc: 0.8510\n",
      "Epoch 49/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.4139 - acc: 0.8214 - val_loss: 0.3714 - val_acc: 0.8470\n",
      "Epoch 50/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4144 - acc: 0.8250 - val_loss: 0.3696 - val_acc: 0.8515\n",
      "Epoch 51/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4197 - acc: 0.8224 - val_loss: 0.3705 - val_acc: 0.8470\n",
      "Epoch 52/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4188 - acc: 0.8175 - val_loss: 0.3706 - val_acc: 0.8435\n",
      "Epoch 53/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.4118 - acc: 0.8236 - val_loss: 0.3688 - val_acc: 0.8475\n",
      "Epoch 54/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4074 - acc: 0.8255 - val_loss: 0.3669 - val_acc: 0.8540\n",
      "Epoch 55/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4114 - acc: 0.8242 - val_loss: 0.3670 - val_acc: 0.8535\n",
      "Epoch 56/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4164 - acc: 0.8204 - val_loss: 0.3681 - val_acc: 0.8525\n",
      "Epoch 57/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4194 - acc: 0.8221 - val_loss: 0.3700 - val_acc: 0.8460\n",
      "Epoch 58/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4127 - acc: 0.8223 - val_loss: 0.3678 - val_acc: 0.8510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4196 - acc: 0.8202 - val_loss: 0.3684 - val_acc: 0.8500\n",
      "Epoch 60/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4184 - acc: 0.8215 - val_loss: 0.3690 - val_acc: 0.8515\n",
      "Epoch 61/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4108 - acc: 0.8265 - val_loss: 0.3685 - val_acc: 0.8500\n",
      "Epoch 62/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4128 - acc: 0.8260 - val_loss: 0.3674 - val_acc: 0.8530\n",
      "Epoch 63/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4197 - acc: 0.8230 - val_loss: 0.3682 - val_acc: 0.8515\n",
      "Epoch 64/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.4168 - acc: 0.8217 - val_loss: 0.3675 - val_acc: 0.8490\n",
      "Epoch 65/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.4144 - acc: 0.8229 - val_loss: 0.3678 - val_acc: 0.8505\n",
      "Epoch 66/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4132 - acc: 0.8264 - val_loss: 0.3668 - val_acc: 0.8540\n",
      "Epoch 67/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4148 - acc: 0.8231 - val_loss: 0.3667 - val_acc: 0.8525\n",
      "Epoch 68/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4039 - acc: 0.8270 - val_loss: 0.3651 - val_acc: 0.8535\n",
      "Epoch 69/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4124 - acc: 0.8236 - val_loss: 0.3639 - val_acc: 0.8550\n",
      "Epoch 70/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4148 - acc: 0.8250 - val_loss: 0.3648 - val_acc: 0.8540\n",
      "Epoch 71/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4163 - acc: 0.8227 - val_loss: 0.3649 - val_acc: 0.8560\n",
      "Epoch 72/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4142 - acc: 0.8266 - val_loss: 0.3656 - val_acc: 0.8525\n",
      "Epoch 73/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4157 - acc: 0.8254 - val_loss: 0.3646 - val_acc: 0.8560\n",
      "Epoch 74/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4165 - acc: 0.8215 - val_loss: 0.3649 - val_acc: 0.8510\n",
      "Epoch 75/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4118 - acc: 0.8291 - val_loss: 0.3642 - val_acc: 0.8525\n",
      "Epoch 76/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4124 - acc: 0.8259 - val_loss: 0.3632 - val_acc: 0.8550\n",
      "Epoch 77/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4046 - acc: 0.8311 - val_loss: 0.3616 - val_acc: 0.8570\n",
      "Epoch 78/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4180 - acc: 0.8256 - val_loss: 0.3623 - val_acc: 0.8570\n",
      "Epoch 79/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4083 - acc: 0.8260 - val_loss: 0.3613 - val_acc: 0.8590\n",
      "Epoch 80/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4150 - acc: 0.8217 - val_loss: 0.3620 - val_acc: 0.8550\n",
      "Epoch 81/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.4079 - acc: 0.8273 - val_loss: 0.3625 - val_acc: 0.8540\n",
      "Epoch 82/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4092 - acc: 0.8248 - val_loss: 0.3624 - val_acc: 0.8540\n",
      "Epoch 83/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.4110 - acc: 0.8253 - val_loss: 0.3614 - val_acc: 0.8535\n",
      "Epoch 84/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4080 - acc: 0.8281 - val_loss: 0.3608 - val_acc: 0.8580\n",
      "Epoch 85/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4106 - acc: 0.8276 - val_loss: 0.3602 - val_acc: 0.8595\n",
      "Epoch 86/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4067 - acc: 0.8278 - val_loss: 0.3597 - val_acc: 0.8580\n",
      "Epoch 87/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4128 - acc: 0.8242 - val_loss: 0.3600 - val_acc: 0.8590\n",
      "Epoch 88/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4092 - acc: 0.8264 - val_loss: 0.3593 - val_acc: 0.8575\n",
      "Epoch 89/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4133 - acc: 0.8229 - val_loss: 0.3606 - val_acc: 0.8565\n",
      "Epoch 90/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4051 - acc: 0.8264 - val_loss: 0.3591 - val_acc: 0.8560\n",
      "Epoch 91/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4081 - acc: 0.8255 - val_loss: 0.3586 - val_acc: 0.8580\n",
      "Epoch 92/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4085 - acc: 0.8259 - val_loss: 0.3586 - val_acc: 0.8610\n",
      "Epoch 93/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4039 - acc: 0.8276 - val_loss: 0.3568 - val_acc: 0.8605\n",
      "Epoch 94/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4124 - acc: 0.8253 - val_loss: 0.3579 - val_acc: 0.8595\n",
      "Epoch 95/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4088 - acc: 0.8260 - val_loss: 0.3585 - val_acc: 0.8560\n",
      "Epoch 96/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4088 - acc: 0.8261 - val_loss: 0.3580 - val_acc: 0.8600\n",
      "Epoch 97/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4056 - acc: 0.8319 - val_loss: 0.3581 - val_acc: 0.8620\n",
      "Epoch 98/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.4099 - acc: 0.8245 - val_loss: 0.3593 - val_acc: 0.8570\n",
      "Epoch 99/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4117 - acc: 0.8266 - val_loss: 0.3592 - val_acc: 0.8575\n",
      "Epoch 100/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4061 - acc: 0.8300 - val_loss: 0.3593 - val_acc: 0.8560\n",
      "Epoch 101/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.4038 - acc: 0.8305 - val_loss: 0.3572 - val_acc: 0.8575\n",
      "Epoch 102/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4040 - acc: 0.8294 - val_loss: 0.3572 - val_acc: 0.8575\n",
      "Epoch 103/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.4129 - acc: 0.8236 - val_loss: 0.3585 - val_acc: 0.8565\n",
      "Epoch 104/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4102 - acc: 0.8284 - val_loss: 0.3569 - val_acc: 0.8620\n",
      "Epoch 105/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4110 - acc: 0.8264 - val_loss: 0.3581 - val_acc: 0.8570\n",
      "Epoch 106/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4070 - acc: 0.8254 - val_loss: 0.3556 - val_acc: 0.8615\n",
      "Epoch 107/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4080 - acc: 0.829 - 0s 50us/sample - loss: 0.4079 - acc: 0.8299 - val_loss: 0.3568 - val_acc: 0.8605\n",
      "Epoch 108/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4113 - acc: 0.8265 - val_loss: 0.3569 - val_acc: 0.8595\n",
      "Epoch 109/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4082 - acc: 0.8291 - val_loss: 0.3573 - val_acc: 0.8580\n",
      "Epoch 110/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4081 - acc: 0.8278 - val_loss: 0.3568 - val_acc: 0.8595\n",
      "Epoch 111/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4091 - acc: 0.8271 - val_loss: 0.3561 - val_acc: 0.8605\n",
      "Epoch 112/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4062 - acc: 0.8270 - val_loss: 0.3564 - val_acc: 0.8600\n",
      "Epoch 113/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4053 - acc: 0.8286 - val_loss: 0.3556 - val_acc: 0.8600\n",
      "Epoch 114/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.4037 - acc: 0.8284 - val_loss: 0.3555 - val_acc: 0.8610\n",
      "Epoch 115/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4055 - acc: 0.8236 - val_loss: 0.3546 - val_acc: 0.8605\n",
      "Epoch 116/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4128 - acc: 0.8216 - val_loss: 0.3569 - val_acc: 0.8550\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.4009 - acc: 0.8278 - val_loss: 0.3552 - val_acc: 0.8590\n",
      "Epoch 118/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.4042 - acc: 0.8269 - val_loss: 0.3537 - val_acc: 0.8620 0s - loss: 0.3953 - acc: \n",
      "Epoch 119/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.4086 - acc: 0.8255 - val_loss: 0.3547 - val_acc: 0.8595\n",
      "Epoch 120/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4097 - acc: 0.8260 - val_loss: 0.3546 - val_acc: 0.8585\n",
      "Epoch 121/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4041 - acc: 0.8289 - val_loss: 0.3541 - val_acc: 0.8615\n",
      "Epoch 122/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4036 - acc: 0.8253 - val_loss: 0.3538 - val_acc: 0.8600\n",
      "Epoch 123/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4097 - acc: 0.8286 - val_loss: 0.3549 - val_acc: 0.8605\n",
      "Epoch 124/1000\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4042 - acc: 0.8257 - val_loss: 0.3547 - val_acc: 0.8575\n",
      "Epoch 125/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4117 - acc: 0.8275 - val_loss: 0.3543 - val_acc: 0.8630\n",
      "Epoch 126/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4055 - acc: 0.8285 - val_loss: 0.3547 - val_acc: 0.8580\n",
      "Epoch 127/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4132 - acc: 0.8229 - val_loss: 0.3559 - val_acc: 0.8560\n",
      "Epoch 128/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4037 - acc: 0.8271 - val_loss: 0.3545 - val_acc: 0.8580\n",
      "Epoch 129/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4071 - acc: 0.8271 - val_loss: 0.3556 - val_acc: 0.8550\n",
      "Epoch 130/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4130 - acc: 0.8219 - val_loss: 0.3554 - val_acc: 0.8555\n",
      "Epoch 131/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4092 - acc: 0.8300 - val_loss: 0.3557 - val_acc: 0.8570\n",
      "Epoch 132/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4097 - acc: 0.8260 - val_loss: 0.3553 - val_acc: 0.8580\n",
      "Epoch 133/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4024 - acc: 0.8292 - val_loss: 0.3542 - val_acc: 0.8585\n",
      "Epoch 134/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4086 - acc: 0.8282 - val_loss: 0.3540 - val_acc: 0.8605\n",
      "Epoch 135/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4053 - acc: 0.8256 - val_loss: 0.3531 - val_acc: 0.8600\n",
      "Epoch 136/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.4081 - acc: 0.8253 - val_loss: 0.3531 - val_acc: 0.8600\n",
      "Epoch 137/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3998 - acc: 0.8305 - val_loss: 0.3529 - val_acc: 0.8585\n",
      "Epoch 138/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4055 - acc: 0.8275 - val_loss: 0.3545 - val_acc: 0.8570\n",
      "Epoch 139/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4054 - acc: 0.8279 - val_loss: 0.3529 - val_acc: 0.8590\n",
      "Epoch 140/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4073 - acc: 0.8273 - val_loss: 0.3539 - val_acc: 0.8595\n",
      "Epoch 141/1000\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.4048 - acc: 0.8300 - val_loss: 0.3521 - val_acc: 0.8625\n",
      "Epoch 142/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4011 - acc: 0.8305 - val_loss: 0.3508 - val_acc: 0.8600\n",
      "Epoch 143/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.4078 - acc: 0.8273 - val_loss: 0.3525 - val_acc: 0.8580\n",
      "Epoch 144/1000\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.4092 - acc: 0.8260 - val_loss: 0.3539 - val_acc: 0.8570\n",
      "Epoch 145/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.4076 - acc: 0.8264 - val_loss: 0.3541 - val_acc: 0.8585\n",
      "Epoch 146/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.4082 - acc: 0.8254 - val_loss: 0.3554 - val_acc: 0.8565\n",
      "Epoch 147/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.4067 - acc: 0.8291 - val_loss: 0.3542 - val_acc: 0.8565\n",
      "Epoch 148/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3999 - acc: 0.8295 - val_loss: 0.3530 - val_acc: 0.8570\n",
      "Epoch 149/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3991 - acc: 0.8307 - val_loss: 0.3508 - val_acc: 0.8600\n",
      "Epoch 150/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.4045 - acc: 0.8304 - val_loss: 0.3524 - val_acc: 0.8605\n",
      "Epoch 151/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4052 - acc: 0.8265 - val_loss: 0.3522 - val_acc: 0.8585\n",
      "Epoch 152/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.4011 - acc: 0.8291 - val_loss: 0.3522 - val_acc: 0.8580\n",
      "Epoch 153/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.4083 - acc: 0.8219 - val_loss: 0.3527 - val_acc: 0.8565\n",
      "Epoch 154/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.4026 - acc: 0.8309 - val_loss: 0.3524 - val_acc: 0.8580\n",
      "Epoch 155/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.4090 - acc: 0.8259 - val_loss: 0.3527 - val_acc: 0.8595\n",
      "Epoch 156/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.4079 - acc: 0.8256 - val_loss: 0.3527 - val_acc: 0.8600\n",
      "Epoch 157/1000\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.4030 - acc: 0.8289 - val_loss: 0.3528 - val_acc: 0.8575\n",
      "Epoch 158/1000\n",
      "8000/8000 [==============================] - 1s 124us/sample - loss: 0.4024 - acc: 0.8266 - val_loss: 0.3533 - val_acc: 0.8585\n",
      "Epoch 159/1000\n",
      "8000/8000 [==============================] - 1s 89us/sample - loss: 0.4085 - acc: 0.8259 - val_loss: 0.3538 - val_acc: 0.8570\n",
      "Epoch 160/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.4047 - acc: 0.8259 - val_loss: 0.3538 - val_acc: 0.8565\n",
      "Epoch 161/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4017 - acc: 0.8275 - val_loss: 0.3522 - val_acc: 0.8600\n",
      "Epoch 162/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4027 - acc: 0.8300 - val_loss: 0.3526 - val_acc: 0.8580\n",
      "Epoch 163/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4013 - acc: 0.8278 - val_loss: 0.3521 - val_acc: 0.8580\n",
      "Epoch 164/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4070 - acc: 0.8286 - val_loss: 0.3533 - val_acc: 0.8590\n",
      "Epoch 165/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.4041 - acc: 0.8257 - val_loss: 0.3525 - val_acc: 0.8565\n",
      "Epoch 166/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4060 - acc: 0.8251 - val_loss: 0.3521 - val_acc: 0.8570\n",
      "Epoch 167/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4038 - acc: 0.8285 - val_loss: 0.3519 - val_acc: 0.8585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c14885c320>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=25, mode='min')\n",
    "\n",
    "# Creating the model\n",
    "model = Sequential()\n",
    "\n",
    "# Input/hidder layer\n",
    "model.add(Dense(units=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "# Hidder layer\n",
    "model.add(Dense(units=X_train.shape[1] // 2, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=1000, validation_data=(X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising (Using Dropout and EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.404216</td>\n",
       "      <td>0.826875</td>\n",
       "      <td>0.353690</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.408585</td>\n",
       "      <td>0.825500</td>\n",
       "      <td>0.354742</td>\n",
       "      <td>0.8595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.409691</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.354555</td>\n",
       "      <td>0.8585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.404097</td>\n",
       "      <td>0.828875</td>\n",
       "      <td>0.354056</td>\n",
       "      <td>0.8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.403635</td>\n",
       "      <td>0.825250</td>\n",
       "      <td>0.353839</td>\n",
       "      <td>0.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.409702</td>\n",
       "      <td>0.828625</td>\n",
       "      <td>0.354862</td>\n",
       "      <td>0.8605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.825750</td>\n",
       "      <td>0.354722</td>\n",
       "      <td>0.8575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.411732</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.354323</td>\n",
       "      <td>0.8630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.405523</td>\n",
       "      <td>0.828500</td>\n",
       "      <td>0.354709</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.413201</td>\n",
       "      <td>0.822875</td>\n",
       "      <td>0.355934</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.403739</td>\n",
       "      <td>0.827125</td>\n",
       "      <td>0.354467</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.407086</td>\n",
       "      <td>0.827125</td>\n",
       "      <td>0.355573</td>\n",
       "      <td>0.8550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.412968</td>\n",
       "      <td>0.821875</td>\n",
       "      <td>0.355393</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.409198</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.355726</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.409678</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.355305</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.402416</td>\n",
       "      <td>0.829250</td>\n",
       "      <td>0.354205</td>\n",
       "      <td>0.8585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.408561</td>\n",
       "      <td>0.828250</td>\n",
       "      <td>0.354038</td>\n",
       "      <td>0.8605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.405255</td>\n",
       "      <td>0.825625</td>\n",
       "      <td>0.353082</td>\n",
       "      <td>0.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.408110</td>\n",
       "      <td>0.825250</td>\n",
       "      <td>0.353080</td>\n",
       "      <td>0.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.399839</td>\n",
       "      <td>0.830500</td>\n",
       "      <td>0.352889</td>\n",
       "      <td>0.8585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.405464</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.354472</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.405398</td>\n",
       "      <td>0.827875</td>\n",
       "      <td>0.352869</td>\n",
       "      <td>0.8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.407328</td>\n",
       "      <td>0.827250</td>\n",
       "      <td>0.353909</td>\n",
       "      <td>0.8595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.404750</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.352069</td>\n",
       "      <td>0.8625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.401147</td>\n",
       "      <td>0.830500</td>\n",
       "      <td>0.350793</td>\n",
       "      <td>0.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.407833</td>\n",
       "      <td>0.827250</td>\n",
       "      <td>0.352550</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.409203</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.353851</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.407607</td>\n",
       "      <td>0.826375</td>\n",
       "      <td>0.354121</td>\n",
       "      <td>0.8585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.408220</td>\n",
       "      <td>0.825375</td>\n",
       "      <td>0.355423</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.406693</td>\n",
       "      <td>0.829125</td>\n",
       "      <td>0.354191</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.399870</td>\n",
       "      <td>0.829500</td>\n",
       "      <td>0.353025</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.399090</td>\n",
       "      <td>0.830750</td>\n",
       "      <td>0.350807</td>\n",
       "      <td>0.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.404473</td>\n",
       "      <td>0.830375</td>\n",
       "      <td>0.352440</td>\n",
       "      <td>0.8605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.405177</td>\n",
       "      <td>0.826500</td>\n",
       "      <td>0.352203</td>\n",
       "      <td>0.8585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.401069</td>\n",
       "      <td>0.829125</td>\n",
       "      <td>0.352166</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.408291</td>\n",
       "      <td>0.821875</td>\n",
       "      <td>0.352743</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.402576</td>\n",
       "      <td>0.830875</td>\n",
       "      <td>0.352402</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.409040</td>\n",
       "      <td>0.825875</td>\n",
       "      <td>0.352699</td>\n",
       "      <td>0.8595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.407943</td>\n",
       "      <td>0.825625</td>\n",
       "      <td>0.352713</td>\n",
       "      <td>0.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.403047</td>\n",
       "      <td>0.828875</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>0.8575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.402385</td>\n",
       "      <td>0.826625</td>\n",
       "      <td>0.353348</td>\n",
       "      <td>0.8585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.408464</td>\n",
       "      <td>0.825875</td>\n",
       "      <td>0.353838</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.404671</td>\n",
       "      <td>0.825875</td>\n",
       "      <td>0.353759</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.401750</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.352162</td>\n",
       "      <td>0.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.402750</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.352573</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.401287</td>\n",
       "      <td>0.827750</td>\n",
       "      <td>0.352098</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.828625</td>\n",
       "      <td>0.353307</td>\n",
       "      <td>0.8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.404089</td>\n",
       "      <td>0.825750</td>\n",
       "      <td>0.352505</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.405968</td>\n",
       "      <td>0.825125</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.403779</td>\n",
       "      <td>0.828500</td>\n",
       "      <td>0.351889</td>\n",
       "      <td>0.8585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       acc  val_loss  val_acc\n",
       "117  0.404216  0.826875  0.353690   0.8620\n",
       "118  0.408585  0.825500  0.354742   0.8595\n",
       "119  0.409691  0.826000  0.354555   0.8585\n",
       "120  0.404097  0.828875  0.354056   0.8615\n",
       "121  0.403635  0.825250  0.353839   0.8600\n",
       "122  0.409702  0.828625  0.354862   0.8605\n",
       "123  0.404167  0.825750  0.354722   0.8575\n",
       "124  0.411732  0.827500  0.354323   0.8630\n",
       "125  0.405523  0.828500  0.354709   0.8580\n",
       "126  0.413201  0.822875  0.355934   0.8560\n",
       "127  0.403739  0.827125  0.354467   0.8580\n",
       "128  0.407086  0.827125  0.355573   0.8550\n",
       "129  0.412968  0.821875  0.355393   0.8555\n",
       "130  0.409198  0.830000  0.355726   0.8570\n",
       "131  0.409678  0.826000  0.355305   0.8580\n",
       "132  0.402416  0.829250  0.354205   0.8585\n",
       "133  0.408561  0.828250  0.354038   0.8605\n",
       "134  0.405255  0.825625  0.353082   0.8600\n",
       "135  0.408110  0.825250  0.353080   0.8600\n",
       "136  0.399839  0.830500  0.352889   0.8585\n",
       "137  0.405464  0.827500  0.354472   0.8570\n",
       "138  0.405398  0.827875  0.352869   0.8590\n",
       "139  0.407328  0.827250  0.353909   0.8595\n",
       "140  0.404750  0.830000  0.352069   0.8625\n",
       "141  0.401147  0.830500  0.350793   0.8600\n",
       "142  0.407833  0.827250  0.352550   0.8580\n",
       "143  0.409203  0.826000  0.353851   0.8570\n",
       "144  0.407607  0.826375  0.354121   0.8585\n",
       "145  0.408220  0.825375  0.355423   0.8565\n",
       "146  0.406693  0.829125  0.354191   0.8565\n",
       "147  0.399870  0.829500  0.353025   0.8570\n",
       "148  0.399090  0.830750  0.350807   0.8600\n",
       "149  0.404473  0.830375  0.352440   0.8605\n",
       "150  0.405177  0.826500  0.352203   0.8585\n",
       "151  0.401069  0.829125  0.352166   0.8580\n",
       "152  0.408291  0.821875  0.352743   0.8565\n",
       "153  0.402576  0.830875  0.352402   0.8580\n",
       "154  0.409040  0.825875  0.352699   0.8595\n",
       "155  0.407943  0.825625  0.352713   0.8600\n",
       "156  0.403047  0.828875  0.352785   0.8575\n",
       "157  0.402385  0.826625  0.353348   0.8585\n",
       "158  0.408464  0.825875  0.353838   0.8570\n",
       "159  0.404671  0.825875  0.353759   0.8565\n",
       "160  0.401750  0.827500  0.352162   0.8600\n",
       "161  0.402750  0.830000  0.352573   0.8580\n",
       "162  0.401287  0.827750  0.352098   0.8580\n",
       "163  0.407000  0.828625  0.353307   0.8590\n",
       "164  0.404089  0.825750  0.352505   0.8565\n",
       "165  0.405968  0.825125  0.352082   0.8570\n",
       "166  0.403779  0.828500  0.351889   0.8585"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c147e10908>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the DFF_NN (Using only EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1000\n",
      "8000/8000 [==============================] - 1s 184us/sample - loss: 0.6926 - acc: 0.5295 - val_loss: 0.5982 - val_acc: 0.7085\n",
      "Epoch 2/1000\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.5533 - acc: 0.7574 - val_loss: 0.5160 - val_acc: 0.7880\n",
      "Epoch 3/1000\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4958 - acc: 0.7934 - val_loss: 0.4805 - val_acc: 0.7970\n",
      "Epoch 4/1000\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4717 - acc: 0.7972 - val_loss: 0.4620 - val_acc: 0.7985\n",
      "Epoch 5/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4582 - acc: 0.7972 - val_loss: 0.4490 - val_acc: 0.7980\n",
      "Epoch 6/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4488 - acc: 0.7979 - val_loss: 0.4392 - val_acc: 0.7995\n",
      "Epoch 7/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4412 - acc: 0.8011 - val_loss: 0.4315 - val_acc: 0.8045\n",
      "Epoch 8/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4351 - acc: 0.8039 - val_loss: 0.4254 - val_acc: 0.8115\n",
      "Epoch 9/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4297 - acc: 0.8102 - val_loss: 0.4199 - val_acc: 0.8170\n",
      "Epoch 10/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4249 - acc: 0.8142 - val_loss: 0.4152 - val_acc: 0.8220\n",
      "Epoch 11/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4205 - acc: 0.8164 - val_loss: 0.4109 - val_acc: 0.8250\n",
      "Epoch 12/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4163 - acc: 0.8175 - val_loss: 0.4065 - val_acc: 0.8265\n",
      "Epoch 13/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4122 - acc: 0.8211 - val_loss: 0.4020 - val_acc: 0.8275\n",
      "Epoch 14/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4077 - acc: 0.8256 - val_loss: 0.3980 - val_acc: 0.8300\n",
      "Epoch 15/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4030 - acc: 0.8294 - val_loss: 0.3926 - val_acc: 0.8325\n",
      "Epoch 16/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3981 - acc: 0.8309 - val_loss: 0.3875 - val_acc: 0.8395\n",
      "Epoch 17/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3934 - acc: 0.8344 - val_loss: 0.3827 - val_acc: 0.8375\n",
      "Epoch 18/1000\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3888 - acc: 0.8369 - val_loss: 0.3787 - val_acc: 0.8445\n",
      "Epoch 19/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3846 - acc: 0.8393 - val_loss: 0.3734 - val_acc: 0.8470\n",
      "Epoch 20/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3803 - acc: 0.8401 - val_loss: 0.3691 - val_acc: 0.8450\n",
      "Epoch 21/1000\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3766 - acc: 0.8426 - val_loss: 0.3649 - val_acc: 0.8515\n",
      "Epoch 22/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3728 - acc: 0.8457 - val_loss: 0.3610 - val_acc: 0.8515\n",
      "Epoch 23/1000\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3694 - acc: 0.8478 - val_loss: 0.3581 - val_acc: 0.8545\n",
      "Epoch 24/1000\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3665 - acc: 0.8470 - val_loss: 0.3541 - val_acc: 0.8560\n",
      "Epoch 25/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3634 - acc: 0.8503 - val_loss: 0.3519 - val_acc: 0.8580\n",
      "Epoch 26/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3610 - acc: 0.8511 - val_loss: 0.3492 - val_acc: 0.8590\n",
      "Epoch 27/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3587 - acc: 0.8520 - val_loss: 0.3475 - val_acc: 0.8585\n",
      "Epoch 28/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3564 - acc: 0.8536 - val_loss: 0.3449 - val_acc: 0.8600\n",
      "Epoch 29/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3546 - acc: 0.8526 - val_loss: 0.3433 - val_acc: 0.8615\n",
      "Epoch 30/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3531 - acc: 0.8549 - val_loss: 0.3431 - val_acc: 0.8635\n",
      "Epoch 31/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3515 - acc: 0.8551 - val_loss: 0.3414 - val_acc: 0.8640\n",
      "Epoch 32/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3503 - acc: 0.8546 - val_loss: 0.3406 - val_acc: 0.8650\n",
      "Epoch 33/1000\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.3493 - acc: 0.8565 - val_loss: 0.3393 - val_acc: 0.8640\n",
      "Epoch 34/1000\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.3483 - acc: 0.8562 - val_loss: 0.3386 - val_acc: 0.8655\n",
      "Epoch 35/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.3474 - acc: 0.8572 - val_loss: 0.3383 - val_acc: 0.8650\n",
      "Epoch 36/1000\n",
      "8000/8000 [==============================] - 1s 185us/sample - loss: 0.3467 - acc: 0.8579 - val_loss: 0.3377 - val_acc: 0.8640.3492 - acc: 0.\n",
      "Epoch 37/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3461 - acc: 0.8572 - val_loss: 0.3371 - val_acc: 0.8660\n",
      "Epoch 38/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3456 - acc: 0.8580 - val_loss: 0.3374 - val_acc: 0.8635\n",
      "Epoch 39/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3449 - acc: 0.8590 - val_loss: 0.3372 - val_acc: 0.8645\n",
      "Epoch 40/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3443 - acc: 0.8587 - val_loss: 0.3368 - val_acc: 0.8655\n",
      "Epoch 41/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3438 - acc: 0.8590 - val_loss: 0.3369 - val_acc: 0.8635\n",
      "Epoch 42/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3417 - acc: 0.860 - 0s 53us/sample - loss: 0.3434 - acc: 0.8590 - val_loss: 0.3371 - val_acc: 0.8655\n",
      "Epoch 43/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3430 - acc: 0.8601 - val_loss: 0.3360 - val_acc: 0.8655\n",
      "Epoch 44/1000\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.3424 - acc: 0.8594 - val_loss: 0.3361 - val_acc: 0.8655\n",
      "Epoch 45/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3421 - acc: 0.8594 - val_loss: 0.3364 - val_acc: 0.8655\n",
      "Epoch 46/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3417 - acc: 0.8594 - val_loss: 0.3356 - val_acc: 0.8645\n",
      "Epoch 47/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3413 - acc: 0.8599 - val_loss: 0.3346 - val_acc: 0.8665\n",
      "Epoch 48/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3413 - acc: 0.8590 - val_loss: 0.3361 - val_acc: 0.8665\n",
      "Epoch 49/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3409 - acc: 0.8591 - val_loss: 0.3348 - val_acc: 0.8655\n",
      "Epoch 50/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3403 - acc: 0.8586 - val_loss: 0.3352 - val_acc: 0.8680\n",
      "Epoch 51/1000\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 0.3404 - acc: 0.8604 - val_loss: 0.3357 - val_acc: 0.8640\n",
      "Epoch 52/1000\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.3398 - acc: 0.8605 - val_loss: 0.3342 - val_acc: 0.8665\n",
      "Epoch 53/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3410 - acc: 0.859 - 1s 75us/sample - loss: 0.3396 - acc: 0.8601 - val_loss: 0.3351 - val_acc: 0.8655\n",
      "Epoch 54/1000\n",
      "8000/8000 [==============================] - 1s 113us/sample - loss: 0.3394 - acc: 0.8601 - val_loss: 0.3345 - val_acc: 0.8640\n",
      "Epoch 55/1000\n",
      "8000/8000 [==============================] - 1s 147us/sample - loss: 0.3392 - acc: 0.8594 - val_loss: 0.3356 - val_acc: 0.8665\n",
      "Epoch 56/1000\n",
      "8000/8000 [==============================] - 2s 217us/sample - loss: 0.3391 - acc: 0.8584 - val_loss: 0.3344 - val_acc: 0.8665\n",
      "Epoch 57/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3387 - acc: 0.8599 - val_loss: 0.3349 - val_acc: 0.8650\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3390 - acc: 0.8601 - val_loss: 0.3341 - val_acc: 0.8670\n",
      "Epoch 59/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3384 - acc: 0.8595 - val_loss: 0.3343 - val_acc: 0.8665\n",
      "Epoch 60/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3387 - acc: 0.8618 - val_loss: 0.3358 - val_acc: 0.8660\n",
      "Epoch 61/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3381 - acc: 0.8600 - val_loss: 0.3341 - val_acc: 0.8645\n",
      "Epoch 62/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3377 - acc: 0.8605 - val_loss: 0.3341 - val_acc: 0.8665\n",
      "Epoch 63/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3379 - acc: 0.8608 - val_loss: 0.3339 - val_acc: 0.8650\n",
      "Epoch 64/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3375 - acc: 0.8601 - val_loss: 0.3331 - val_acc: 0.8650\n",
      "Epoch 65/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3374 - acc: 0.8608 - val_loss: 0.3336 - val_acc: 0.8655\n",
      "Epoch 66/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3370 - acc: 0.8610 - val_loss: 0.3336 - val_acc: 0.8665\n",
      "Epoch 67/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3369 - acc: 0.8615 - val_loss: 0.3349 - val_acc: 0.8635\n",
      "Epoch 68/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3367 - acc: 0.8621 - val_loss: 0.3337 - val_acc: 0.8675\n",
      "Epoch 69/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3364 - acc: 0.8609 - val_loss: 0.3355 - val_acc: 0.8625\n",
      "Epoch 70/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3364 - acc: 0.8615 - val_loss: 0.3364 - val_acc: 0.8610\n",
      "Epoch 71/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3364 - acc: 0.8624 - val_loss: 0.3338 - val_acc: 0.8680\n",
      "Epoch 72/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3360 - acc: 0.8615 - val_loss: 0.3334 - val_acc: 0.8675\n",
      "Epoch 73/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3357 - acc: 0.8614 - val_loss: 0.3360 - val_acc: 0.8615\n",
      "Epoch 74/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3363 - acc: 0.8636 - val_loss: 0.3338 - val_acc: 0.8640\n",
      "Epoch 75/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3353 - acc: 0.8625 - val_loss: 0.3338 - val_acc: 0.8650\n",
      "Epoch 76/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3354 - acc: 0.8629 - val_loss: 0.3344 - val_acc: 0.8625\n",
      "Epoch 77/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3354 - acc: 0.8639 - val_loss: 0.3336 - val_acc: 0.8630\n",
      "Epoch 78/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3355 - acc: 0.8640 - val_loss: 0.3333 - val_acc: 0.8635\n",
      "Epoch 79/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3350 - acc: 0.8625 - val_loss: 0.3327 - val_acc: 0.8660\n",
      "Epoch 80/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3348 - acc: 0.8622 - val_loss: 0.3326 - val_acc: 0.8640\n",
      "Epoch 81/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3347 - acc: 0.8631 - val_loss: 0.3328 - val_acc: 0.8635\n",
      "Epoch 82/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3345 - acc: 0.8636 - val_loss: 0.3344 - val_acc: 0.8590\n",
      "Epoch 83/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3346 - acc: 0.8624 - val_loss: 0.3326 - val_acc: 0.8650\n",
      "Epoch 84/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3342 - acc: 0.8627 - val_loss: 0.3332 - val_acc: 0.8640\n",
      "Epoch 85/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3342 - acc: 0.8634 - val_loss: 0.3338 - val_acc: 0.8615\n",
      "Epoch 86/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3341 - acc: 0.8643 - val_loss: 0.3336 - val_acc: 0.8615\n",
      "Epoch 87/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3342 - acc: 0.8629 - val_loss: 0.3327 - val_acc: 0.8645\n",
      "Epoch 88/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3338 - acc: 0.8639 - val_loss: 0.3323 - val_acc: 0.8645\n",
      "Epoch 89/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3335 - acc: 0.8629 - val_loss: 0.3314 - val_acc: 0.8655\n",
      "Epoch 90/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3336 - acc: 0.8625 - val_loss: 0.3332 - val_acc: 0.8635\n",
      "Epoch 91/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3335 - acc: 0.8627 - val_loss: 0.3333 - val_acc: 0.8635\n",
      "Epoch 92/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3332 - acc: 0.8626 - val_loss: 0.3320 - val_acc: 0.8620\n",
      "Epoch 93/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3330 - acc: 0.8640 - val_loss: 0.3321 - val_acc: 0.8630\n",
      "Epoch 94/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3328 - acc: 0.8631 - val_loss: 0.3326 - val_acc: 0.8620\n",
      "Epoch 95/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3328 - acc: 0.8641 - val_loss: 0.3320 - val_acc: 0.8620\n",
      "Epoch 96/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3325 - acc: 0.8630 - val_loss: 0.3313 - val_acc: 0.8655\n",
      "Epoch 97/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3326 - acc: 0.8624 - val_loss: 0.3320 - val_acc: 0.8620\n",
      "Epoch 98/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3326 - acc: 0.8634 - val_loss: 0.3331 - val_acc: 0.8600\n",
      "Epoch 99/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3322 - acc: 0.8636 - val_loss: 0.3311 - val_acc: 0.8640\n",
      "Epoch 100/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3323 - acc: 0.8641 - val_loss: 0.3312 - val_acc: 0.8635\n",
      "Epoch 101/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3321 - acc: 0.8637 - val_loss: 0.3318 - val_acc: 0.8635\n",
      "Epoch 102/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3318 - acc: 0.8649 - val_loss: 0.3311 - val_acc: 0.8655\n",
      "Epoch 103/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3318 - acc: 0.8636 - val_loss: 0.3309 - val_acc: 0.8635\n",
      "Epoch 104/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3318 - acc: 0.8645 - val_loss: 0.3339 - val_acc: 0.8575\n",
      "Epoch 105/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3318 - acc: 0.8633 - val_loss: 0.3319 - val_acc: 0.8605\n",
      "Epoch 106/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3315 - acc: 0.8644 - val_loss: 0.3317 - val_acc: 0.8600\n",
      "Epoch 107/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3314 - acc: 0.8644 - val_loss: 0.3320 - val_acc: 0.8585\n",
      "Epoch 108/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3312 - acc: 0.8648 - val_loss: 0.3299 - val_acc: 0.8640\n",
      "Epoch 109/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3311 - acc: 0.8637 - val_loss: 0.3317 - val_acc: 0.8615\n",
      "Epoch 110/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3309 - acc: 0.8652 - val_loss: 0.3315 - val_acc: 0.8600\n",
      "Epoch 111/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3311 - acc: 0.8645 - val_loss: 0.3306 - val_acc: 0.8625\n",
      "Epoch 112/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3310 - acc: 0.8660 - val_loss: 0.3297 - val_acc: 0.8635\n",
      "Epoch 113/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3308 - acc: 0.8645 - val_loss: 0.3300 - val_acc: 0.8620\n",
      "Epoch 114/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3310 - acc: 0.8641 - val_loss: 0.3297 - val_acc: 0.8640\n",
      "Epoch 115/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3304 - acc: 0.866 - 0s 38us/sample - loss: 0.3304 - acc: 0.8662 - val_loss: 0.3323 - val_acc: 0.8595\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3309 - acc: 0.8666 - val_loss: 0.3320 - val_acc: 0.8600\n",
      "Epoch 117/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3306 - acc: 0.8634 - val_loss: 0.3315 - val_acc: 0.8595\n",
      "Epoch 118/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3304 - acc: 0.8643 - val_loss: 0.3298 - val_acc: 0.8640\n",
      "Epoch 119/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3301 - acc: 0.8664 - val_loss: 0.3301 - val_acc: 0.8640\n",
      "Epoch 120/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3301 - acc: 0.8666 - val_loss: 0.3319 - val_acc: 0.8615\n",
      "Epoch 121/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3300 - acc: 0.8655 - val_loss: 0.3294 - val_acc: 0.8645\n",
      "Epoch 122/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3299 - acc: 0.8656 - val_loss: 0.3305 - val_acc: 0.8610\n",
      "Epoch 123/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3301 - acc: 0.8650 - val_loss: 0.3318 - val_acc: 0.8605\n",
      "Epoch 124/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3298 - acc: 0.8660 - val_loss: 0.3295 - val_acc: 0.8635\n",
      "Epoch 125/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3297 - acc: 0.8655 - val_loss: 0.3304 - val_acc: 0.8625\n",
      "Epoch 126/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3294 - acc: 0.8671 - val_loss: 0.3295 - val_acc: 0.8645\n",
      "Epoch 127/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3297 - acc: 0.8654 - val_loss: 0.3292 - val_acc: 0.8640\n",
      "Epoch 128/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3297 - acc: 0.8661 - val_loss: 0.3294 - val_acc: 0.8625\n",
      "Epoch 129/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3294 - acc: 0.8662 - val_loss: 0.3298 - val_acc: 0.8635\n",
      "Epoch 130/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3293 - acc: 0.8662 - val_loss: 0.3295 - val_acc: 0.8625\n",
      "Epoch 131/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3292 - acc: 0.8666 - val_loss: 0.3307 - val_acc: 0.8595\n",
      "Epoch 132/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3282 - acc: 0.865 - 0s 38us/sample - loss: 0.3293 - acc: 0.8661 - val_loss: 0.3295 - val_acc: 0.8620\n",
      "Epoch 133/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3292 - acc: 0.8668 - val_loss: 0.3314 - val_acc: 0.8610\n",
      "Epoch 134/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3292 - acc: 0.8673 - val_loss: 0.3299 - val_acc: 0.8615\n",
      "Epoch 135/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3291 - acc: 0.8664 - val_loss: 0.3296 - val_acc: 0.8610\n",
      "Epoch 136/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3291 - acc: 0.8660 - val_loss: 0.3303 - val_acc: 0.8610\n",
      "Epoch 137/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3289 - acc: 0.8669 - val_loss: 0.3307 - val_acc: 0.8610\n",
      "Epoch 138/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3288 - acc: 0.8652 - val_loss: 0.3291 - val_acc: 0.8670\n",
      "Epoch 139/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3292 - acc: 0.8664 - val_loss: 0.3288 - val_acc: 0.8640\n",
      "Epoch 140/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3288 - acc: 0.8658 - val_loss: 0.3284 - val_acc: 0.8660\n",
      "Epoch 141/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3288 - acc: 0.8661 - val_loss: 0.3298 - val_acc: 0.8600\n",
      "Epoch 142/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3287 - acc: 0.8659 - val_loss: 0.3295 - val_acc: 0.8600\n",
      "Epoch 143/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3286 - acc: 0.8664 - val_loss: 0.3290 - val_acc: 0.8615\n",
      "Epoch 144/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3284 - acc: 0.8662 - val_loss: 0.3287 - val_acc: 0.8645\n",
      "Epoch 145/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3285 - acc: 0.8656 - val_loss: 0.3301 - val_acc: 0.8610\n",
      "Epoch 146/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3287 - acc: 0.8668 - val_loss: 0.3292 - val_acc: 0.8615\n",
      "Epoch 147/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3284 - acc: 0.8668 - val_loss: 0.3305 - val_acc: 0.8595\n",
      "Epoch 148/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3281 - acc: 0.8675 - val_loss: 0.3286 - val_acc: 0.8635\n",
      "Epoch 149/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3283 - acc: 0.8669 - val_loss: 0.3290 - val_acc: 0.8610\n",
      "Epoch 150/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3283 - acc: 0.8661 - val_loss: 0.3291 - val_acc: 0.8595\n",
      "Epoch 151/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3279 - acc: 0.8668 - val_loss: 0.3324 - val_acc: 0.8605\n",
      "Epoch 152/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3281 - acc: 0.8671 - val_loss: 0.3280 - val_acc: 0.8660\n",
      "Epoch 153/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3281 - acc: 0.8658 - val_loss: 0.3288 - val_acc: 0.8630\n",
      "Epoch 154/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3277 - acc: 0.8671 - val_loss: 0.3282 - val_acc: 0.8630\n",
      "Epoch 155/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3278 - acc: 0.8673 - val_loss: 0.3275 - val_acc: 0.8650\n",
      "Epoch 156/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3276 - acc: 0.8669 - val_loss: 0.3298 - val_acc: 0.8610\n",
      "Epoch 157/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3279 - acc: 0.8675 - val_loss: 0.3290 - val_acc: 0.8605\n",
      "Epoch 158/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3280 - acc: 0.8660 - val_loss: 0.3276 - val_acc: 0.8660\n",
      "Epoch 159/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3315 - acc: 0.863 - 0s 44us/sample - loss: 0.3278 - acc: 0.8652 - val_loss: 0.3288 - val_acc: 0.8645\n",
      "Epoch 160/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3276 - acc: 0.8671 - val_loss: 0.3293 - val_acc: 0.8605\n",
      "Epoch 161/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3275 - acc: 0.8668 - val_loss: 0.3282 - val_acc: 0.8630\n",
      "Epoch 162/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3276 - acc: 0.8674 - val_loss: 0.3277 - val_acc: 0.8635\n",
      "Epoch 163/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3277 - acc: 0.8666 - val_loss: 0.3293 - val_acc: 0.8600\n",
      "Epoch 164/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3274 - acc: 0.8668 - val_loss: 0.3287 - val_acc: 0.8600\n",
      "Epoch 165/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3273 - acc: 0.8666 - val_loss: 0.3288 - val_acc: 0.8640\n",
      "Epoch 166/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3273 - acc: 0.8669 - val_loss: 0.3291 - val_acc: 0.8605\n",
      "Epoch 167/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3273 - acc: 0.8676 - val_loss: 0.3300 - val_acc: 0.8595\n",
      "Epoch 168/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3273 - acc: 0.8659 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 169/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3274 - acc: 0.8662 - val_loss: 0.3281 - val_acc: 0.8630\n",
      "Epoch 170/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3273 - acc: 0.8665 - val_loss: 0.3291 - val_acc: 0.8610\n",
      "Epoch 171/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3271 - acc: 0.8662 - val_loss: 0.3289 - val_acc: 0.8620\n",
      "Epoch 172/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3272 - acc: 0.8662 - val_loss: 0.3282 - val_acc: 0.8640\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3271 - acc: 0.8676 - val_loss: 0.3286 - val_acc: 0.8625\n",
      "Epoch 174/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3268 - acc: 0.8676 - val_loss: 0.3274 - val_acc: 0.8650\n",
      "Epoch 175/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3267 - acc: 0.8664 - val_loss: 0.3289 - val_acc: 0.8615\n",
      "Epoch 176/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3272 - acc: 0.8656 - val_loss: 0.3279 - val_acc: 0.8620\n",
      "Epoch 177/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3267 - acc: 0.8668 - val_loss: 0.3274 - val_acc: 0.8655\n",
      "Epoch 178/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3267 - acc: 0.8652 - val_loss: 0.3282 - val_acc: 0.8650\n",
      "Epoch 179/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3265 - acc: 0.8673 - val_loss: 0.3279 - val_acc: 0.8630\n",
      "Epoch 180/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3264 - acc: 0.8671 - val_loss: 0.3283 - val_acc: 0.8615\n",
      "Epoch 181/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3267 - acc: 0.8656 - val_loss: 0.3286 - val_acc: 0.8625\n",
      "Epoch 182/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3262 - acc: 0.8658 - val_loss: 0.3286 - val_acc: 0.8645\n",
      "Epoch 183/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3263 - acc: 0.8674 - val_loss: 0.3292 - val_acc: 0.8610\n",
      "Epoch 184/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3264 - acc: 0.8669 - val_loss: 0.3277 - val_acc: 0.8655\n",
      "Epoch 185/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3263 - acc: 0.8666 - val_loss: 0.3293 - val_acc: 0.8630\n",
      "Epoch 186/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3263 - acc: 0.8668 - val_loss: 0.3274 - val_acc: 0.8660\n",
      "Epoch 187/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3264 - acc: 0.8676 - val_loss: 0.3282 - val_acc: 0.8630\n",
      "Epoch 188/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3258 - acc: 0.8660 - val_loss: 0.3276 - val_acc: 0.8640\n",
      "Epoch 189/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3258 - acc: 0.8673 - val_loss: 0.3288 - val_acc: 0.8620\n",
      "Epoch 190/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3259 - acc: 0.8662 - val_loss: 0.3282 - val_acc: 0.8635\n",
      "Epoch 191/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3259 - acc: 0.8658 - val_loss: 0.3285 - val_acc: 0.8630\n",
      "Epoch 192/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3259 - acc: 0.8665 - val_loss: 0.3276 - val_acc: 0.8650\n",
      "Epoch 193/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3256 - acc: 0.8664 - val_loss: 0.3272 - val_acc: 0.8665\n",
      "Epoch 194/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3256 - acc: 0.8669 - val_loss: 0.3273 - val_acc: 0.8650\n",
      "Epoch 195/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3253 - acc: 0.8670 - val_loss: 0.3277 - val_acc: 0.8640\n",
      "Epoch 196/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3255 - acc: 0.8659 - val_loss: 0.3278 - val_acc: 0.8640\n",
      "Epoch 197/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3255 - acc: 0.8674 - val_loss: 0.3306 - val_acc: 0.8600\n",
      "Epoch 198/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3260 - acc: 0.8661 - val_loss: 0.3287 - val_acc: 0.8620\n",
      "Epoch 199/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3253 - acc: 0.8658 - val_loss: 0.3284 - val_acc: 0.8640\n",
      "Epoch 200/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3251 - acc: 0.8671 - val_loss: 0.3295 - val_acc: 0.8615\n",
      "Epoch 201/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3255 - acc: 0.8660 - val_loss: 0.3276 - val_acc: 0.8655\n",
      "Epoch 202/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3257 - acc: 0.8665 - val_loss: 0.3290 - val_acc: 0.8645\n",
      "Epoch 203/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3252 - acc: 0.8665 - val_loss: 0.3281 - val_acc: 0.8640\n",
      "Epoch 204/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3250 - acc: 0.8661 - val_loss: 0.3283 - val_acc: 0.8635\n",
      "Epoch 205/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3250 - acc: 0.8674 - val_loss: 0.3293 - val_acc: 0.8635\n",
      "Epoch 206/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3250 - acc: 0.8670 - val_loss: 0.3284 - val_acc: 0.8635\n",
      "Epoch 207/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.3250 - acc: 0.8671 - val_loss: 0.3287 - val_acc: 0.8650\n",
      "Epoch 208/1000\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.3250 - acc: 0.8660 - val_loss: 0.3280 - val_acc: 0.8640\n",
      "Epoch 209/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3250 - acc: 0.8656 - val_loss: 0.3282 - val_acc: 0.8645\n",
      "Epoch 210/1000\n",
      "8000/8000 [==============================] - 1s 90us/sample - loss: 0.3245 - acc: 0.8659 - val_loss: 0.3291 - val_acc: 0.8625\n",
      "Epoch 211/1000\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.3244 - acc: 0.8669 - val_loss: 0.3281 - val_acc: 0.8640\n",
      "Epoch 212/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3246 - acc: 0.8675 - val_loss: 0.3280 - val_acc: 0.8635\n",
      "Epoch 213/1000\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.3243 - acc: 0.8670 - val_loss: 0.3284 - val_acc: 0.8625\n",
      "Epoch 214/1000\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3245 - acc: 0.8649 - val_loss: 0.3283 - val_acc: 0.8620\n",
      "Epoch 215/1000\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 0.3249 - acc: 0.8659 - val_loss: 0.3274 - val_acc: 0.8640\n",
      "Epoch 216/1000\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.3245 - acc: 0.8649 - val_loss: 0.3278 - val_acc: 0.8650\n",
      "Epoch 217/1000\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 0.3241 - acc: 0.8651 - val_loss: 0.3296 - val_acc: 0.8610\n",
      "Epoch 218/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.3243 - acc: 0.8658 - val_loss: 0.3275 - val_acc: 0.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c14a136b38>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=25, mode='min')\n",
    "\n",
    "# Creating the model\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Input/hidder layer\n",
    "model_2.add(Dense(units=X_train.shape[1], activation='relu'))\n",
    "# model_2.add(Dropout(rate=0.2))\n",
    "\n",
    "# Hidder layer\n",
    "model_2.add(Dense(units=X_train.shape[1] // 2, activation='relu'))\n",
    "# model_2.add(Dropout(rate=0.5))\n",
    "\n",
    "# Output layer\n",
    "model_2.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling\n",
    "model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the model\n",
    "model_2.fit(X_train, y_train, batch_size=128, epochs=1000, validation_data=(X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising (Using only EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.327362</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.328148</td>\n",
       "      <td>0.8630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.327281</td>\n",
       "      <td>0.866500</td>\n",
       "      <td>0.329148</td>\n",
       "      <td>0.8610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.327054</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.328882</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.327210</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.328246</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.327083</td>\n",
       "      <td>0.867625</td>\n",
       "      <td>0.328643</td>\n",
       "      <td>0.8625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.326779</td>\n",
       "      <td>0.867625</td>\n",
       "      <td>0.327409</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.326722</td>\n",
       "      <td>0.866375</td>\n",
       "      <td>0.328904</td>\n",
       "      <td>0.8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.327230</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.327928</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.326735</td>\n",
       "      <td>0.866750</td>\n",
       "      <td>0.327378</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.326675</td>\n",
       "      <td>0.865250</td>\n",
       "      <td>0.328151</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.326541</td>\n",
       "      <td>0.867250</td>\n",
       "      <td>0.327897</td>\n",
       "      <td>0.8630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.326448</td>\n",
       "      <td>0.867125</td>\n",
       "      <td>0.328302</td>\n",
       "      <td>0.8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.326691</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.328565</td>\n",
       "      <td>0.8625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.326228</td>\n",
       "      <td>0.865750</td>\n",
       "      <td>0.328647</td>\n",
       "      <td>0.8645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.326299</td>\n",
       "      <td>0.867375</td>\n",
       "      <td>0.329243</td>\n",
       "      <td>0.8610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.326448</td>\n",
       "      <td>0.866875</td>\n",
       "      <td>0.327659</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.326304</td>\n",
       "      <td>0.866625</td>\n",
       "      <td>0.329266</td>\n",
       "      <td>0.8630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.326336</td>\n",
       "      <td>0.866750</td>\n",
       "      <td>0.327415</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.326410</td>\n",
       "      <td>0.867625</td>\n",
       "      <td>0.328249</td>\n",
       "      <td>0.8630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.325778</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.327587</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.325825</td>\n",
       "      <td>0.867250</td>\n",
       "      <td>0.328757</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.325852</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.328158</td>\n",
       "      <td>0.8635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.325876</td>\n",
       "      <td>0.865750</td>\n",
       "      <td>0.328494</td>\n",
       "      <td>0.8630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.325867</td>\n",
       "      <td>0.866500</td>\n",
       "      <td>0.327570</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.325641</td>\n",
       "      <td>0.866375</td>\n",
       "      <td>0.327207</td>\n",
       "      <td>0.8665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.325638</td>\n",
       "      <td>0.866875</td>\n",
       "      <td>0.327277</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.325288</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.327740</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.325483</td>\n",
       "      <td>0.865875</td>\n",
       "      <td>0.327846</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.325462</td>\n",
       "      <td>0.867375</td>\n",
       "      <td>0.330601</td>\n",
       "      <td>0.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.325966</td>\n",
       "      <td>0.866125</td>\n",
       "      <td>0.328694</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.865750</td>\n",
       "      <td>0.328380</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.325121</td>\n",
       "      <td>0.867125</td>\n",
       "      <td>0.329512</td>\n",
       "      <td>0.8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.325465</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.327554</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.325746</td>\n",
       "      <td>0.866500</td>\n",
       "      <td>0.329025</td>\n",
       "      <td>0.8645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.325210</td>\n",
       "      <td>0.866500</td>\n",
       "      <td>0.328079</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.324966</td>\n",
       "      <td>0.866125</td>\n",
       "      <td>0.328269</td>\n",
       "      <td>0.8635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.325011</td>\n",
       "      <td>0.867375</td>\n",
       "      <td>0.329277</td>\n",
       "      <td>0.8635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.324982</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.328426</td>\n",
       "      <td>0.8635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.324996</td>\n",
       "      <td>0.867125</td>\n",
       "      <td>0.328656</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.325003</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.328016</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.325019</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.328175</td>\n",
       "      <td>0.8645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.324473</td>\n",
       "      <td>0.865875</td>\n",
       "      <td>0.329093</td>\n",
       "      <td>0.8625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.324371</td>\n",
       "      <td>0.866875</td>\n",
       "      <td>0.328103</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.324587</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.328034</td>\n",
       "      <td>0.8635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.324337</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.328389</td>\n",
       "      <td>0.8625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.324503</td>\n",
       "      <td>0.864875</td>\n",
       "      <td>0.328295</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.324865</td>\n",
       "      <td>0.865875</td>\n",
       "      <td>0.327368</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.324539</td>\n",
       "      <td>0.864875</td>\n",
       "      <td>0.327830</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.324094</td>\n",
       "      <td>0.865125</td>\n",
       "      <td>0.329577</td>\n",
       "      <td>0.8610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.324326</td>\n",
       "      <td>0.865750</td>\n",
       "      <td>0.327517</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       acc  val_loss  val_acc\n",
       "168  0.327362  0.866250  0.328148   0.8630\n",
       "169  0.327281  0.866500  0.329148   0.8610\n",
       "170  0.327054  0.866250  0.328882   0.8620\n",
       "171  0.327210  0.866250  0.328246   0.8640\n",
       "172  0.327083  0.867625  0.328643   0.8625\n",
       "173  0.326779  0.867625  0.327409   0.8650\n",
       "174  0.326722  0.866375  0.328904   0.8615\n",
       "175  0.327230  0.865625  0.327928   0.8620\n",
       "176  0.326735  0.866750  0.327378   0.8655\n",
       "177  0.326675  0.865250  0.328151   0.8650\n",
       "178  0.326541  0.867250  0.327897   0.8630\n",
       "179  0.326448  0.867125  0.328302   0.8615\n",
       "180  0.326691  0.865625  0.328565   0.8625\n",
       "181  0.326228  0.865750  0.328647   0.8645\n",
       "182  0.326299  0.867375  0.329243   0.8610\n",
       "183  0.326448  0.866875  0.327659   0.8655\n",
       "184  0.326304  0.866625  0.329266   0.8630\n",
       "185  0.326336  0.866750  0.327415   0.8660\n",
       "186  0.326410  0.867625  0.328249   0.8630\n",
       "187  0.325778  0.866000  0.327587   0.8640\n",
       "188  0.325825  0.867250  0.328757   0.8620\n",
       "189  0.325852  0.866250  0.328158   0.8635\n",
       "190  0.325876  0.865750  0.328494   0.8630\n",
       "191  0.325867  0.866500  0.327570   0.8650\n",
       "192  0.325641  0.866375  0.327207   0.8665\n",
       "193  0.325638  0.866875  0.327277   0.8650\n",
       "194  0.325288  0.867000  0.327740   0.8640\n",
       "195  0.325483  0.865875  0.327846   0.8640\n",
       "196  0.325462  0.867375  0.330601   0.8600\n",
       "197  0.325966  0.866125  0.328694   0.8620\n",
       "198  0.325301  0.865750  0.328380   0.8640\n",
       "199  0.325121  0.867125  0.329512   0.8615\n",
       "200  0.325465  0.866000  0.327554   0.8655\n",
       "201  0.325746  0.866500  0.329025   0.8645\n",
       "202  0.325210  0.866500  0.328079   0.8640\n",
       "203  0.324966  0.866125  0.328269   0.8635\n",
       "204  0.325011  0.867375  0.329277   0.8635\n",
       "205  0.324982  0.867000  0.328426   0.8635\n",
       "206  0.324996  0.867125  0.328656   0.8650\n",
       "207  0.325003  0.866000  0.328016   0.8640\n",
       "208  0.325019  0.865625  0.328175   0.8645\n",
       "209  0.324473  0.865875  0.329093   0.8625\n",
       "210  0.324371  0.866875  0.328103   0.8640\n",
       "211  0.324587  0.867500  0.328034   0.8635\n",
       "212  0.324337  0.867000  0.328389   0.8625\n",
       "213  0.324503  0.864875  0.328295   0.8620\n",
       "214  0.324865  0.865875  0.327368   0.8640\n",
       "215  0.324539  0.864875  0.327830   0.8650\n",
       "216  0.324094  0.865125  0.329577   0.8610\n",
       "217  0.324326  0.865750  0.327517   0.8640"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_2 = pd.DataFrame(model_2.history.history)\n",
    "losses_2[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c14a157a20>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2sAAAExCAYAAADiPzooAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xm8nGV9///Xvcw+Z8/JSvaVQPYgIISwGAUi1hWRlrbWVrtg7bfa9ttNKSKi8uvXBcGl1Vaxiq3WukAVFIIgokkIIRCSQPbkJGc/Z/a5l+v3xz2c5JBAEkwy55D38/HII+fMmbnv677nmpn7fV+f6x7LGGMQERERERGREcWudwNERERERETkSAprIiIiIiIiI5DCmoiIiIiIyAiksCYiIiIiIjICKayJiIiIiIiMQAprIiIiIiIiI5DCmoiIiIiIyAiksCYiIiIiIjICKayJiIiIiIiMQO7pXmEYhgSBOd2rPSbHsUZku0SORX1XRjP1Xxmt1HdltFLfHRliMee47nfaw1oQGPr7i6d7tcfU3Jweke0SORb1XRnN1H9ltFLfldFKfXdkaG9vOK77qQxSRERERERkBFJYExERERERGYEU1kREREREREYghTUREREREZERSGFNRERERERkBFJYExERERERGYEU1kREREREREYghTUREREREZERSGFNRERERERkBHLr3QAROX6mWsV7Yh12axvu7Dn1bs5pZyoVAKxE4uXvFwRUH3kYfB8rm8VqaMSZPAW7oeF0NFPkzGMM+GVwk2BZ9W7NiTMGq9KPXe4jjDdgkq1gOydt2ZgQQg/CACz7yP3klbBLPWDbhJkJr3wfBlWscj8m3gCx1Ctqq1UZwC52gjEELbNOzn4wBrvQgZ3bP+zmMDuRMPsbbK8x4BXBtsFywXaPb1lhgFXqifbT8fZZv4yd78DyigSts8B50eeQMRBWj7z9VDFh9FwnW07Pa86EWMVucBOYWCba1ydt2QbLK2CVesCEmEQTJtF4ctcximkvyKhkggBsG+tFb1CmUsbfsT06SG9oxM5msRqbsGKxYfcLC3n8JzcQ7N9H7LzzcadOO/p6jMH09hAcOIDd1oYzfsLwv4chwfbnCQf6j6vdluNgjx2HPXYclutiqlX8pzdRXb8Wf8tmCMOh+9oNDdgTJuJMmAjJJN4vHqH6i0cxxQIA8RUrSf/hH8PSBRjPw1v3a6o/X0NYKODUHmdPmoQ7azZ2U/PQcoMDHVTXPIj3xDqM7x9aX0sL7px5uHPmYo+fiL/5abz1a/HWryUcGMBuaMDKNmA1NBzatw2N2OPGRY+bORMrkSTs6cZ7Yh3VdWvBq+LOnos7Zx7OrFlY8UMfYqZaweRymNwg4cAA4YEDBB37CTr2Yzc2krj6jbhzz8ayLEy5TOk736b0H1+D0JB5//8hcdXqI57/qA9UyH30w1TXPDh83zc20vDhjxI//8KXfY5MGGLZJ1Z04O/Yjrfu1ziTzsJdtBg7nTnux76S9b3ksoKAsLuLsLMT56zJ2C0tJ2W5LxYW8pieHpwpU0/eMnt7CLs6cWbOxnJPw0dTUMEudBKm2iCWjm4zIc7ATtyuTdiFA/itc/DbF2BSbUd9fKxjLfE9P8cudGBV81heEWyH8py3UJn1xqMetFnVPLF9vyC+52HswgHwK1hBBTCEDZMJmqbjN0/HxBuwQh9MAECYbMEkWwlTrVheEWdwN/bgHuxiJyaWqR3cNGEXOnAPbiDWuQFnYBd+29l445fjTViGiTdiFw9iF7qwS93RgX3oQ1j7P/CwQg/C2v+BhxX6GDuGSTQSJpowsTR2NYdV7sMu99f+78OqDGCZgDCWqR2ATyRMtUVti2cwTgK7cBAn34Gd349xU/jjFjOwPc7gj9eTmDmJ7PKJpJrz2GGVwGmidDDA662SXjINJxZEB3MmwDhJjJsAOxbt98oAdnUQgipYDtguxnYxyWbCZBthqg0rrOL0b8fp34EzuGdov77wnNjFLqywOnSbwcKkWglTYwjT7YSpNsJkK3btgNIu9eD6eVrLOUypQG47xCa1Ept3Dn7b2Rg3idvzLG7PZpy+54eWbUxtBbYd7Rs3hV0dxPLLQ+sOky1UW85hYFcDtI7HnTMPa+oc7LBKbP8vie1/nNjBJwCDiWWjA2fAKvdiV3OHlhNvIEyPjQ56TYgVeNF2WzbGdqN9ZVnRuoMKll/GLvXU+uOhZfjjluKNW4KJpbC8IpZfxvJLtZ9L4JfAcqPnxElgnBhQe282QfSa6nkWuzJw1JdiGMsQtMwiaJpOmBkX/UuNwS734vTvwOp6nuq+PszYmYQT5xNOXkTMO0h87y+I7X0UJ79v+Euz4Sz89nPx2xcQNM2orSTq127fttrrYyOWX4yaaMepVJuwUimc7KG+hQkIilUKz1eIu4NkW7qxam/Vxo7jj5mPP3YRBBXcvudw+rZhVwYIU20EDZMJGqcQptsxicbo9ekksUtd2IVOrPxBvK48lYMelc4KQc4j3myRaPVJNZVxUxVs40Pog+UQNEbvDUHzdKzKALGuTTjdT2N7BcJ4Q7T/WmYTZMZjYmlMPAuA27st6oM9z4LtRO8vDVOpFBuJ21XiqSq2lzui7xNLE8ay0eu93IvT9xxu33PD+oZxElEfMgGEPsZYhE1nDbUzzIwb6p/GTWKF3lBfs4tdOIN7cHJ7sHN7sUu9w5Y91DcSTXgTXkN18iV4U1YSpsdiD+7Gqb33hel2gsYpBNlJ0Xum8bD8StQ/y73YpeifN3YBYdO0o/a/0cAyZuit47TwvID+/uLpXOVxaW5Oj8h2nanCQh5/45OEXZ2EuUFMLk/Y30tYO5gPOzshHh8KJVY6g//8cwS7dkAQHLE8e0w79sSJOOMmEHTsw9/8zLD7OdOmE195OXY2OxQYwo79BAc6oHzoQ9SeOInY0uW4U6fhPf1UFHgGjv4B9LIcB3vsWMLeXqhUwLZxps04bMTIEPb3E3YeHGqn1dRE/OKVJC65FH/rFkrfuhtTLJJavpzy5s2YfB4rncFqbiY8eGDY9tnjxuPOnkPY3YX/7OaoCVOmYmWyh9bX2UnY0z28nakUsUVLcMaOI8znonCVzxHmDv08tB7HwW5ri54biIJdMknY3XVi+2Xc+KgdlQrOzFnEX3MB5R/fh+ntIXb+hZhSEX/jk8TOO5/sh/4vzsRJQw8P83kG//ZD+BvWk/6zDxA//4Ja3+mj+K9fItjxPOk/eC+p3303lm0TdOwh+NHX8bZsw+8rE3T1Efb14c6bT3zlZSQuupBYawK7fxd21/PQuQtTKBAWy4SFMpWDZYrPdON3dA/bBvfsc3DPnh8F3FQMJx6SWjgdx/GwKgNg2QQtsyis303+M5+OnqOJk3AmTMCZOoXk8gXEJzbilHuxawe3Tn4/hD7V1HTyW8oU123DFPJYQRWCKqZcxe8rQHAo8DszZ0X9dc48cKKjDAuwJ56FO2sWViIJfhm3bxt25zPYe5+CbAO0TCHITsTE0sM+UL1SgoG13RQeeRpTquAuWEjqXTcQv2gFlmVhlfuiEFHsxPIrBP29FB9chynmcWIGO+bjxAzGjYOTICRGuKeDwub9eD1e1L4YJKc2E58/k+zSycSsXpx8B5ZXIGiegd8yi6BlFpZXiA68+7djFw8edhRsog9rr0Clo0Bhd0hyZjuxOTMIm6dgFztxuzbh9m6NAgm1g9rUGKx8F+FgiWreIfRsEk0esWxAmB1PmJ1ItZSguC8gGCjSNm47sVgRY7uEtX1lYhnsYjfO4C7CVBul+dcTNE3Hye/H27qF4uNbsPKdWBiM5RIb10hmdganKYNFiNW3m+K2AQZ3pXDiIa1zCySaDp1QeTG/YlPqiuMmA2LZACcRElRsCv0t5PrHUukBhzIOgziuTywTkGz1SLZ4uNkYgUniFWNUCy44LrEmF7cpjhWPgxMDO4ax3eggqzKIVenH8oqYeEMUHhPNtRDZQphsrm1/J05+f9Rvy31RwKrmIahGoSc7IRpJKebovXcL/VvjJJo8qgUH49vEm0LcjEXpIJggOuCPZXzOuriXRKsByxl2YPnC82fijRgnTlAIGNzqU9wbkhlXpGVGDicW9Q1jxwmaphI0TgH3sBNHboowPZYg3kZpd554e4pYvIhd6sEuRsHWLnZjlfsw8SxhshWTasNtaGWww6Prv7bgd0Un0RJtFs3T+smOLxNmx+I3zyTITKG8v0x520HK2w5gWRaNl8+lYek4bFOO9meqFZNsg6BMuOlxuu/ZQLXnsPdwNyQ9tkrbuXlic+fij1+GcRJYXgHKOfy+Mr7JEIQpgjBBckoDMXsQp9iJVc3VwpkbjZKZEBP6FLf04/d5ZBaNwWlqiF6TqVbC9DjCzFgIPWIH1hPrWIvTsxmLaD8GpAjtNHYmhXHTGDcJJsCqBT4Cj9CD0gEodVpYjU24s2bhnLOMoHEylSe3UP7VU1Se2kJsUhtNF46nYewAbm5X9N5RO2j3ija9z7fSvy1BWB1+qBrL+KQnQmL+TNyl5+E0Z2snHCq1Ey5P4fZvxwRQ6olT6IxT6koQbw5pfO1krFlL8ZtnEvb2MPA/v6SwdjdYkJycJTM7Q7zFJvdMnsKWPCaI1u00p0lfvIjk0rOx9jxDuHsr4YEO3IxDfN4knFnnYLLjsHL7Yf9OvF17oZzHtQs4sRBjLIqdcQrdWYoHHUz09oPlgpux8AYNtV2MFbNxW1K4LWmcxhi2l8eqDmJ5BVJjIb1sFsG4BQSNU3AGd+P0bsPpew671IWfh0JnguqgS2qSQ2L+LIL2szFhSOmXT9H3SBderhamLXAbLNyMi52wsBMWTtzCifvYjofrVCCZIsyMj/6l2yAMa89zmaCvSHX/INV9A/i9BZyMi5s1JFIlLMsnqFqEno0JLJJtVTLjKqTbq+BYlCrjKRVaqBaSkMpiNTZjNbXiNGeJNTi4DQa32kV876M4g7sOve+VbQoH45S6E1TzDl7ewSu4uOmA9nNyNE4tDYVqv2IxuDuFdc5F+H/01Zd8L62X9vbjq/ZRWKtRWKsfYwxhVyf+1i34T2/Ce2GU6fDQ5brYTc3YEyZEI0bjJ2DK5ShQ7d+PKeRxps/EnTsXd9acKCTkBjH5PGFfL2FHRxTADnRgjxlDbNl5xJYux5kwkepjj0YjTU8+Eb0JpTNRsJswcWhkyx4/gfBAB966X+NtWI/J57HHjqstZ9kRI24vua2eR3jgUFusxqZoGYuXHrVEz/g+YVcnZnAQZ+asYSMO4eAApW9+A/+Rh7DnLyCx8jJiy1+DFY9Hj+vuIti7B3/bVoKtz+Jv24qVzkQhZOVlOGdNPmJ9YXc3/rYtBPv2RqNl8885+iiHMTj924nt+hlBdx/lfDPlzirB/gO4s+cQW7Ycd/ZcLNsi7Owg2Po0/o4dGNyhsgYrFsNqaMTKJHESFk5bI05TBhsf099Jec0jFB9ai7e7k8T0NlounUR6vMFYDv2bLfrvfRpjID53OvHJY4iPy5D78a/wDg4w9qqxNE0tESZbCbMTCbITCZxG+r75CMVfbyUxeyIU+qjsL0XdK+0TzwbEMgF22qXY4VDpjUp/7FhI6FtgjlJmYhnS7VUaJpdIT3HxKo0UOmyK+w3V3mDowxjASQSMXZijaUYRQjj4ZCN9W7MkxxoSbeAPBng5qOYcMBaxrE/DWWXcVABYmHiWSq9NbnuICWpBInP4wZwhlokOyN1UQGUgRuFgglJ3fOig98VtTzQGOKkAv+DgFRxMGN3PSQbEa8t54QR5GMYp7I8+ARunlEg2e/Q9l8EruMSaoHFqmeyYPKm2KmFg0bslS++WDKFvYdkMLfuIZjiG5KQ4yVnjcMa0UN26i/KOAaoDFk4yYMLlhuSsCRg3FY2MFDsPdUMswoZJUViyDo1OGidB/7oCvQ91QFg70EpBw6Qi6bPcqIR41mKCxin427dTXreZ0qb9VLvLQ/cfal8yRnxskmCghD9wKDhZCZeGt64i/nt/AZnDRjBNSGzvI6Q2/hvxnfcTlC26NjbQvz2N5VhYiXg08mAsTD4f9b9zF+DOnE3l4Ycwfb3YLU2E+SJ4Honli0hfeRlucxzHKeNSoLyjm/zjOymv2wT+Ye+T8RhUa6E3ncGdNw/j+ZjcIGagl7Dv0IklK5XGlI7+mWePHUf8sitIrn4T7vRoZCLs66X68zV4Gzdgt7RG740TJ0E8PnTixpRKWKnU0Oi7FY8z1IEwh372qhTuugP/mU2k3/JGmt64hCDWSnHDbsr3/wxTLBBbsozYooU4js/gP3+OcHCQ7Af/huTV10QlhUEFK/AI7QTBvv34W7dQffjBqPw5CLAnTiLcvw8rnSb1hiuIn7eMIExi8gVMpRyN+J89P6pw8H0qP/lfiv/2ZcKODrAs3HNq76mvvRjnrMlHjH6bMITv/yc9n/kMdnMLmQ/+DWHnQco//D7Bti1H7+strcSWLifsOoi/8Uns8RNI/94f4J6zALuhEashS/kH/0Phrs9hZbJk/+r/4jbECDY/ib9lM6XHn8Lki1FVxe+9h6Crk+qaB6k++nNMbnD4yuIJklddTfLa63EPGwE3xuA9/hiFL3+BYOuztfvGSbz+KlLvvB532vTh21kuU338MaqPPEiwazdBRwemvw84dDIotmQZBEH0ubZ/H/5z2/A3Px19htv2sIoRHAeCAKu1jfj5F+JtWEfY0YF91mQSr3sDeFXMQA9hZwfVdU+CMcQvvYLk66/EeB507YYDz1Pd1UX16W3RCUPAam3DnRN9/uN7UVv27cHfsxsqVbAsnCmTCfZGo3DxS6/AnTad0jfvxlQrpN7+TkimqK75GcGO7dEys1kSr7+KxFWrCTs6KP/wf/B+/fhhJ4YA14VahYrV0oo7bTr+zh2Yvt6j9gGITpTGli7HPXch7tx5OJOnYDkOplzGf/656DN4z+5DJ6e7u6M+D+D7mEIBZ/oM0u95H/FLLsX09+M9EVXBVNetJdy7Z3i/a2wk/tqL8TdvJti1A2f2HMa8+/cpDBSGTkyHvb2HTsTmc9F70+HP28uwJ52FO2cuzuQphD09Q+3G87CyaexMGjB427ZDtRr1CayoJBggkYj24VFOtFstrdiNTVipGK5bwe8ewD8QVTJZqRTOhHbc1gyxBovyln14+wdwxzeTvXQRle1dlNZvAT8g9a7ryfzpXxzX9pxOCmsnSGHt5DOVCsHBA4QHOsC2h8roCEP857bib9mCXwsRL7z5vzAqEVsWfQA4U6ZiZxsgmTxqydvJFA4OQGiwEyFubg92sQtjx6L6bCdRKyOpYKolTF8fdlO21iYTnU3u34EzsCN6XLKFID0Ok24fKlE5yh4Cv4RdGYhKiPwyYXpsFC4aJmDcNFYYgPHBmKgMKd6ISTTi5PfjHlhHrGMtsd7NGL9SK2fyoxKgWAYTz2LcFBx+EBvLRGe3M2MJ0+MJGs+KSggaJmN5BWJdm3C7n8Lp3RaVuARl8CvgxIbOJhvbPeJMF4CxXYKWOdEZ1kp/tF2HlfYM7edYFpNqBawjynaOJqhYWOkEJhWdyccv4Qzuxs9bdG/OUu6JURmIYUILyw2ZeIUhNXcCYbodu9yHnd+PXTgYlU8Z6H8uTeeTjcSabVKLZxJ//Zuw5izFGdwVPYe53Rg7hpeD4jNdeP1VrOax0DYB2s6KymobGrCzDdhjWoj7HdFZ3J5nayMItbPLtoOfGo/vjKE66DLw3Yfxtu7EnTUDy3Xwnt1GwyXzaLukGct1CWMZiGXwqi7FZ3spPbmLyjPPDxsps9IZEpddSua180m2VqIyr8ao3Ma4SZzcvmhkK7c3GgnxClAYIOjLY5w4OHEMLl5XjuqeHrx9fQSFKva48dhTZmFNnh2Vpe7ZTrh/D2H/QPQasGPgOMSWnUfm6pXE43mc3B6sfDeldZvJPfIclb05MGDFY+C6mGKJxEUXkPndG7Bnn4MJLMJ8HoqHvc+GPq1nz2GgdOSHdLD5SQZu/ifCjg4yf/J+kte+i2D3Lir/820q9/8EU65iNTZGpbitbbgzZ+HMmYszcRLFL92Ft34t8ZWXk7nxA/ibnqKy5mdUf/mLoZFyK5vFymSjUWjbxl24mNi5C6OTMxOj0fpg+3PRSaRtW7Gbm6MTK8vOA9umcMen8X75i+jAa/lrov2Wy0OljJXJRCPLdkBlzcOYcoXk299J+vf/EDubHdpGf+cOqmt+RmXNQwTbnyN+0QqSq99E7DUXYHI5yt/7DqXv/ueh98fDWI2NJN5wNYlLL8fkcodKiJuao5Mlc88+4kRLWMgTPLcNf+sWgr17sMe0D52UIgxrB2778J/dTPWxRyEIcM9diBWLHTqZ1dKKKeSjg67fgJXOkP3bfyRx6eXHvG/Y10vupn/AW78Wd+686OAOoFrF37nj0HPa3ELyytUkVl+DO2063rPPUPrWf1B96KdHPxBMpXEXLSHcv5dg9y7cufNIXX8DwZ7dVB76GcFz24bu58yejTt9BmEuFx2M7tuLGRwkfsmlZP/674aVmvtbt+DXHgtE/Wvu3Kh6wrKiwPSrX1L8ly8MVTocLnbBRTT83T9it7QO3w+FPOX/vCeqqihEI3lWtoH4xZcQW7Ycu6k5+oy1Lco/+gGVH98Lnoc772yoTQUwuRzBju3YEyaQfvcf4Z59DuX/uofyfT+CaiWqQqmdpDTlEtXHH4NKBauxEXf23FoFwEQwId76dXhPbYTqofI1q6ERZ8oUYkuWR5/jCxZiisVon2zdgikUiL/2YtxzF2DZNsb3qT78IKVv3h3tC9eNXtMNDcRecwGpd1w3rHricCYICJ7bivfkBvxtW/C3bo2qaxwXZ8KEaDsmTyG2eCmxJUuxGxoJDh6Mtvf7/x2dFLjwIrI3/sWwkm5/9y7CPbuJLT8vqj44THCgA//pTdjtY7EnTsRubSPsPBjti/W/Jti9G2f6jCg4zp477MQxYfR6ctrHHnV7jocJQ6oP/TSqFNm9C6u1DdPbE+37dAZ38RLiL5yMnnQW1V//kuqah6j+4ufYY9pJ/8F7ia+8jJbW7Mse85owxJSKmFzuZV/rVkvrcc8FN9Uq/jPRtA+C4LBpF9HJ7hfWF3Z3EezfV6tuOhCdbMpFQdJuaor61dLzcGfPGfYeZ8KQ6pqfRftm106shkYSr7+S5BvfFIX4EUhh7QQprP1mjDEEu3ZGc5zW/Rp/8zOEXZ0v/yDHwZkxc+hNzZ0zD3fWbKzUCU6KDio4A7ujs9VOAuMmozrlwd1ReUB+f22OQS92uTeay5CK5jEYN1UrdenELhzEzu3D9vKvbB+4SYKmaYSZcVjl/mh5pe4oRL3UYyxnaC4ITiJqR/nIA7OXeqw/Zj72WUuphAlwXIzlRCVLXjGay+EXh50FjOZmdEb/XmL+gLFjBM0zajX2CYybwAqq0T4s92J5Rbzxy6hOvYLq1MsxsXRUKnNgLU73M+AmCRONmERzVBrmJsFJYmw3CnDl3mgivQmj5yDVFpVSuemh58/E0rXyqqjMCvdFfcIvR6Msg7swsQyB04TXlYfx03HGTTxyo8IAq5qrTfL3ozKgzLjTeiEEYwyVB35M8a47CPM5Gv7mH0hcserlH1OpRGeTa6xk8vTM53oFwlwOb8N6vPVrMblBUtdejztn7jEf93LvvWE+T/7jN1N9+KGhkRIch/hrL45G1/P5KCR1dUZzVV84qEilyH7gQySufuOwkzymWiXY8fzQiaKwr5f4+RcSX7HyiAPj41F97FEKd32OsKcbK9sQHbQkEphicWi0yV2wmMyNH3jJebFDbXuJuYumUsbb8AThwMDQQYszZQrxi1fWRq5OjbCvl/KP76Ny3w8BiK+4lMSll+HMnB2dPOrtJejYj/G9Q/NZU6lo2/N5wtzgyx7kOTNm4owdd9ztMb5P6e5/x3ti3WELcXCmTos+Q+bMw5k67aivj+DggSicNjRiNTSA6w5VcXjr10I8Qfr3/oD4JZcO6y/Bvr14G54YOqkY7NiO1dwcld9PnEjTRRfiX7DyFZ9INMbgP/UkYVdXrdw/hz1+PInXveFllxkODlC5/8dREFm6/CXfE8LeHkr//R38jRuG7bP4ipUk3/hbw+Zyh319lP/3RwQ7tg+NkIEhftElxFdeRmzRkqOux1Qq+FuexUqlsCdMHHYy4oT3R6UC8fhvdGLWeB44zjHnAYeFPGHnQdzpM1/xuurJ+D6V+/+X6qM/x50zj9iy83DnznvJvmCMGbZfX83HvCYI8LdtwZ0+85gXI6s3hbUT9GruuKdCmMtFoWzrs4fOmNWG/e3xE4gtXIxz1lnYE6J5OC88JprjFEb169NnvuTBhlXoJL734WgiblDB8itgAky8kTDZhIk34PQ9NzTR+mgTU19g7FhtPkArYbIVQh+7HIU3yyscmkCeGUeQnUjYOIWgcTJhZhyEfjT/JShHk7JrYQLn8PIeojr/zPhho1jRymvh4KXYsSMDg1fCKXREV1azDysbrAxGE+lrE5i9sYshnnnlfdcr4eT2RBN1B3eDm8BvX4DfOuf0Xc3qDGQqZUyxdMou/jHaHKv/GmMofesbVH++hvjFl5C88mrs1iMv+GF8n2DnDvwdzxM7Z8FLno0XOVl03CCjlfruyKCwdoLUcY/NGIO/4QnKP/ofKg/+LCp9cBycadNxZ88ltnARsWXnYU+Y+NJnxqoF3IEduJ0bcA9uwO16CuxYdNWkxskYyyG+Zw2xzieHr9uOri417IpFlo3fvgBvwvn47edEl34Nylh+hTDZRNAwhbBpCmF67JEh6lVEfVdGM/VfGa3Ud2W0Ut8dGY43rI3MehqpO2MMpX//CuXv//fQJFPjVTGDg1iZDMmrVpN4w9W4c+YeMcz8wqiYk9sfzReqXcnOzncMK70Lky34YxdCGBLrfBJ7+71gQvxxSymc/zdUpl5O0Dw9GuV54Xte/HJtjtcgYXZ89B0pIiIiIiKvQgprcgRTKZO79aNUf3Y/sddcgD1uPACWZeEuWEji0iuw7AAnt5cwzGNMNOrlHlhL6ql/I/H8j4bmaYXJluhKfA2T8SacT9AwkbBhCt7YhYSNU4aXAIZ+9D05L3xg/IA5AAAgAElEQVTn0dG4SUI3CZnjn+sgIiIiIjIaKaydoUyxSPWXj1JZ8yBhx37cBYuIL12OM2UquY9+BP/ZZ0j/8Y2krr8hKmk0BvfAOuK7HyR+77/gHnxiKJAZ242+bLXcSxhvpLTg9ynPu5agaTrETuBiIYfNzxIREREROdPpyPgME+bzFP75E1TWPATVClZzC87UqZS/9x3K3/5mdKdkkoZbPkHikkuxyn0kt3yH5NN34/Y9V5sntpDS4j/Gb5uHVe7FKXRilbrxxy6mPPetLz8yJiIiIiIix0Vh7QwSdncz8FcfINixneRvvZXEpVfgLlwUfRljpYL39FP4m58msWwJaWcHif99H/GdD2AFFbxxSxm8/J+pzrgSk2is96aIiIiIiLzqKay9ChljqD7yMFYiQWzBIqxUimDPbgY++OeE/X00fvL/EX/NBQA4/dtxD6yLLgCS24+T3U3soZuxggphqp3y/Osozf9tgjHz67xVIiIiIiJnFoW1Vxnj++Rvv43Kj74f3eC6uOcsINi1E4yh6dN3kmoPiT/+KRLb/xe3d8vQY8NUG0F2IqVzb6Ay42r88csOXYVRREREREROK4W1VxFTKZO76R+oPvIwqd99N7GFi/HW/Rpv/Vrc1iztb55Odu17cHJ7MZaNN+E15C++ieqUSwkazgI3We9NEBERERGRGoW1V4mwu5vBj/wt/lMbyfzFh0i97VrwSjSmt5JueB5ncBfm4Aaqk1dQXP4XVKavwqTa6t1sERERERF5CQpro1hw8CDVhx+ksuZn+BufBMeh8W8+SPbsRmK/uIXk5nuwy31445ZQOP+vqExbBfFMvZstIiIiIiLHQWFtlAn27aXy0M+ornkQf/PTADhTp9B06TRamzeT3PmXsBOMZVOdtorikj/GH798+JdPi4iIiIjIiKewNgIZYwg79uNveRb/ua0Ee/cSduwn6NiP6e8DwJ13NtnffRfNjVvJ9t4H2FRmvZHc+GX47efit80/sS+kFhERERGREUVhbYQwYYi3fi3lH34f7/HHMPlc9AfHwR4/AWfCRBKXXIozfQaJ8xbTsPsbpJ76NPS5lM79PUpL3keYnVjfjRARERERkZNGYa3OTKVM6dvfovyD7xF27MdqaCS+8jJi88/BmTMXd/pMrEQiunMYkNz8TTIPvAOr0k95/m9TeM1fYtLt9d0IERERERE56RTW6sjbsJ7cJz5GuHcPsaXLybz3T4ivuPRQOHtBUCG55buknrgLt3871Ynnk7/4ZoL2c+rTcBEREREROeUU1uogLOQpfuHzlL/3HewJE2n8f3cQX/6aQ3cIPJzcHpz+HbjdT5Pc9DWcwgG8MecycOUXqc64WhcMERERERF5lVNYO828pzaS++g/Eh44QPLad5H5wz/Giru4+39FfM8a4rvX4HZvwgr9ocdUJ11I7vL/D2/yJQppIiIiIiJnCIW108T4PsWvfYXSv38Fe9w4mu74ErGzZ5N66iukn/gCdrkPY9n445ZQWvw+/OaZBM0zCJqn68urRURERETOQAprp0HY18vg3/8N/lNPknjDVWT+/AOkd36PzNd/H7vURWXKZZTnX4c36SJMsrnezRURERERkRFAYe0UC/bvY+CDf07Y1Un2wzeTvnARjff+DrGujVQnXUjh/C/hTziv3s0UEREREZERRmHtFPK3bWXgQx8Az6Pp058nNcan8T9XY3kFBq78EtUZV2kOmoiIiIiIHJV9rDuEYciHP/xh3vnOd3LDDTewa9euYX//13/9V9761rfytre9jfvvv/+UNXS0qT7+GAPvfx+W69D0+S+SdbfQ/L13gJuk/23/Q3WmrugoIiIiIiIv7Zgjaw888ADVapV77rmHDRs2cNttt3HXXXcBMDg4yNe//nV+8pOfUCqVePOb38yqVatOeaNHsnBwgMIdn6Fy3w9xJk9i/G+fTWbNO3EKB6hOvIDBK7+ESbXWu5kiIiIiIjLCHTOsrVu3jhUrVgCwePFiNm3aNPS3VCrFxIkTKZVKlEolrDN4pCgcHKD6y8co3PFpzEAfLcuSjJ3xa6zdT1CdchmFiz5MZcZV4MTq3VQRERERERkFjhnW8vk82Wx26HfHcfB9H9eNHjphwgRWr15NEAS8733vO+YKHceiuTn9GzT51HAc+6jtMr5P+amNVJ7ZTOXZzVQ3b8Sywc6kcTIpwnKZyvO78bsHAEi0hkxc1U1izmzCpZ8imP8W7HQrKSB1mrdJzgwv1XdFRgP1Xxmt1HdltFLfHV2OGday2SyFQmHo9zAMh4Laww8/TGdnJz/96U8BeM973sPSpUtZuHDhSy4vCAz9/cXftN0nXXNz+oh2Gc9j8EMfwFu/FgAnZZNoLAEQHrDwqjaWbUi3+CQXeSTawD3/EsqL3k1u4gXRnLQqUB152yuvHkfruyKjhfqvjFbquzJaqe+ODO3tDcd1v2OGtaVLl/Lggw9y9dVXs2HDBubMmTP0t6amJpLJJPF4HMuyaGhoYHBw8JW3egQxxpD/1Mfx1q9lzCWNNDdvxWofT2nZXxK0HtoHxokTptowyVZK8QZdNERERERERE6KY4a1VatW8eijj3LddddhjOHWW2/lq1/9KlOmTOGKK67gF7/4Bddeey22bbN06VIuuuii09HuU6709a9Sue+HNF88lrZp2ylceAvls98JTqLeTRMRERERkTOAZYwxp3OFnheMyKHXw4eEKz+9n9xNf09i1ZVMnfQDvCkryK36bJ1bKHJ0KmeQ0Uz9V0Yr9V0ZrdR3R4bjLYM85vesnWnCwQFyt96Mu3ARjX/2bpxyF964JfVuloiIiIiInGEU1l4k2LsXqhVS77qBeG/0NQW+wpqIiIiIiJxmCmsvEvb2AGC3jcHt3IBxEvhj5te5VSIiIiIicqZRWHuRsKcbALutjdjBJ/DHnANOvM6tEhERERGRM43C2ouEPd1gWdhNjbhdGzVfTURERERE6kJh7UVMTw9WUzOxweex/LLmq4mIiIiISF0orL1I2NON3daGe/AJAI2siYiIiIhIXSisvUjY043dGs1XC5OthI1T6t0kERERERE5AymsvUjY2xNdCfLgBrxxi8Gy6t0kERERERE5AymsHcaEIWFPD3ZLI07fNs1XExERERGRulFYO4wZGIAgIBYrYWE0X01EREREROpGYe0wL3zHWtzqBcAfu7iezRERERERkTOYwtphhsKavwe/eQYm2VznFomIiIiIyJlKYe0wYU8PAInyVs1XExERERGRulJYO8yhMshuvLGL6twaERERERE5kymsHSbs7cFKpbBdg0m21rs5IiIiIiJyBlNYO0zY043d0gSAcZN1bo2IiIiIiJzJFNYOE/Z0Yzc3AGCcRJ1bIyIiIiIiZzKFtcOEPT04TdnoF42siYiIiIhIHSms1RhjCHu6cZrS0e8KayIiIiIiUkcKazWmUIByGacxFf2uMkgREREREakjhbUavzu6bL/TUBtR08iaiIiIiIjUkcJaTdDVBYDTEAdUBikiIiIiIvWlsFbjd9fCWsYFwDgKayIiIiIiUj8KazVBV60MMuMAGlkTEREREZH6Ulir8bu7IB7HiYfRDbrAiIiIiIiI1JHCWk3Q1YXd2oYdVjF2DGyn3k0SEREREZEzmMJajd/djd3WBn5ZJZAiIiIiIlJ3Cms1QXc3dtsYLL8MuriIiIiIiIjUmcJajV8rg7SCCsbVfDUREREREakvhTXAVKuEAwPYbWNUBikiIiIiIiOCwhoQ9vYAYLe1YQVlfceaiIiIiIjUncIaEPZE37EWzVmrgMogRURERESkzhTWgLDnhZG1MRpZExERERGREUFhjeEja5qzJiIiIiIiI4HCGrWRNdvGamlRGaSIiIiIiIwICmuAGejHaW3FchyVQYqIiIiIyIjg1rsBI0Hyt95Cy6rL8UBlkCIiIiIiMiIcM6yFYchNN93Eli1biMfj3HLLLUydOhWAzZs3c+uttw7dd8OGDXz+85/nkksuOXUtPgXcWXPINKfp7y9GX4rtqAxSRERERETq65hh7YEHHqBarXLPPfewYcMGbrvtNu666y4Azj77bL7+9a8DcN999zF27NhRF9RezPLLoJE1ERERERGps2OGtXXr1rFixQoAFi9ezKZNm464T7FY5HOf+xx33333yW/h6WTCaGRNYU1EREREROrsmGEtn8+TzWaHfnccB9/3cd1DD/2v//ovrrzySlpbW4+5QsexaG5Ov8LmnjqOY9OcdQBIZhuJj8A2ihyN49gj8jUlcjzUf2W0Ut+V0Up9d3Q5ZljLZrMUCoWh38MwHBbUAH7wgx/w2c9+9rhWGASG/v7iCTbz1GtuTjPQ08sYoORZlEZgG0WOprk231JkNFL/ldFKfVdGK/XdkaG9veG47nfMS/cvXbqUhx9+GIguIDJnzpxhf8/lclSrVSZMmPAKmjkyPL6zj6/9clc0Xw1UBikiIiIiInV3zJG1VatW8eijj3LddddhjOHWW2/lq1/9KlOmTOGKK65gx44dTJo06XS09ZS5f2sXj+3s483vHAcorImIiIiISP0dM6zZts3NN9887LaZM2cO/bxw4ULuvPPOk9+y0ygTd8hX/EMja/pSbBERERERqbNjlkGeCbJxl2I1IPRK0Q0aWRMRERERkTpTWAMyiegqkNVyFNY0siYiIiIiIvWmsEZUBglQLkdXvTRuop7NERERERERUVgDyMSjqXvVcu0ypiqDFBERERGROlNYA7K1MkivojJIEREREREZGRTWODSy5lVrYU1lkCIiIiIiUmcKaxy6wIhficogNbImIiIiIiL1prDGoZG1wIu+Z01z1kREREREpN4U1jh0NcigWhtZUxmkiIiIiIjUmcIakI47WBYYr4zBAjte7yaJiIiIiMgZTmENsC2LTNwl9CtRCaRl1btJIiIiIiJyhlNYq8kmXCyvhHFUAikiIiIiIvXn1rsBI0U24WIFZYwuLiIiIiIiclyCwKevrwvfr9a7KSOS68ZpaWnHcV5Z7FJYq8kmHaxcBZNQWBMREREROR59fV0kk2kymfFYmko0jDGGQmGQvr4uxoyZ8IqWoTLImmzCxQ4qoDJIEREREZHj4vtVMplGBbWjsCyLTKbxNxp1VFiraUjEcFQGKSIiIiJyQhTUXtpvum8U1mqySRfHVBXWRERERERkRFBYq8kmHGJhBRyFNRERERGR0eLee3/AXXd9rt7NOCUU1mqyCZe4qRJqzpqIiIiIiIwAuhpkTTbhkqCKbyusiYiIiIicqB89fZDvbzpwUpf5pnPHs/qcccd1329+825++tOf4DgOixYt4U//9M/ZuHEDd9zxaVzXpaGhgY985Ba6u7u59dZ/wnVdHMfhH/7hn2hvH3tS232yKKzVZBMuCcujasXr3RQRERERETkBe/fuZv36tXzhC1/BcRz+/u//mkcf/TkbNqxn5crLeNe7buCRRx5mcDDHr3/9OHPnzuP97/9LnnzyCXK5QYW1ka4hGSNJlSpxnHo3RkRERERklFl9zrjjHgU72bZt28prX7sC143izaJFi9mx43luuOHdfO1rX+EDH/gT2tvHMn/+ubzxjb/FN77x73zwg+8nk8nyvvf9WV3afDw0Z60mm3BIUqWCRtZEREREREaT2bPn8Mwzm/B9H2MMGzY8weTJU7n//vu4+uo38rnPfZHp02fw/e9/l0ceWcOiRUv4zGfu4rLLruAb3/j3ejf/JWlkrSaas+ZRIUa63o0REREREZHjdtZZU1iwYBF/8ifvwRjDwoWLuOSSS3nmmae55ZabSKfTuK7LX//132OM4eab/xHHcbBtm/e//y/r3fyXpLBWk40ZXCukZOK01LsxIiIiIiJyXK6++pqhn6+77neG/e2cc87lK1+5+4jHfPGLXz3l7ToZVAZZ0+D6ABRNrM4tERERERERUVgbknUCAEqhwpqIiIiIiNSfwlpN2vIAKISqDBURERERkfpTWKuxgzIABY2siYiIiIjICKCw9gK/AkA+0MiaiIiIiIjUn8JajeWXAMgprImIiIiIyAigsPYCPyqDHPAV1kREREREpP4U1l5QK4Mc9J06N0RERERERERfin1IrQxywNMuERERERE5UYln/4vk5m+d1GWWz76Oyry3v+x9CoU8t912C/l8joGBfq655i3MmTOPz3zmdowxtLeP5SMf+SjPPffcEbclEsmT2t6TTcnkBV5UBtnvaWRNRERERGS02Lt3L6973etZufJyuru7uPHG95JIJPmnf7qVadOm893v/ic7d+7kk5/82BG3zZ07r97Nf1kKay/wXwhrqgwVERERETlRlXlvP+Yo2KnQ1tbGt7/9H6xZ8yDpdAbf9ykWe5k2bToAb33rOwDo6zvytpFOyaTGqoW13qpDEJo6t0ZERERERI7HN7/5dc49dyEf/vBHufzy12GMYcyYMezZsxuAu+/+N9asefCot410xxxZC8OQm266iS1bthCPx7nllluYOnXq0N/XrFnD5z//eQDmz5/PRz7yESzLOnUtPlVqYa1MnJIXkE1o0FFEREREZKS76KJLuP32j/OTn9xHU1MTjuPwwQ/+LR//+M3Ytk1bWxvXXns9Y8eOPeK2ke6YieSBBx6gWq1yzz33sGHDBm677TbuuusuAPL5PJ/61Kf42te+RmtrK1/+8pfp6+ujtbX1lDf8pKuFtQpx8hVfYU1EREREZBRYunQ5//Ef3zni9jvv/Jdhv5999jlH3DbSHbMMct26daxYsQKAxYsXs2nTpqG/PfHEE8yZM4dPfOITXH/99YwZM2Z0BjUAv0xguYTYFKpBvVsjIiIiIiJnuGMOH+XzebLZ7NDvjuPg+z6u69LX18fjjz/O9773PdLpNL/927/N4sWLmT59+ksuz3EsmpvTJ6f1J8lP9/yU5wY28sdudOlOO+6OuDaKvBTHsdVfZdRS/5XRSn1XRquT3XcPHrRwHF0G4+VY1ivPP8cMa9lslkKhMPR7GIa4bvSw5uZmFixYQHt7OwDLly9n8+bNLxvWgsDQ3198RY09VR7Z9SgPlXbyR3YCgAO9BfobE3VulcjxaW5Oj7jXlMjxUv+V0Up9V0ark913jTEEQXjSlvdqZMyR+ae9veG4HnvMGLx06VIefvhhADZs2MCcOXOG/nbuueeydetWent78X2fJ598klmzZp1I20eE1kQbA8an4kQja/mKyiBFRERERKS+jjmytmrVKh599FGuu+46jDHceuutfPWrX2XKlClcccUVfPCDH+QP//APAbjyyiuHhbnRoiURzbPrjUejaYWKX8/miIiIiIiIHDus2bbNzTffPOy2mTNnDv28evVqVq9effJbdhq1JtoA6I3FAHSBERERERERqTvNBgRaXxhZGwprGlkTEREREZH6Uljj0Mhat+OQjjkaWRMREREReZW58cb3smvXzpf8+9vffg2VSuX0Neg46JufgeZ4CwA9tkUm4VDQBUZERERERE7IT/bex317f3hSl3nVWW/k9WdddVKXOZoorAFxJ06TgR4bMnGHvMogRURERERGhb/7u7/iHe+4jiVLlrF589PceednaW5uIZ/PMTDQzzXXvIW3vOXtx728jo793HbbR/F9H8uy+MAHPsTs2XP42MduYt++vVSrVd71rt/hiitezxe/+HnWr19LGIasWvUGrr32+pO6bQprNWNC6HZDsglXI2siIiIiIifo9WddVZdRsGuueTP33fdDlixZxr33/pClS5czY8ZMVq68nO7uLm688b0nFNY+//lP8/a3v5MVKy5l27Yt3HbbR/nc577A+vVr+Zd/+TqWZfGrX/0SgB//+F7uuONLjBnTzr33/uCkb5vCWk1bENITC8jEHV1gRERERERklDj//Au5887PMDg4wMaNT3D77Z/lC1+4gzVrHiSdzuD7J3Zsv3PnThYtWgrA7Nlz6ew8SDqd4f/8n7/mk5/8GMVigde/PgqlN930Mb74xTvo6enhggtee9K3TWGtZkzg86TxmRh36cxX690cERERERE5DrZtc9llr+P2229jxYpL+da37ubccxfylre8nfXr1/LYY4+c0PKmTZvGxo1PcPHFK9m2bQutrW10d3ezZctmPv7x26lUKrztbatZtepKHnzwp9x0060YY7jhhmt53evewPjxE07atims1YzxPHpMlVkxW1+KLSIiIiIyiqxe/Sauvfa3+Na3/puOjv3cfvvH+clP7qOpqQnHcahWj38w5s/+7C/4xCdu4ZvfvBvf9/nbv/1H2tra6O3t4d3vvp5UKs111/0O8XicxsZGfv/3r6ehoYHzzruAcePGn9Ttsowx5qQu8Rg8L6C/v3g6V3lsxvDDb8znn1tbeEPyS9z39AAPvf+ierdK5Lg0N6dH3mtK5Dip/8popb4ro9XJ7rsHDuxi/PipJ215r0ZH20ft7Q3H9ViNrAEEZcb40UVFHDdHoRoQGoNtWXVumIiIiIiInCzPPLOJO+/87BG3X3HF60/oIiSni8IaYPllxgS1K0C6eSBBsRqQTWj3iIiIiIi8Wsyffy533PGlejfjuNn1bsBIYAUVxgQhAKE9CEChqsv3i4iIiIhI/SisARw2suZbAwC6fL+IiIiIiNSVwhpRGWRTGOJgU6UW1vTF2CIiIiIiUkcKa0RlkDbQ6mYph/0A5DWyJiIiIiIidaSwRjSyBtAaa6BYC2saWRMRERERefW48cb3smvXzno344TococAQ2GtiQ4/Cmv9Ja+eLRIRERERGVXK//sjyj/6wUldZnL1NSSvXH1SlzmaKKxx2MhavIWtuWeJORb7B8p1bpWIiIiIiBzL3/3dX/GOd1zHkiXL2Lz5ae6887M0N7eQz+cYGOjnmmveclzfofbggw/w3e/+J8YYAG655ZM0Njby6U9/is2bn8bzfN7znvdy0UWXHHHbihWXnpJtU1gjmrMG0Jpopa+nnwmNcfYqrImIiIiIHLfklavrMgp2zTVv5r77fsiSJcu4994fsnTpcmbMmMnKlZfT3d3FjTe+97jC2p49u/nUpz5DMpnkk5/8GL/61WMkEkkGBvr58pe/Rk9PN9/5zrcJQ3PEbQprp1JtZK0l0UZoAiY0B+zrL9W5USIiIiIiciznn38hd975GQYHB9i48Qluv/2z/P/t3XmcXGWd7/HPWWqv3tPdSWffV0IElDWIIsIFAReGZYZFQByZq+hVRwedQbwwyMxwHUc218EriiI6o7h7USCySyBAEpJAQjpJp9Pd6b32Ouc894+qNISEJA1Juir5vnn1q7ZTVb/q/qaoXz3Pec43vnEbDz/8IPF4As/bt4UDGxoaufHGLxGPx2lv38iiRYvp6mpn4cLFADQ1jeOjH/077r77e7tcd6BogRHA8svTIKPNADTU5OgYzI0MgYqIiIiISGWybZt3ves93HLLzSxdego//vEPWLRoMddddwPvfvd79ukzfSqV4rvf/SZf/vJNfP7z/0gkEsEYw7Rp01izZvXINp/+9Md3e92BopE1wPLK0yBjLQDUJLKkCy6DWY/6eGgsSxMRERERkb0466xzOP/8c/nxj/+bzs6t3HLLV/jDH35LXV0djuNQKBT2eP9EIsERRxzJFVdcTCwWo6amhu3bezjzzLN5+umnuPrqK/F9n8svv4rjjjthl+sOFDVrvLrASENsAgDRaAaooWMwq2ZNRERERKTCtbaO5+GHnwRgwoQ27rnnZ7tsc9tt33rD+1uWxQ033Lzb2/7X//rcPl13IKhZA/BzGCwaY60A2KFhoJWOwRwLJ9SObW0iIiIiIrJfrF69kjvu+Pou15966nv3aRGSg03NGuWRNTdKLJQg6sQIrCEAtgxoRUgRERERkT0xxmBZ1liXsU8WLFi0xxG2/e2troGhBUYoLzASigKl5fuHiv00JcJ0DGpFSBERERGRN+K6YdLpIS3MtxvGGNLpIVw3/KYfQyNrUFq639nRrDXRV+hlYl2UDh1rTURERETkDTU0NNPf30MqNTDWpVQk1w3T0ND85u+/H2upWsW24wgn64HSyFp7aiNT6qMs3zw4xpWJiIiIiFQux3EZN27CWJdxyNI0SCA/768I3vsVoHRg7L58aWStezhPwQvGuDoRERERETkcqVl7ncZII8PFYVprXQzQOaSpkCIiIiIicvCpWXudxkgTAHWJ0uIiW7TfmoiIiIiIjAE1a6/TGC41a5FICoAOLd8vIiIiIiJjQM3a6zRGGgHw7WEirq3l+0VEREREZEyoWXudllgrAJ2ZjtLy/RpZExERERGRMaBm7XUaIo20RFt5cXC1jrUmIiIiIiJjRs3abixoWMTq/pVMqo/RMZjVEdlFREREROSgU7O2G/PrF9Kd66I+mSVbDOjLFMe6JBEREREROcyoWduNBfULAfDDGwE0FVJERERERA46d28bBEHA9ddfz9q1awmHw9x4441MnTp15PYbb7yRZ555hkQiAcAdd9xBTU3Ngav4IJhdOwfXchkI1gNvo2Mwy+K22rEuS0REREREDiN7bdYeeOABCoUC9957LytWrODmm2/mzjvvHLl91apVfOc736GxsfGAFnowhZ0IM2tnsyW3FngbW7QipIiIiIiIHGR7nQa5fPlyli5dCsCSJUtYuXLlyG1BENDe3s51113HhRdeyE9/+tMDV+lBtqB+IS8NraE56WgapIiIiIiIHHR7HVlLpVIkk8mRy47j4HkeruuSyWS4+OKLufzyy/F9n0svvZRFixYxb968N3w8x7Gor4/vn+r3I8exd6rrmIlH8d/tP2Va8yBdqdqKrFkEds2uSDVRfqVaKbtSrZTd6rLXZi2ZTJJOp0cuB0GA65buFovFuPTSS4nFYgAcd9xxrFmzZo/Nmu8bBgYyb7Xu/a6+Pr5TXVPDswGIxDazbkM92/vSuLY1VuWJvKHXZ1ekmii/UigkMt4AACAASURBVK2UXalWym5laG7etzU+9joN8qijjmLZsmUArFixgjlz5ozctnHjRv76r/8a3/cpFos888wzLFy48E2WXFkmxNqoD9cTSW5mKOfxXMfgWJckIiIiIiKHkb2OrJ122mk8+uijXHjhhRhjuOmmm7jrrruYMmUKp556KmeffTbnn38+oVCIc889l9mzZx+Mug84y7KYV7+QLen1RFybP63bztGT68e6LBEREREROUxYxhhzMJ+wWPQrcuh1d0PCP3j5e/znum9xZPE/WLfN55cfPRbb0lRIqSyaziDVTPmVaqXsSrVSdivDfpsGeThbUL8IgNmT+uhOFVi9bXiMKxIRERERkcOFmrU9mFs3HwuLUHwzjm3x4Evbx7okERERERE5TKhZ24NEKMG05HQ2pF7k7VPqefCl7RzkWaMiIiIiInKYUrO2F4saFvN833OcODPB5oEcL29P7/1OIiIiIiIib5Gatb04Y/JZZP0MQeJpLNBUSBEREREROSjUrO3FvLoFzKmdx//r/AVHTqrlwZd6x7okERERERE5DKhZ2wvLsjh36gdpT73C/KndvLw9zab+7FiXJSIiIiIihzg1a/vg3W2nUROqocd+ENuCnzzbMdYliYiIiIjIIU7N2j6IOBHOmPQ+nu59hP9xRJSfrtjKhl4tNCIiIiIiIgeOmrV9dM6UDxCYgAkTVxALO3ztoQ1jXZKIiIiIiBzC1Kzto4mJSby9+Tge6PwVVx43kcc39vPohr6xLktERERERA5RatZG4dwpH6Q3v51xrS8ypSHGvz+0Hs8PxrosERERERE5BKlZG4V3tBzHrNo5/OdL3+DqpRNo78/ykxVbx7osERERERE5BKlZGwXHcvjkws+wPdfDBv9+jpvWwDcfbWf9di02IiIiIiIi+5eatVFa2HAEp088k5++8mOuPClKLOzw2V+sYjBbHOvSRERERETkEKJm7U24at7fEXGi3NN+O/9y9ny6hvN88dcv4gVmrEsTEREREZFDhJq1N6Ex0sjlcz7C09ufYshZwT+cOpsn2we4bdkrY12aiIiIiIgcItSsvUnnTvkgM2pmctvqf+edc6Ocv6SNHy7fwn1acERERERERPYDNWtvkmO7fG7xFxkoDHDjs1/imndOZemMRv71jy9z7zMdY12eiIiIiIhUOTVrb8Gcunl8cuFnWN77F77/8nf4l3MWcMqsJm55cD33LN8y1uWJiIiIiEgVU7P2Fp05+WzOmnwOP9pwN0/0/JmvvG8+p84Zx78/tIG7ntyEMVp0RERERERERk/N2n7wiQWfZm7dfP7l+RvYnNnIjWfN5/R5zdzxyEb+6TdryBX9sS5RRERERESqjJq1/SDshPnyUTcRdWJ89slr2Jpp53+fOY+rT5zGH9b0cMWPVrBlIDvWZYqIiIiISBVRs7aftMRa+T/H3grAp5/8BFvS7Vxx3BS+9sFFdA3nufQHz/Knl7aPcZUiIiIiIlIt1KztR1OT0/g/x96KMYZPP/kJNqXaOWF6I9+/+G1Mqo/y+ftXc/3v1pLKe2NdqoiIiIiIVDg1a/vZtJrp5YYt4FNPXM1zvc8ysS7Gdy9awhXHTeG3q7v46+8vZ/nmgbEuVUREREREKpiatQNgWs10/v24O6gJ1fKZp67hZ6/ci2tbXH3iNL594RIc2+JjP3meG/+wjsFscazLFRERERGRCqRm7QCZkpzKHSd8l+NbTuT2F/+Dm577Mlkvy+K2Wu659GguOWYSv1q5jb+662l+s7pLS/yLiIiIiMhOnOuvv/76g/mEQWDI5SpvNCkaDe33usJOmFMmvBvXdvnvjfexbNuDLGxYxPh4C8dOa+DkmU08v3WIe5/dylPtA8wcF6elJrJfa5BD34HIrsjBovxKtVJ2pVopu5Uhkdi3z/waWTvAbMvm4lkf5pZjv07Oz/E/H7uKe17+Pr7xmdOS5DsXLeGLp81m80CWD9+zgn/89Yt0DuXGumwRERERERljGlkrO9DfMkyIt3HGpDPZmtnKf7Xfx7O9y5lXv4DGSCPzWmv44JETsG2LX67s4ifPdpArBiwYX0PYVT8te6ZvyKSaKb9SrZRdqVbKbmXY15E1NWtlByO4ESfCyePfxcTEJB7o+B3/tfEn5PwsC+qPIB6K8PYp9Zy5oIW+TJH7VnTyy5XbiIcd5rQksS3rgNYm1UtvulLNlF+pVsquVCtltzLsa7NmmYO8skWx6DMwkDmYT7lP6uvjB7WuwcIA31pzB7/d8itaoq1cPf8TnDz+XVjlpmz1tmG+9tB6nu0YYmpDjI+dOI13zxmnpk12cbCzK7I/Kb9SrZRdqVbKbmVobq7Zp+3UrJWNVXBf6HuO/1h1CxuG17OoYTFXz7+G+fULADDG8PDLvdz56EY29GaY25Lkfy6dxvHTGg96nVK59KYr1Uz5lWql7Eq1UnYrg5q1URrL4PrG53dbfs1/rv0W/YU+Tm17Lx+Z+zFaY+NLtweG36/p5puPtbN1MMc7Zzbx6XfNpK0uOib1SmXRm65UM+VXqpWyK9VK2a0MatZGqRKCm/HS/Gj9D7jvlR8B8FfTL+SimZcQdxMAFP2AHy3v4NuPt2OAy4+dzMXHTCaiRUgOa5WQXZE3S/mVaqXsSrVSdiuDmrVRqqTgdme7+M7ab/DA1t/TEG7girl/yxmTzsKxHAC2DeX4j4c38MC67Uyqj/LZd8/ixOmaGnm4qqTsioyW8ivVStmVaqXsVoZ9bdb2uhpkEAR86Utf4hvf+Ab3338/Rx99NPX19btsc9VVV5FOpzniiCP2+ISH82qQ+yoRSrJ0/Ckc23w8awfX8Iv2n/FE92NMT86gJdZKMuLynrnNHDmxlsdf6efeZ7eyrjvFogm11ETdsS5fDrJKyq7IaCm/Uq2UXalWym5l2G8HxX7ggQcoFArce++9fOYzn+Hmm2/eZZuvfe1rDA4Ojr5K2aN59Qv4j+Pu5ItLrqe/0Mc1T3yMG569jo70FgCOndrAjy47mo8vnc6T7f2c/72n+d6Tmyj6wRhXLiIiIiIib9Vem7Xly5ezdOlSAJYsWcLKlSt3uv13v/sdlmVx8sknH5gKD3OWZXFq23v5vyf/mItnfZjHuv7Mh5ddxL+/8K/05HoIOTaXvWMy911+DCdMb+T2RzbyN3c/w7Nb1DyLiIiIiFSzvc6ZS6VSJJPJkcuO4+B5Hq7rsm7dOn71q1/x9a9/ndtvv32fntBxLOrr42++4gPEceyKrGuHeuJ8etynuOSIv+E/V32Xn738U37f8Rs+sugqPrzgcubVx/nWpY38aW03//tXq/novc/xoaMm8rn3zqUxER7r8uUAqvTsiuyJ8ivVStmVaqXsVpe9NmvJZJJ0Oj1yOQgCXLd0t5///Od0dXVx2WWX0dHRQSgUYuLEiXscZfN9U5E7NVbLzpYhEvztrGs4t+2v+NbaO7jj+dt5aNPDXHvkdUxMTOKo1iQ/uvRovvP4Jn64fAsPrO7imnfO4H0LW3VA7UNUtWRXZHeUX6lWyq5UK2W3Muy3BUYymQwPP/ww73nPe1ixYgXr16/nnHPOAeDEE0/k/PPP54Mf/CBDQ0OccMIJvO9979vjE2qBkf0jGarhnRPezaTEZH6/5Tf8YtN/UReuY3btXEKOzbFTGzhl9jhWbRvmJ89u5elNA8xvTdKkUbZDTrVlV+S1lF+pVsquVCtltzLstwVGTjvtNMLhMBdeeCFf+cpXuPbaa7nrrrv44x//+JaLlLfu1Lb38t2ldzO/fgFfXfmvfOapT4wsQDJrXIJvXnAk//TeObzSm+GSu5/hlj+9zHDOG+OqRURERERkb3SctbJqHxIOTMBvNt/PN9fcTjEoctnsKzl/+kU4dmnK6mC2yJ2PbuS/nuukIR7i6hOncfai8Ti2pkZWu2rPrhzelF+pVsquVCtltzLooNijdKgEd3uuh6+v+iqPdD3MrNo5fPaIa5lTN3fk9jVdw/zrH9fzQucQM5riXHPyDE6Y3oCl/dmq1qGSXTk8Kb9SrZRdqVbKbmVQszZKh1pwl217iFtXfZX+fB/nTb+QD8/5CFEnCoAxhj+9tJ3b/vwKWwZyHDOlnk+ePJ15rfsWGqksh1p25fCi/Eq1UnalWim7lUHN2igdisFNFYf55prb+fXm+2mNjeey2VdyWtvpI1Mji37Az57r5DuPtzOY8/gf81v4u5OmMb42OsaVy2gcitmVw4fyK9VK2ZVqpexWBjVro3QoB/e53me548Wv89LQWqYkpvLhOR/h5PHvwrZK68sM5zy+99RmfvxMaWGSDyyewMXHTFLTViUO5ezKoU/5lWql7Eq1UnYrg5q1UTrUg2uM4c9dD3PXum/TnnqFtzUdzecWf5HW2PiRbbYN5fjWY+385sVuAM6Y38Klb5/EjKbEWJUt++BQz64c2pRfqVbKrlQrZbcyqFkbpcMluL7x+e3mX3Lni7dhWxafWPhpTms7Y6cFRrYN5bhneQf//XwnOS/gnTObuOwdkzmirXYMK5c3crhkVw5Nyq9UK2VXqpWyWxnUrI3S4RbcrZkO/uW5G3mh/zlObD2Zq+d/grb4xJ22GcgW+cmzHfzk2a0M5jyOmlTHZe+YzPHTtHpkJTncsiuHFuVXqpWyK9VK2a0MatZG6XAMrm987nvlx3z/pe/iBR7vn/ohLp51ObXhnUfQMgWfn7/QyQ+f3kJ3qsDs5gQffsdk3j2nGVfHaRtzh2N25dCh/Eq1UnalWim7lUHN2igdzsHdnuvhe+u+w++2/Jq4m+DiWZfx/qnnEXbCO21X9AN+92I33//LZjb2ZWmrjXDOEeN538LxtNZExqh6OZyzK9VP+ZVqpexKtVJ2K4OatVFScGHD0Hq+tfZ2nup5gvGxCVw5929514T3jKwauUNgDMte7uXeFVt5etMAtgXHT2vk3CPGs3RGI65jv8EzyIGg7Eo1U36lWim7Uq2U3cqgZm2UFNxXLd/+F7655jZeHnqJuXXzuGz2Rzi2+fjd7qe2ZSDLL1du45eruuhJFWiMhzhrQStnLxrP9Kb4GFR/+FF2pZopv1KtlF2pVspuZVCzNkoK7s4CE/BAx+/53kvfYVu2k7l187ls9pVv2LR5geGJjX384oVt/HlDH35gmNoQY+nMJk6e2cQRbbXav+0AUXalmim/Uq2UXalWym5lULM2Sgru7hWDIn/o+C0/fPn/si3byZTEVM6YdBanTTyDpui43d6nN13gj+t6+PP6Pp7ePIAXGOqiLifOaOTkmU0cO7WBZMQ9yK/k0KXsSjVTfqVaKbtSrZTdyqBmbZQU3D0rBkX+uPUP/GbzL1nZ/zy25XBc8/FcMuty5tbPf8P7pfIeT7b3s2x9L49u6GMw5+HaFsdMri+PujUyvjZ6EF/JoUfZlWqm/Eq1UnalWim7lUHN2igpuPtuU6qd32/5Db/e/AuGikOc0HISH57zEWbVztnj/bzA8MLWIZat72XZ+l429WcBmNIQY8nEWo6cWMfitlqmNMSwdRy3fabsSjVTfqVaKbtSrZTdyqBmbZQU3NFLF9P8V/tPuG/Dj0l5wyyoX8SxLcdzbPPxzKqds8sqkq+3sS/DIxv6eGbzAM9vHWIw5wEQC9nMbk4ypznBnJYkc1qSzGyKEw05B+NlVR1lV6qZ8ivVStmVaqXsVgY1a6Ok4L55qeIwP2//GY92LWPt4BoAmiLjOGXCqZw28XRm187d7aIkrxUYw8a+DCu3DrOuJ8W67hTretKkCz4AtgVTG+PMaU4wtyXJ7OYEUxvjNCcjh/3CJcquVDPlV6qVsivVStmtDGrWRknB3T/68338ZfuTPLJtGU/2PEYxKDI5MYW3Nx/HvLr5zKtfwMT4pL02b1Bq4LYO5ljXky41b+UGrms4P7KNY0FzMsKE2ggT6qKMr40yoSbChNoo42sjjK+NEnEP7eO+KbtSzZRfqVbKrlQrZbcyqFkbJQV3/xsuDvFw54M82PkALw6sIufnAKgP17O09RROaTuVxY1LcKzRTW8cyBZ5qSfFloEc24ZydA7lR067U3mC1yW6MR6iMR6mIR6iMR6iIR4uncZK5+tjLnWxEPWxELVRt+r2l1N2pZopv1KtlF2pVspuZVCzNkoK7oHlBx4bUxtZM7iaZ7b/hce7HyXn52iMNHFU09HMLY+6zaiZScSJ7nV/tzfi+QHdqQKdQzm2DeXpHMrRNZynP1OkL1OkP1ugP1McmV75erYFNRGX+nLzVhcLURd1R87Xx1zqoqXzibBDPOyQDLvEww7hMRrBU3almim/Uq2UXalWym5lULM2SgruwZX1sjzZ8zgPd/6Jlf3P05vfvtPtITtE2A4zMT6ZBQ2LWNiwiLl182mKjCPmxt7y8+eKPgPZUgM3mCsykC0ykPUYzJbOj5zmXr2u4O/5n0rIsYiHHBIRl0TYGWnmEuVmLjHy85rLEZdEyCERcYiFHGzLwrLAAkKOTTzsEHHtPY72KbtSzZRfqVbKrlQrZbcyqFkbJQV3bPXkelg7sJrN6U0UggIFv0DOz/JKagNrBl4k52dHto05cRoiDUxKTGZGzUxm1MxianIaDZFG6sL1hOzQfq/PGEPOC3Zq4tIFn0zBI1PwSe/4yXtkij7pvE+6WL5cvi1T8MkUdz+itzfxkENt1B0Z6dsximcMhMMOUduirjyNMxF2CDk2Eccm5FqlU8cm7NqEHZuwYxF2S9dFdpw6NqHy9TsaQ2MMBd+QK/qEHJtYyN6nfQ1FRkPvvVKtlF2pVspuZdjXZs09wHWI7JPmaDPN49+529v8wGPD8Ho2DK+nL99Lf76P3nwvm9ObeLZ3OcWguNP2CTdJwk0QdiJE7AhRN0pdqI76cAN14Xrqw/XUlX8SoSQFP0/ez5MPSvvUuZaLa4cI2SFc2yVkhcqXXRzbpa4mREOtTTEokvfzFIICNaEaxscm49p7/iflB4Zs8dXmLV3wRhq9bMEnMAYDBMGrjVK2WGryXjvKN5AtYlkWtgVWzmYgnR9pIN8q17ZwbYuCH+y0/1/EtUf26/MCQ77ok/MCbMuiJuKSjLjURl2SEYea8nnHtsh7hoIfUPQDYiFnZFQxWm4MHbv0kwg7JCMuybBLNGTjlOvYcbtT3va111Xb/oUiIiIio6FmTSqeY7vMrpvL7Lq5u9zmBR6b05vYnN7EQL6fwcIA/YV+sl6GQlBqwrJ+lm3ZbawdXMNgYQDPeAemTsthQqyN1th4fHyKQZGiX6QYFCgGRQpBAYCm6Diaoy20RFtojrXSGm1lQl0rCTfBxtQrrB96iZeHXsKxHKbXz2BuzUza4hMpBAXSxRQZL03aS5Hy0qSLKZwwtLoTmVk7m0mxKRR9h55cH12ZLvrz/bjECNs1hEiSLmbpznXQnetkqNhP3G6ixp5A3JqA8UOkvRRpf5icn6MmVE99qJFYKITnG/qzRfqzRQazOXy3m6KzhZy9GWNswt5UTH4KfZka2vs9hnMew3mPwJSmh4YdG9e2yHkBeS/Y91+qncMO9WK8OoyfoDRBtHS9E9uEE9uMExrADg1huYNYJoqdWYybPRLXNBIL2cRCzkiT6LgZUu4zDFovEg4mEMotJJ+ZgG05jK+JML42QmtN6XAQgQFDaYTRmNLqpEDp+nJT7drWSGOajLiEnXKT6ezaXLqvazRd235NI4pGLUVERGQXmgZZpiHhw4MxhrSXZrAwwGBhgLSXIuxEiNpRwk4ECwvPFCkGHl5QpBgU8YxXOg2KeIFH0RTxjU/YDhOxI4SdMIOFQbakN7ElvYWeXBeO5RIqj86F7PDIPngA23M9dOe66M52kQ/yu9RoYzM5OYXABHSktxDwxs2NjY1jOyOji47lYFv2LqONb5aNTVN0HBEnSt7PkfdzpL00vimN4IXsMGBGnq8x0kTciWNbdrkWB9cun1ouDZFGGiPjqHUbwbikisPl5jNNMfDxfPACGC72011oZ9jvGaklYiWoddrwTZF+v51Su2QRteqIWg1ErAaywXaGzCYAaphBKGjEBBGCIEyObeRDa8EKwKsDZwgsg2tqiQaTyXsBec8nMAGWk8NyMlhOBjAEXh2mWIvxajFBBIyLMS4EYYwff/XHuGCc0g+A5WFZPth5nMg27NgWnNhmsAoE2Sn42Wn42cmAheNmcdwMtpPBdjPl589iWRYWNhYOtolgeY0YrwFTbCBsJ4g5MaJOjLibIB4KE3VLDaptQ8EMMWBeJmu6MAQYSn+3hN1EgzuZpvAkEqE4YWfHtFiLkANYOXwrg2UZkqFaEk4Ndnkk0y43lhaMnLctKJoCvfmt9OS34lFgSeORTK2dODJ91hgzMlJrv6Y53dt7b2dmK7/b8ms2DL/MgvpFvK3paGbXzR31KrIHih94BJgDMv1aKpcxhoaGhD43SFXSZ97KoH3WRknBlYPNGMNQcYieXBfd2W6Gi0NMSU4rr4gZAaDg59mUbqcz00nUiZBwk8TdBIlQkqSbIOrEqKuPsXpraTRu/dA6fOPTHG2lJdZCXbiBjJdmqDDIUHGQsB2mLT6JtvhEGiKNdGU7SyOTqU3l6Zy11IZqibpR+vN9dOe66cl2UwjyRJ0YYSdC3IkzrWY6s2rnMCUxBd8ErB9+idX9K3l56CWKQamZ3fETlE+LQbE8hXU7aS898ntIuAlibhwbG1P+r8atYXrNTGbUzKQtMYneXA+b0pvYnGrHtmwWNSzmiMYjmV+/gLib2On3uiW9mYc7/8RTPU8wWBgg42fIehnqwvWcMuFU3jXhVGbUzGKoOMhTPU/wRPdjbM10YFFqQAJjEXcT1ITqqAnVABZ9+R768tvpK2wfmfpa8PN7bKR3p9ZppTk0E4cwXcV1DPpbd7udTYgQSVxKo4kBHsYEeGTwrOE3CJSFHdRi+fUYr4Yg1A2h7j3WY4yF8eMAWFYABGAXsCzzuu0cjJfA+AmMl8T4SUzgYrspLHcYyx3CDg3t8vhBoQk/PbO0ffk6y/KwnBR2KIXtpLGIYPk12EEtjqnBwcW2HGwLCpFV5EPrwFg4QSO+01t6jCCGE9RjE8KxQljYpQbYyhNYeeJWK832Isa7R1LntJHiFfqCl+j11+FTIGTt+BIlRsxqJEoTYRqI200krHGE7TiObWNZlKbaGoNlMXKdZQX0m1Wszz3Ki8NPkAsyuFaIsBUnbMeJ2DEidpyoE6c5MolpiXnMSM5jXKSFkFMaTTXk2ZbfxPrUSl4aWkVPfhtvazqGk8e/kwUNC7EtG2MMA4V+OtJbylPBX2bD8AbqwnWc2LqU45pPoD7SAEAxKNKd7cK1XcZFm/dLMztUGGJTuh3HspmcmEIyVPpgkfWyrOp/gef7VxCYgNm1c5hVO4e2+MTdjhBnvSwDhf6RL2YyXpqkW8OsujlEnehbrnNvdnzMeX1tfuDRkenAtux9Pv7nYGGA327+Ffdv+m98PD486ypOn3Tmm17BWOTNynpZ2lOvMK1mxqj/Hekzb2VQszZKCq5Uq2rMbtbLUAw8EqFExYyQvBl5P19uhIcYLg5RCAp45VFZgyFsRwjZISJOhCnJqdSF63e6/0C+n3VDa3Etl9pwLbWhOmrDdXv8H2/Oz9GV3UZXdhvpYoqsnyXnZxkqDNGd66In2832fA8T4hM5omExixoWM71mJmE7hF3+XXdmtrIx9QobhzfQle3GGAuwMMYiZMWJ2gnCdgITOKS8QYa9flLFQYa9AVLeAGl/kGJQIOk2kHTrSTqN1LstNITbaHAnEAQ269PPszH7PNsKqylS2h+09CwuUauOiFVLiBp8q0DW7ydPPz47jzSHzTga/RNp9I8nTCOeNUzKXkPKWkeRYTxTJKBAYAJMEC7/uPihDkx410bYz7dg/DiW5YFVLI2gusPlRvVVxo+Upt1aRSw7D3axVH0QxgQRLDuP5eQwfhRveCFBoQnK11l2rnSf8nk7vB3L9sqPGwN8sIs7NcRBoZGgWIcT34Rl+QTFWgjiWKE+LLvwmrqi+PlW7NAAdmgQjIVVHI+x0+AMw47HNDZu0ECIRqwgDCYEJkRgTOn3ZRUwFMt1FEuv07KwieAQwrYscvTs8sVAmDrC1JJmKwa/1CRjjYzYOkRwrRgOYRzCBBTJmYFd/q47WFjUO5NpdKfhmBowYQI/jEuMuBsnGYoTdUMMBR30eq/QW2wnH6QI2VHCVqx8GiVsxwjbUSJ2jKgbI+bECdku2wtb2ZbbSHe+nWKQJ+k2kXSaiNo1DPld9BU78E1pVkBdqIm5NYuZV7eYwECqmCLtpcn7ufKodEDaG+SFwSfwTJFF9W/D2B6r+l5gRnI2F8/4W2pDjXTnutie68EzBZpjjbTEmhgXa6Ih3EBtuA7bssn5OZ7Z/jSPdf+ZZ7cvJ+JEGBdtpjnawvjYBKYkZjIpPp36UAv5IENXbgvbcpvpzXUz7A2TLtfWFB3H5MRkJiem0hobTzJUQ9JNYFsOWzMdrB18kTUDq+nN91Ibrivtrx2qL30RQIBvArygSM7PkfOzZL0sffk+enLd9ORKX/QsbjyStzUdw5Kmo6gJ1VAISlP7U8UU2zJb6cx20pXdhsGMzDSJO/Hy/uEN1IXr8I1PxsuQ8dJYll2ueQphJ4IfeGxKb+LloXX05ntpjbYyPj6B8bEJ1IXrd2mCC36evnxf6fmcCGE7gmPZZMuvIeeVT/0cWT9b+lLNBPiUZk1kvDSDhUEGCwP4xmdmzWzm1s9nZs1MUl6atQMvsnbwRXrz25lbN5/FjUcyOTEVy7LwA4++fB8pb5jaUB114Xpc26UYFOnMdLA5vYneXC81oZryfvF1AGT9HFkvg8HQHG2mJTqeRGjnLxn3lR94PNP7NP+v4/c80rWMnJ/FtVzm1S/gyMYlTExMJurEiDoRwKIzs5Ut6U10ZDqoDdVwZNNRLGk8igVts1nftan8Je9LBASMj02gNTaepsg44lt9kQAADiRJREFUTHnGzI4vWbdlt9KZ6aQv30tDpIFx5V05Ik6klAm/gI9PjVtLfaT0tw/ZITzj4Qc+eT8/MqOoO9eFBYyPtzEh1kZLrJWQHcKmNAvDMx5ZLzvyd7SwsC0b23KoCdXQEm3dZVVwYwyd2a2s6n+BVf0v0J7ayMza2Rzd9HaObFqyy5e6lULN2ihV4wdeEVB2pbq9Nr8Fv4BvvJH/we/4cPtm9OV7Wb79L3SktzCnbh7z6xYRd2sp+gFeYPD8AN+AaxsyQT8Dhe305LfRne2mO9vFYGGASHmKadSJ4RufrJcl42WwsFhQexxTIkeSyts4NiOL7MRCDn5gKAYBRd+QLeZoT2/glfSLbMtuwiaMY0VwiFDjtNISmkeEOoq+IV1M0V54hs35v+CZInGrhag1jjgtNLhTqAs1E3Ft/MDQld/A5sLT9AXrCVNHxDQRoRHf+KSC7WRNDwX6MVYBrCLGKpY+9JQbKdsKY5kQmDAELoExeKaAT54AH9sbh+O1YHktGGPw3W34bjfGHsQqTsTKzYTcNALjYNxtmPAWTGgb2AVMuQE0gVMa5fWSBF4SE0RLjXAQwXJTONEtOLEt2JHOcqP7xtO3g2ItQa6t1ETb5SbaKmDZhXJD/ZrTctNaam7HE+RbIYhgueV9W900pthAkG/Fz7diWR5OfANOYj22mxp5TmNsCEKAXTpvHLzUAop9xxMUWgGDW/sckZbflprnvSiNZCdKzb5dhCCKnZtdmiLsDII7iOW+OkJtAnek0X/1uhAEMawgAu4gvKaZf3UjByx/5DHw67DsDDjZXbcduY+LbcI4phbX1OOaBsAj46zDt/f82mwTxcIhoPy33ycWMauJghnCZzevAcBYuFacsJXEtVxyZoCCSe9+21GxiNo1gCEXDJevKTWwO85H7Di5oJSFuFOHjUPaHxjZZoeEmyTrZwnM6Bb3SrhJkm4tcTdOzI2XmytDQFBafdrPki6mSXnDZLxMeZZKUJ7+D0m3hpNaT2Fh/dt4eeglVg2sYMPw2t3O9oi7cdrik+jNbae/0DdyXcYb3eeGkB2mIdzAYGFgt7tw7CvHckoLqY3yd/ZataE6xkXHkffzpX3tvfTI7hhxN87kxFReGV5PISjgWA6Xzr6CS2Zd/qaf70BRszZK+sAr1UrZlWqm/B5eduy7uON0x8I9Ybf0YTnrZcn6WbJemlQxw3A+x/jYJOpCDaXxLbP7xzCG0iq1nk/Gy5Et5km4SUKOXVrMx7FwrdLiP7ZlUfSD8n6qr/7kih49+S7CToiaUJK4G8O17ZHn9YPSCr07DsPihFyKBQ9jFWjPPYFrh6lzx1EbGodlXPoLAwwW+hkq9pM3gxTMEHkzhGNFGGctocbMwfNtXMcqHV7FsbGdPGnTQcpsZjDoIGbVkbTbSFhtREwTgXEp+qUvAoIgIE8/adNFzvSWpkmTxTM5EnYrDc5M6uyJgFtehTjPcHEYPwgAC4wN2FgmDJQ+QFNePMmMLLAUULC7ydovEVhFLBPCMg4WURy/CSdowgpi5b8t5d9VHt8eJrBTBFa69DxBBEwU33jk2EbR2Ybv9JQa+VwbfnYi+LUkE2lisUFCkQGKDJM3KQomhW+KGK+mtN+wV4PBKo2Q20UgAFMaWSfYcRrCmPIpNhgLsEv7HPsxwAYMljtY+sIg2oHx4wTZSfi5iWBCWOHtuLGNOPGNAATFuvJiV9HS/sRuCstJYYIYQWEcQb4Z49WVRtfdNJaTBqyRuoDSlwWhAezQAJaTLY3I24XSCHd5Mr5l2VgmhG3iOESxTJQgcPADCAKLYm48+aG5YF63RqBVKNVkFUlEfRIRiwjNhKkl7Dh4QUDabCXrrKPodlLMjqOQmYCfnwDGIRYbJBEfJhJJE3Kc8r72IUJWkohpxjG1WNgEBPhkKFp9BMbDJkRpvUIbnzQ+KTxrCGN5YBwsXGxC1IWaaIq00BIdRyRkkzN9ZEwPmaCvtB5A4OMHAZZlE7PjRN0YETtCMQgo+KXb094ww34Pab+XvOknZEeJ2nFibpJ6t4Up8XlMik8jEQ6T8/JsTK9mQ/Y5TpjwNj4w69QD9r72ZqlZGyV9YJBqpexKNVN+pVopuwfXjlV4g3I3ueO8eU2D+eqqvaUGvtR07ny/nVb63WXbV1cAfu1tO/ZftS3wjSkdQidTWiHZ83fsEwk7Viy2rPK07/JukNarG5Sng5cep+ibkea76AcUfINXHpUv+AFeeSZAuHys1B1N/Y7jpYZHjqFaavhzXkB/pkB/pnSIn9c+vmNbxEI2kZBDfSKCFQSly26pkRvKeQzmPFI5r/QFRvkLjd21Ca/dv9MauY5drttxLjCG4bzHUM5jKFfc6bBAr2Vbr/4dXs+xLaLl11w6RmxphelM+VBIe2pmzl00nn88fc4ethgbOs6aiIiIiBwSXrsK7WvbARm9sfyiISg3qYEx+EHpNFRekdi1SysH+4Eh7wcUPUPItYi4Dq79xn9zYww5Lxg5hm226I8cNijs2DQlwgfxFe5/atZEREREROSAsy2LiPvGjZdVnq7sOjbsY49lWdbIMVWpzLVE3hKtNSsiIiIiIlKB1KyJiIiIiIhUIDVrIiIiIiIiFUjNmoiIiIiISAVSsyYiIiIiIlKB1KyJiIiIiIhUoL02a0EQcN1113HBBRdwySWX0N7evtPtP/zhD/nQhz7Eeeedx4MPPnjAChURERERETmc7PU4aw888ACFQoF7772XFStWcPPNN3PnnXcC0NfXxz333MPPf/5z8vk8Z511FqeccspORzYXERERERGR0dtrs7Z8+XKWLl0KwJIlS1i5cuXIbY2NjfziF7/AdV06Ojqora3da6PmOBb19fG3WPb+5zh2RdYlsjfKrlQz5VeqlbIr1UrZrS57bdZSqRTJZHLksuM4eJ6H65bu6rouP/jBD7j11lu55JJL9vqEvm8YGMi8hZIPjPr6eEXWJbI3yq5UM+VXqpWyK9VK2a0Mzc01+7TdXpu1ZDJJOp0euRwEwUijtsPFF1/M+eefz1VXXcUTTzzBcccd94aPFwo5+1zcwVapdYnsjbIr1Uz5lWql7Eq1Unarx14XGDnqqKNYtmwZACtWrGDOnDkjt23YsIGPf/zjGGMIhUKEw2FsWwtMioiIiIiIvFV7HVk77bTTePTRR7nwwgsxxnDTTTdx1113MWXKFE499VTmzZvHBRdcgGVZLF26lHe84x0Ho24REREREZFDmmWMMWNdhIiIiIiIiOxMcxZFREREREQqkJo1ERERERGRCqRmTUREREREpALtdYGRQ10QBFx//fWsXbuWcDjMjTfeyNSpU8e6LJE39P73v5+amtKSu5MmTeKCCy7gn//5n3Ech5NOOomPf/zjY1yhyK6ee+45brnlFu6++27a29v5h3/4ByzLYvbs2XzpS1/Ctm1uu+02HnroIVzX5Qtf+AKLFy8e67JFdsruqlWr+NjHPsa0adMAuOiiizjzzDOVXakoxWKRL3zhC3R0dFAoFLj66quZNWuW3ner1GHfrD3wwAMUCgXuvfdeVqxYwc0338ydd9451mWJ7FY+nwfg7rvvHrnu3HPP5dZbb2Xy5Ml89KMfZdWqVSxcuHCsShTZxbe//W3uv/9+YrEYAF/5ylf41Kc+xbHHHst1113HH//4R9ra2njqqae477776Ozs5BOf+AQ/+9nPxrhyOdy9PrurV6/m8ssv54orrhjZZtWqVcquVJT777+f+vp6/u3f/o3+/n4+8IEPMG/ePL3vVqnDfhrk8uXLWbp0KQBLlixh5cqVY1yRyBtbs2YN2WyWK664gksvvZS//OUvFAoFpkyZgmVZnHTSSTz++ONjXabITqZMmcKtt946cnnVqlUjh3k5+eSTeeyxx1i+fDknnXQSlmXR1taG7/v09fWNVckiwK7ZXblyJQ899BB/8zd/wxe+8AVSqZSyKxXnjDPO4JOf/OTIZcdx9L5bxQ77Zi2VSpFMJkcuO46D53ljWJHIG4tGo1x55ZV897vf5ctf/jLXXnvtyDe+AIlEguHh4TGsUGRXp59+Oq776kQOYwyWZQGvZvb178XKslSC12d38eLFfO5zn+OHP/whkydP5vbbb1d2peIkEgmSySSpVIprrrmGT33qU3rfrWKHfbOWTCZJp9Mjl4Mg2OmNWaSSTJ8+nXPOOQfLspg+fTo1NTUMDAyM3J5Op6mtrR3DCkX2zrZf/V/Pjsy+/r04nU6P7JspUilOO+00Fi1aNHJ+9erVyq5UpM7OTi699FLOPfdczj77bL3vVrHDvlk76qijWLZsGQArVqxgzpw5Y1yRyBv76U9/ys033wxAV1cX2WyWeDzOpk2bMMbwyCOPcMwxx4xxlSJ7tmDBAp588kkAli1bxjHHHMNRRx3FI488QhAEbN26lSAIaGxsHONKRXZ25ZVX8vzzzwPw+OOPs3DhQmVXKs727du54oor+Pu//3vOO+88QO+71eywH0I67bTTePTRR7nwwgsxxnDTTTeNdUkib+i8887j2muv5aKLLsKyLG666SZs2+azn/0svu9z0kknceSRR451mSJ79PnPf55/+qd/4qtf/SozZszg9NNPx3EcjjnmGC644AKCIOC6664b6zJFdnH99ddzww03EAqFGDduHDfccAPJZFLZlYryjW98g6GhIe644w7uuOMOAL74xS9y44036n23ClnGGDPWRYiIiIiIiMjODvtpkCIiIiIiIpVIzZqIiIiIiEgFUrMmIiIiIiJSgdSsiYiIiIiIVCA1ayIiIiIiIhVIzZqIiIiIiEgFUrMmIiIiIiJSgdSsiYiIiIiIVKD/DzHORKeBmmnYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_2.plot(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the DFF_NN (Using only Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1000\n",
      "8000/8000 [==============================] - 7s 873us/sample - loss: 0.6974 - acc: 0.6676 - val_loss: 0.5773 - val_acc: 0.7390\n",
      "Epoch 2/1000\n",
      "8000/8000 [==============================] - 1s 131us/sample - loss: 0.6144 - acc: 0.7461 - val_loss: 0.5372 - val_acc: 0.7845\n",
      "Epoch 3/1000\n",
      "8000/8000 [==============================] - 1s 105us/sample - loss: 0.5803 - acc: 0.7764 - val_loss: 0.5130 - val_acc: 0.7995\n",
      "Epoch 4/1000\n",
      "8000/8000 [==============================] - 1s 108us/sample - loss: 0.5503 - acc: 0.7856 - val_loss: 0.4943 - val_acc: 0.7980\n",
      "Epoch 5/1000\n",
      "8000/8000 [==============================] - 1s 129us/sample - loss: 0.5441 - acc: 0.7950 - val_loss: 0.4816 - val_acc: 0.7990\n",
      "Epoch 6/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.5272 - acc: 0.7926 - val_loss: 0.4734 - val_acc: 0.7985\n",
      "Epoch 7/1000\n",
      "8000/8000 [==============================] - 1s 117us/sample - loss: 0.5131 - acc: 0.7965 - val_loss: 0.4637 - val_acc: 0.7975\n",
      "Epoch 8/1000\n",
      "8000/8000 [==============================] - 1s 99us/sample - loss: 0.5117 - acc: 0.7960 - val_loss: 0.4586 - val_acc: 0.7980\n",
      "Epoch 9/1000\n",
      "8000/8000 [==============================] - 1s 110us/sample - loss: 0.5021 - acc: 0.7971 - val_loss: 0.4544 - val_acc: 0.7980\n",
      "Epoch 10/1000\n",
      "8000/8000 [==============================] - 1s 141us/sample - loss: 0.5001 - acc: 0.7975 - val_loss: 0.4509 - val_acc: 0.7980\n",
      "Epoch 11/1000\n",
      "8000/8000 [==============================] - 1s 104us/sample - loss: 0.4938 - acc: 0.7966 - val_loss: 0.4484 - val_acc: 0.7980\n",
      "Epoch 12/1000\n",
      "8000/8000 [==============================] - 1s 100us/sample - loss: 0.4823 - acc: 0.7991 - val_loss: 0.4445 - val_acc: 0.7980\n",
      "Epoch 13/1000\n",
      "8000/8000 [==============================] - 1s 98us/sample - loss: 0.4862 - acc: 0.8002 - val_loss: 0.4427 - val_acc: 0.7980\n",
      "Epoch 14/1000\n",
      "8000/8000 [==============================] - 1s 119us/sample - loss: 0.4826 - acc: 0.7997 - val_loss: 0.4407 - val_acc: 0.7980\n",
      "Epoch 15/1000\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 0.4829 - acc: 0.7996 - val_loss: 0.4388 - val_acc: 0.7980\n",
      "Epoch 16/1000\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.4787 - acc: 0.8036 - val_loss: 0.4358 - val_acc: 0.7980\n",
      "Epoch 17/1000\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.4754 - acc: 0.8034 - val_loss: 0.4334 - val_acc: 0.7975\n",
      "Epoch 18/1000\n",
      "8000/8000 [==============================] - 1s 107us/sample - loss: 0.4707 - acc: 0.8054 - val_loss: 0.4291 - val_acc: 0.8020\n",
      "Epoch 19/1000\n",
      "8000/8000 [==============================] - 1s 89us/sample - loss: 0.4679 - acc: 0.8076 - val_loss: 0.4266 - val_acc: 0.8010\n",
      "Epoch 20/1000\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.4643 - acc: 0.8080 - val_loss: 0.4235 - val_acc: 0.7995\n",
      "Epoch 21/1000\n",
      "8000/8000 [==============================] - 1s 93us/sample - loss: 0.4605 - acc: 0.8065 - val_loss: 0.4208 - val_acc: 0.8010\n",
      "Epoch 22/1000\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.4614 - acc: 0.8081 - val_loss: 0.4192 - val_acc: 0.8045\n",
      "Epoch 23/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.4535 - acc: 0.8112 - val_loss: 0.4151 - val_acc: 0.8085\n",
      "Epoch 24/1000\n",
      "8000/8000 [==============================] - 1s 89us/sample - loss: 0.4590 - acc: 0.8100 - val_loss: 0.4159 - val_acc: 0.8065\n",
      "Epoch 25/1000\n",
      "8000/8000 [==============================] - 1s 121us/sample - loss: 0.4541 - acc: 0.8138 - val_loss: 0.4129 - val_acc: 0.8105\n",
      "Epoch 26/1000\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.4509 - acc: 0.8155 - val_loss: 0.4109 - val_acc: 0.8115\n",
      "Epoch 27/1000\n",
      "8000/8000 [==============================] - 1s 95us/sample - loss: 0.4519 - acc: 0.8127 - val_loss: 0.4098 - val_acc: 0.8100\n",
      "Epoch 28/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.4559 - acc: 0.8105 - val_loss: 0.4093 - val_acc: 0.8110\n",
      "Epoch 29/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.4481 - acc: 0.8134 - val_loss: 0.4079 - val_acc: 0.8125\n",
      "Epoch 30/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.4486 - acc: 0.8129 - val_loss: 0.4057 - val_acc: 0.8135\n",
      "Epoch 31/1000\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.4446 - acc: 0.8177 - val_loss: 0.4038 - val_acc: 0.8160\n",
      "Epoch 32/1000\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.4436 - acc: 0.8180 - val_loss: 0.4011 - val_acc: 0.8170\n",
      "Epoch 33/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.4431 - acc: 0.8139 - val_loss: 0.4000 - val_acc: 0.8160\n",
      "Epoch 34/1000\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.4394 - acc: 0.8160 - val_loss: 0.3981 - val_acc: 0.8175\n",
      "Epoch 35/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.4399 - acc: 0.8189 - val_loss: 0.3966 - val_acc: 0.8200\n",
      "Epoch 36/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.4387 - acc: 0.8199 - val_loss: 0.3935 - val_acc: 0.8240\n",
      "Epoch 37/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.4354 - acc: 0.8216 - val_loss: 0.3921 - val_acc: 0.8225\n",
      "Epoch 38/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.4286 - acc: 0.8227 - val_loss: 0.3893 - val_acc: 0.8225\n",
      "Epoch 39/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4358 - acc: 0.8206 - val_loss: 0.3890 - val_acc: 0.8225\n",
      "Epoch 40/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4357 - acc: 0.8198 - val_loss: 0.3897 - val_acc: 0.8230\n",
      "Epoch 41/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4285 - acc: 0.8246 - val_loss: 0.3873 - val_acc: 0.8235\n",
      "Epoch 42/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4275 - acc: 0.8249 - val_loss: 0.3855 - val_acc: 0.8225\n",
      "Epoch 43/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4294 - acc: 0.8244 - val_loss: 0.3858 - val_acc: 0.8235\n",
      "Epoch 44/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4293 - acc: 0.8234 - val_loss: 0.3842 - val_acc: 0.8235\n",
      "Epoch 45/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.4238 - acc: 0.8264 - val_loss: 0.3832 - val_acc: 0.8235\n",
      "Epoch 46/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4252 - acc: 0.8263 - val_loss: 0.3818 - val_acc: 0.8250\n",
      "Epoch 47/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.4239 - acc: 0.8254 - val_loss: 0.3811 - val_acc: 0.8255\n",
      "Epoch 48/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4261 - acc: 0.8255 - val_loss: 0.3816 - val_acc: 0.8245\n",
      "Epoch 49/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.4215 - acc: 0.8250 - val_loss: 0.3807 - val_acc: 0.8245\n",
      "Epoch 50/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4195 - acc: 0.8274 - val_loss: 0.3787 - val_acc: 0.8270\n",
      "Epoch 51/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4286 - acc: 0.8224 - val_loss: 0.3801 - val_acc: 0.8240\n",
      "Epoch 52/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4291 - acc: 0.8198 - val_loss: 0.3807 - val_acc: 0.8240\n",
      "Epoch 53/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4187 - acc: 0.8290 - val_loss: 0.3785 - val_acc: 0.8245\n",
      "Epoch 54/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4229 - acc: 0.8261 - val_loss: 0.3798 - val_acc: 0.8250\n",
      "Epoch 55/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4198 - acc: 0.8263 - val_loss: 0.3766 - val_acc: 0.8275\n",
      "Epoch 56/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4220 - acc: 0.8279 - val_loss: 0.3763 - val_acc: 0.8280\n",
      "Epoch 57/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4229 - acc: 0.8229 - val_loss: 0.3770 - val_acc: 0.8270\n",
      "Epoch 58/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4231 - acc: 0.8299 - val_loss: 0.3777 - val_acc: 0.8270\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4211 - acc: 0.8269 - val_loss: 0.3771 - val_acc: 0.8265\n",
      "Epoch 60/1000\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.4208 - acc: 0.8289 - val_loss: 0.3760 - val_acc: 0.8270\n",
      "Epoch 61/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4207 - acc: 0.8270 - val_loss: 0.3754 - val_acc: 0.8285\n",
      "Epoch 62/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4218 - acc: 0.8289 - val_loss: 0.3758 - val_acc: 0.8290\n",
      "Epoch 63/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4185 - acc: 0.8309 - val_loss: 0.3759 - val_acc: 0.8285\n",
      "Epoch 64/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4220 - acc: 0.8282 - val_loss: 0.3758 - val_acc: 0.8285\n",
      "Epoch 65/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4194 - acc: 0.8270 - val_loss: 0.3753 - val_acc: 0.8270\n",
      "Epoch 66/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4213 - acc: 0.8280 - val_loss: 0.3765 - val_acc: 0.8265\n",
      "Epoch 67/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4209 - acc: 0.8260 - val_loss: 0.3760 - val_acc: 0.8265\n",
      "Epoch 68/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4171 - acc: 0.827 - 0s 45us/sample - loss: 0.4166 - acc: 0.8274 - val_loss: 0.3739 - val_acc: 0.8280\n",
      "Epoch 69/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4212 - acc: 0.8276 - val_loss: 0.3741 - val_acc: 0.8265\n",
      "Epoch 70/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4183 - acc: 0.8276 - val_loss: 0.3747 - val_acc: 0.8275\n",
      "Epoch 71/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4205 - acc: 0.8257 - val_loss: 0.3733 - val_acc: 0.8280\n",
      "Epoch 72/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.4229 - acc: 0.8256 - val_loss: 0.3743 - val_acc: 0.8255\n",
      "Epoch 73/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.4198 - acc: 0.8249 - val_loss: 0.3734 - val_acc: 0.8260\n",
      "Epoch 74/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.4138 - acc: 0.8294 - val_loss: 0.3719 - val_acc: 0.8260\n",
      "Epoch 75/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.4191 - acc: 0.8264 - val_loss: 0.3713 - val_acc: 0.8265\n",
      "Epoch 76/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4136 - acc: 0.8311 - val_loss: 0.3705 - val_acc: 0.8280\n",
      "Epoch 77/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4142 - acc: 0.8313 - val_loss: 0.3704 - val_acc: 0.8300\n",
      "Epoch 78/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4128 - acc: 0.8311 - val_loss: 0.3706 - val_acc: 0.8270\n",
      "Epoch 79/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4099 - acc: 0.8336 - val_loss: 0.3687 - val_acc: 0.8320\n",
      "Epoch 80/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4145 - acc: 0.8296 - val_loss: 0.3702 - val_acc: 0.8290\n",
      "Epoch 81/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4166 - acc: 0.8295 - val_loss: 0.3705 - val_acc: 0.8290\n",
      "Epoch 82/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4123 - acc: 0.8282 - val_loss: 0.3695 - val_acc: 0.8300\n",
      "Epoch 83/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4175 - acc: 0.8291 - val_loss: 0.3689 - val_acc: 0.8320\n",
      "Epoch 84/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4091 - acc: 0.8329 - val_loss: 0.3683 - val_acc: 0.8320\n",
      "Epoch 85/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4135 - acc: 0.8284 - val_loss: 0.3667 - val_acc: 0.8325\n",
      "Epoch 86/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.4134 - acc: 0.8307 - val_loss: 0.3678 - val_acc: 0.8320\n",
      "Epoch 87/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.4112 - acc: 0.8291 - val_loss: 0.3676 - val_acc: 0.8345\n",
      "Epoch 88/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.4141 - acc: 0.8269 - val_loss: 0.3687 - val_acc: 0.8280\n",
      "Epoch 89/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4167 - acc: 0.8275 - val_loss: 0.3692 - val_acc: 0.8275\n",
      "Epoch 90/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4119 - acc: 0.8300 - val_loss: 0.3690 - val_acc: 0.8280\n",
      "Epoch 91/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.4109 - acc: 0.8324 - val_loss: 0.3681 - val_acc: 0.8320\n",
      "Epoch 92/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4072 - acc: 0.8334 - val_loss: 0.3665 - val_acc: 0.8350\n",
      "Epoch 93/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.4143 - acc: 0.8304 - val_loss: 0.3678 - val_acc: 0.8305\n",
      "Epoch 94/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.4111 - acc: 0.8303 - val_loss: 0.3671 - val_acc: 0.8305\n",
      "Epoch 95/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4121 - acc: 0.8286 - val_loss: 0.3661 - val_acc: 0.8315\n",
      "Epoch 96/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4133 - acc: 0.8285 - val_loss: 0.3657 - val_acc: 0.8315\n",
      "Epoch 97/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4150 - acc: 0.8285 - val_loss: 0.3667 - val_acc: 0.8305\n",
      "Epoch 98/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4142 - acc: 0.8301 - val_loss: 0.3662 - val_acc: 0.8310\n",
      "Epoch 99/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4101 - acc: 0.8295 - val_loss: 0.3653 - val_acc: 0.8325\n",
      "Epoch 100/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4093 - acc: 0.8320 - val_loss: 0.3651 - val_acc: 0.8335\n",
      "Epoch 101/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4066 - acc: 0.8316 - val_loss: 0.3641 - val_acc: 0.8375\n",
      "Epoch 102/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4130 - acc: 0.8284 - val_loss: 0.3649 - val_acc: 0.8310\n",
      "Epoch 103/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4131 - acc: 0.8292 - val_loss: 0.3646 - val_acc: 0.8310\n",
      "Epoch 104/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4073 - acc: 0.8300 - val_loss: 0.3591 - val_acc: 0.8445\n",
      "Epoch 105/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4070 - acc: 0.8301 - val_loss: 0.3574 - val_acc: 0.8510\n",
      "Epoch 106/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4028 - acc: 0.8290 - val_loss: 0.3553 - val_acc: 0.8545\n",
      "Epoch 107/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4059 - acc: 0.8342 - val_loss: 0.3560 - val_acc: 0.8550\n",
      "Epoch 108/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3984 - acc: 0.8317 - val_loss: 0.3539 - val_acc: 0.8550\n",
      "Epoch 109/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4027 - acc: 0.8350 - val_loss: 0.3539 - val_acc: 0.8555\n",
      "Epoch 110/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4013 - acc: 0.8335 - val_loss: 0.3532 - val_acc: 0.8570\n",
      "Epoch 111/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4037 - acc: 0.8305 - val_loss: 0.3535 - val_acc: 0.8570\n",
      "Epoch 112/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4030 - acc: 0.8326 - val_loss: 0.3533 - val_acc: 0.8550\n",
      "Epoch 113/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3971 - acc: 0.8363 - val_loss: 0.3520 - val_acc: 0.8550\n",
      "Epoch 114/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3977 - acc: 0.8342 - val_loss: 0.3516 - val_acc: 0.8575\n",
      "Epoch 115/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3989 - acc: 0.8378 - val_loss: 0.3519 - val_acc: 0.8575\n",
      "Epoch 116/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.4022 - acc: 0.8346 - val_loss: 0.3520 - val_acc: 0.8550\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3996 - acc: 0.8390 - val_loss: 0.3512 - val_acc: 0.8600\n",
      "Epoch 118/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3960 - acc: 0.8357 - val_loss: 0.3514 - val_acc: 0.8580\n",
      "Epoch 119/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4004 - acc: 0.8331 - val_loss: 0.3520 - val_acc: 0.8570\n",
      "Epoch 120/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3953 - acc: 0.8384 - val_loss: 0.3512 - val_acc: 0.8565\n",
      "Epoch 121/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3996 - acc: 0.8328 - val_loss: 0.3519 - val_acc: 0.8530\n",
      "Epoch 122/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4043 - acc: 0.8320 - val_loss: 0.3524 - val_acc: 0.8560\n",
      "Epoch 123/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3971 - acc: 0.8353 - val_loss: 0.3509 - val_acc: 0.8590\n",
      "Epoch 124/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4010 - acc: 0.8342 - val_loss: 0.3500 - val_acc: 0.8575\n",
      "Epoch 125/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3997 - acc: 0.8317 - val_loss: 0.3505 - val_acc: 0.8570\n",
      "Epoch 126/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3991 - acc: 0.834 - 0s 45us/sample - loss: 0.3985 - acc: 0.8350 - val_loss: 0.3509 - val_acc: 0.8550\n",
      "Epoch 127/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3912 - acc: 0.8388 - val_loss: 0.3490 - val_acc: 0.8560\n",
      "Epoch 128/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4004 - acc: 0.8332 - val_loss: 0.3496 - val_acc: 0.8550\n",
      "Epoch 129/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3974 - acc: 0.8384 - val_loss: 0.3501 - val_acc: 0.8570\n",
      "Epoch 130/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4011 - acc: 0.8342 - val_loss: 0.3495 - val_acc: 0.8575\n",
      "Epoch 131/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3988 - acc: 0.8328 - val_loss: 0.3491 - val_acc: 0.8575\n",
      "Epoch 132/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3966 - acc: 0.8400 - val_loss: 0.3489 - val_acc: 0.8630\n",
      "Epoch 133/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3943 - acc: 0.8407 - val_loss: 0.3481 - val_acc: 0.8650\n",
      "Epoch 134/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3986 - acc: 0.8380 - val_loss: 0.3487 - val_acc: 0.8620\n",
      "Epoch 135/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3984 - acc: 0.8367 - val_loss: 0.3486 - val_acc: 0.8600\n",
      "Epoch 136/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3971 - acc: 0.8359 - val_loss: 0.3481 - val_acc: 0.8620\n",
      "Epoch 137/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3991 - acc: 0.8339 - val_loss: 0.3481 - val_acc: 0.8585\n",
      "Epoch 138/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3965 - acc: 0.8340 - val_loss: 0.3483 - val_acc: 0.8580\n",
      "Epoch 139/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3968 - acc: 0.8369 - val_loss: 0.3492 - val_acc: 0.8590\n",
      "Epoch 140/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3984 - acc: 0.8378 - val_loss: 0.3492 - val_acc: 0.8595\n",
      "Epoch 141/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3978 - acc: 0.8361 - val_loss: 0.3492 - val_acc: 0.8580\n",
      "Epoch 142/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3972 - acc: 0.8356 - val_loss: 0.3483 - val_acc: 0.8595\n",
      "Epoch 143/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3954 - acc: 0.8365 - val_loss: 0.3477 - val_acc: 0.8590\n",
      "Epoch 144/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.4030 - acc: 0.8356 - val_loss: 0.3490 - val_acc: 0.8600\n",
      "Epoch 145/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3951 - acc: 0.8405 - val_loss: 0.3470 - val_acc: 0.8600\n",
      "Epoch 146/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3944 - acc: 0.8363 - val_loss: 0.3455 - val_acc: 0.8610\n",
      "Epoch 147/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3910 - acc: 0.8413 - val_loss: 0.3443 - val_acc: 0.8605\n",
      "Epoch 148/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3959 - acc: 0.8380 - val_loss: 0.3451 - val_acc: 0.8610\n",
      "Epoch 149/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3942 - acc: 0.8388 - val_loss: 0.3451 - val_acc: 0.8585\n",
      "Epoch 150/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3940 - acc: 0.8390 - val_loss: 0.3448 - val_acc: 0.8575\n",
      "Epoch 151/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3932 - acc: 0.8380 - val_loss: 0.3445 - val_acc: 0.8575\n",
      "Epoch 152/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3928 - acc: 0.8389 - val_loss: 0.3444 - val_acc: 0.8575\n",
      "Epoch 153/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3889 - acc: 0.8344 - val_loss: 0.3431 - val_acc: 0.8615\n",
      "Epoch 154/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3914 - acc: 0.8336 - val_loss: 0.3446 - val_acc: 0.8590\n",
      "Epoch 155/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3879 - acc: 0.8394 - val_loss: 0.3439 - val_acc: 0.8595\n",
      "Epoch 156/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3869 - acc: 0.8382 - val_loss: 0.3431 - val_acc: 0.8605\n",
      "Epoch 157/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3898 - acc: 0.8424 - val_loss: 0.3436 - val_acc: 0.8590\n",
      "Epoch 158/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3917 - acc: 0.8379 - val_loss: 0.3439 - val_acc: 0.8590\n",
      "Epoch 159/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3957 - acc: 0.8391 - val_loss: 0.3453 - val_acc: 0.8580\n",
      "Epoch 160/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3914 - acc: 0.8397 - val_loss: 0.3446 - val_acc: 0.8595\n",
      "Epoch 161/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3880 - acc: 0.8396 - val_loss: 0.3444 - val_acc: 0.8605\n",
      "Epoch 162/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3888 - acc: 0.8414 - val_loss: 0.3435 - val_acc: 0.8600\n",
      "Epoch 163/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3861 - acc: 0.8420 - val_loss: 0.3430 - val_acc: 0.8625\n",
      "Epoch 164/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3884 - acc: 0.8422 - val_loss: 0.3432 - val_acc: 0.8610\n",
      "Epoch 165/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3972 - acc: 0.8365 - val_loss: 0.3454 - val_acc: 0.8595\n",
      "Epoch 166/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3927 - acc: 0.8390 - val_loss: 0.3446 - val_acc: 0.8610\n",
      "Epoch 167/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3949 - acc: 0.8351 - val_loss: 0.3442 - val_acc: 0.8625\n",
      "Epoch 168/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3969 - acc: 0.8330 - val_loss: 0.3452 - val_acc: 0.8625\n",
      "Epoch 169/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3949 - acc: 0.8367 - val_loss: 0.3441 - val_acc: 0.8630\n",
      "Epoch 170/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3965 - acc: 0.8360 - val_loss: 0.3452 - val_acc: 0.8635\n",
      "Epoch 171/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3929 - acc: 0.8356 - val_loss: 0.3451 - val_acc: 0.8620\n",
      "Epoch 172/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3891 - acc: 0.8394 - val_loss: 0.3444 - val_acc: 0.8640\n",
      "Epoch 173/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4016 - acc: 0.8369 - val_loss: 0.3457 - val_acc: 0.8625\n",
      "Epoch 174/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3882 - acc: 0.8404 - val_loss: 0.3435 - val_acc: 0.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3861 - acc: 0.8380 - val_loss: 0.3417 - val_acc: 0.8605\n",
      "Epoch 176/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3963 - acc: 0.8388 - val_loss: 0.3434 - val_acc: 0.8615\n",
      "Epoch 177/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3908 - acc: 0.8386 - val_loss: 0.3429 - val_acc: 0.8635\n",
      "Epoch 178/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3949 - acc: 0.8376 - val_loss: 0.3428 - val_acc: 0.8605\n",
      "Epoch 179/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3923 - acc: 0.8385 - val_loss: 0.3423 - val_acc: 0.8615\n",
      "Epoch 180/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3947 - acc: 0.8357 - val_loss: 0.3437 - val_acc: 0.8640\n",
      "Epoch 181/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3850 - acc: 0.8409 - val_loss: 0.3422 - val_acc: 0.8620\n",
      "Epoch 182/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3903 - acc: 0.8390 - val_loss: 0.3421 - val_acc: 0.8640\n",
      "Epoch 183/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3916 - acc: 0.8394 - val_loss: 0.3433 - val_acc: 0.8615\n",
      "Epoch 184/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3924 - acc: 0.8361 - val_loss: 0.3439 - val_acc: 0.8610\n",
      "Epoch 185/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3935 - acc: 0.8380 - val_loss: 0.3440 - val_acc: 0.8590\n",
      "Epoch 186/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3934 - acc: 0.8369 - val_loss: 0.3432 - val_acc: 0.8610\n",
      "Epoch 187/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3905 - acc: 0.8403 - val_loss: 0.3429 - val_acc: 0.8590\n",
      "Epoch 188/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3955 - acc: 0.8359 - val_loss: 0.3439 - val_acc: 0.8585\n",
      "Epoch 189/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3880 - acc: 0.8413 - val_loss: 0.3425 - val_acc: 0.8625\n",
      "Epoch 190/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3908 - acc: 0.8379 - val_loss: 0.3427 - val_acc: 0.8615\n",
      "Epoch 191/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3893 - acc: 0.8371 - val_loss: 0.3417 - val_acc: 0.8600\n",
      "Epoch 192/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3912 - acc: 0.8342 - val_loss: 0.3417 - val_acc: 0.8605\n",
      "Epoch 193/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3895 - acc: 0.8388 - val_loss: 0.3420 - val_acc: 0.8625\n",
      "Epoch 194/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3921 - acc: 0.8359 - val_loss: 0.3422 - val_acc: 0.8620\n",
      "Epoch 195/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3934 - acc: 0.8372 - val_loss: 0.3427 - val_acc: 0.8615\n",
      "Epoch 196/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3921 - acc: 0.8389 - val_loss: 0.3437 - val_acc: 0.8610\n",
      "Epoch 197/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3921 - acc: 0.8370 - val_loss: 0.3435 - val_acc: 0.8610\n",
      "Epoch 198/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3950 - acc: 0.8350 - val_loss: 0.3427 - val_acc: 0.8630\n",
      "Epoch 199/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3933 - acc: 0.8375 - val_loss: 0.3427 - val_acc: 0.8635\n",
      "Epoch 200/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3923 - acc: 0.8371 - val_loss: 0.3429 - val_acc: 0.8615\n",
      "Epoch 201/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3901 - acc: 0.8372 - val_loss: 0.3416 - val_acc: 0.8630\n",
      "Epoch 202/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3885 - acc: 0.8391 - val_loss: 0.3416 - val_acc: 0.8630\n",
      "Epoch 203/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3910 - acc: 0.8403 - val_loss: 0.3420 - val_acc: 0.8630\n",
      "Epoch 204/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3899 - acc: 0.8401 - val_loss: 0.3418 - val_acc: 0.8600\n",
      "Epoch 205/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3957 - acc: 0.8349 - val_loss: 0.3437 - val_acc: 0.8605\n",
      "Epoch 206/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3899 - acc: 0.8410 - val_loss: 0.3425 - val_acc: 0.8615\n",
      "Epoch 207/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3891 - acc: 0.8394 - val_loss: 0.3424 - val_acc: 0.8605\n",
      "Epoch 208/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3905 - acc: 0.8360 - val_loss: 0.3416 - val_acc: 0.8590\n",
      "Epoch 209/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3959 - acc: 0.8328 - val_loss: 0.3413 - val_acc: 0.8600\n",
      "Epoch 210/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3941 - acc: 0.8340 - val_loss: 0.3430 - val_acc: 0.8595\n",
      "Epoch 211/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3890 - acc: 0.8394 - val_loss: 0.3420 - val_acc: 0.8565\n",
      "Epoch 212/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3899 - acc: 0.8389 - val_loss: 0.3413 - val_acc: 0.8590\n",
      "Epoch 213/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3867 - acc: 0.8400 - val_loss: 0.3402 - val_acc: 0.8605\n",
      "Epoch 214/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3918 - acc: 0.8375 - val_loss: 0.3413 - val_acc: 0.8630\n",
      "Epoch 215/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3944 - acc: 0.8372 - val_loss: 0.3421 - val_acc: 0.8620\n",
      "Epoch 216/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3940 - acc: 0.8331 - val_loss: 0.3427 - val_acc: 0.8615\n",
      "Epoch 217/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3897 - acc: 0.8406 - val_loss: 0.3417 - val_acc: 0.8610\n",
      "Epoch 218/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3973 - acc: 0.8369 - val_loss: 0.3422 - val_acc: 0.8620\n",
      "Epoch 219/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3920 - acc: 0.8350 - val_loss: 0.3422 - val_acc: 0.8625\n",
      "Epoch 220/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3938 - acc: 0.8391 - val_loss: 0.3415 - val_acc: 0.8615\n",
      "Epoch 221/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3855 - acc: 0.8386 - val_loss: 0.3413 - val_acc: 0.8605\n",
      "Epoch 222/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3907 - acc: 0.8390 - val_loss: 0.3408 - val_acc: 0.8635\n",
      "Epoch 223/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3956 - acc: 0.8372 - val_loss: 0.3422 - val_acc: 0.8640\n",
      "Epoch 224/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3861 - acc: 0.8367 - val_loss: 0.3415 - val_acc: 0.8645\n",
      "Epoch 225/1000\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.3845 - acc: 0.8406 - val_loss: 0.3402 - val_acc: 0.8600\n",
      "Epoch 226/1000\n",
      "8000/8000 [==============================] - 1s 101us/sample - loss: 0.3908 - acc: 0.8397 - val_loss: 0.3411 - val_acc: 0.8645\n",
      "Epoch 227/1000\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.3919 - acc: 0.8350 - val_loss: 0.3406 - val_acc: 0.8630\n",
      "Epoch 228/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3919 - acc: 0.8376 - val_loss: 0.3406 - val_acc: 0.8645\n",
      "Epoch 229/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3935 - acc: 0.8428 - val_loss: 0.3415 - val_acc: 0.8650\n",
      "Epoch 230/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3912 - acc: 0.8391 - val_loss: 0.3413 - val_acc: 0.8620\n",
      "Epoch 231/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3895 - acc: 0.8371 - val_loss: 0.3406 - val_acc: 0.8620\n",
      "Epoch 232/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3921 - acc: 0.8370 - val_loss: 0.3406 - val_acc: 0.8600\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3870 - acc: 0.8403 - val_loss: 0.3383 - val_acc: 0.8610\n",
      "Epoch 234/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3930 - acc: 0.8382 - val_loss: 0.3404 - val_acc: 0.8625\n",
      "Epoch 235/1000\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.3947 - acc: 0.8356 - val_loss: 0.3423 - val_acc: 0.8605\n",
      "Epoch 236/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3919 - acc: 0.8375 - val_loss: 0.3416 - val_acc: 0.8625\n",
      "Epoch 237/1000\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3927 - acc: 0.8375 - val_loss: 0.3416 - val_acc: 0.8625\n",
      "Epoch 238/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3883 - acc: 0.8409 - val_loss: 0.3410 - val_acc: 0.8650\n",
      "Epoch 239/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3928 - acc: 0.839 - 0s 58us/sample - loss: 0.3965 - acc: 0.8372 - val_loss: 0.3419 - val_acc: 0.8640\n",
      "Epoch 240/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3947 - acc: 0.8386 - val_loss: 0.3418 - val_acc: 0.8655\n",
      "Epoch 241/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3889 - acc: 0.8397 - val_loss: 0.3404 - val_acc: 0.8670\n",
      "Epoch 242/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3897 - acc: 0.8401 - val_loss: 0.3403 - val_acc: 0.8655\n",
      "Epoch 243/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3904 - acc: 0.8384 - val_loss: 0.3408 - val_acc: 0.8615\n",
      "Epoch 244/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3874 - acc: 0.8409 - val_loss: 0.3399 - val_acc: 0.8630\n",
      "Epoch 245/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3853 - acc: 0.8403 - val_loss: 0.3384 - val_acc: 0.8630\n",
      "Epoch 246/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3896 - acc: 0.8367 - val_loss: 0.3388 - val_acc: 0.8620 0s - loss: 0.3877 - acc: \n",
      "Epoch 247/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3934 - acc: 0.8354 - val_loss: 0.3410 - val_acc: 0.8625\n",
      "Epoch 248/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3886 - acc: 0.8413 - val_loss: 0.3410 - val_acc: 0.8630\n",
      "Epoch 249/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3906 - acc: 0.8419 - val_loss: 0.3405 - val_acc: 0.8630\n",
      "Epoch 250/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3917 - acc: 0.8385 - val_loss: 0.3422 - val_acc: 0.8635\n",
      "Epoch 251/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3892 - acc: 0.8389 - val_loss: 0.3405 - val_acc: 0.8625\n",
      "Epoch 252/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3892 - acc: 0.8372 - val_loss: 0.3405 - val_acc: 0.8620\n",
      "Epoch 253/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3928 - acc: 0.8369 - val_loss: 0.3411 - val_acc: 0.8620\n",
      "Epoch 254/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3935 - acc: 0.8390 - val_loss: 0.3426 - val_acc: 0.8620\n",
      "Epoch 255/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3882 - acc: 0.8421 - val_loss: 0.3406 - val_acc: 0.8615\n",
      "Epoch 256/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3883 - acc: 0.8411 - val_loss: 0.3395 - val_acc: 0.8605\n",
      "Epoch 257/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3921 - acc: 0.8401 - val_loss: 0.3404 - val_acc: 0.8600\n",
      "Epoch 258/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3874 - acc: 0.8406 - val_loss: 0.3397 - val_acc: 0.8615\n",
      "Epoch 259/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3878 - acc: 0.8397 - val_loss: 0.3393 - val_acc: 0.8610\n",
      "Epoch 260/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3921 - acc: 0.8384 - val_loss: 0.3408 - val_acc: 0.8615\n",
      "Epoch 261/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3808 - acc: 0.8454 - val_loss: 0.3383 - val_acc: 0.8610\n",
      "Epoch 262/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3878 - acc: 0.8413 - val_loss: 0.3397 - val_acc: 0.8610\n",
      "Epoch 263/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3904 - acc: 0.8413 - val_loss: 0.3399 - val_acc: 0.8590\n",
      "Epoch 264/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3921 - acc: 0.8393 - val_loss: 0.3410 - val_acc: 0.8580\n",
      "Epoch 265/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3908 - acc: 0.8454 - val_loss: 0.3420 - val_acc: 0.8590\n",
      "Epoch 266/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3931 - acc: 0.8391 - val_loss: 0.3419 - val_acc: 0.8575\n",
      "Epoch 267/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3906 - acc: 0.8422 - val_loss: 0.3408 - val_acc: 0.8620\n",
      "Epoch 268/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3902 - acc: 0.8414 - val_loss: 0.3418 - val_acc: 0.8630\n",
      "Epoch 269/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3871 - acc: 0.8407 - val_loss: 0.3397 - val_acc: 0.8625\n",
      "Epoch 270/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3910 - acc: 0.8399 - val_loss: 0.3410 - val_acc: 0.8625\n",
      "Epoch 271/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3876 - acc: 0.8413 - val_loss: 0.3406 - val_acc: 0.8610\n",
      "Epoch 272/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3917 - acc: 0.8405 - val_loss: 0.3411 - val_acc: 0.8605\n",
      "Epoch 273/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3875 - acc: 0.8405 - val_loss: 0.3412 - val_acc: 0.8625\n",
      "Epoch 274/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3874 - acc: 0.8410 - val_loss: 0.3396 - val_acc: 0.8615\n",
      "Epoch 275/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3919 - acc: 0.8393 - val_loss: 0.3397 - val_acc: 0.8625\n",
      "Epoch 276/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3896 - acc: 0.8381 - val_loss: 0.3397 - val_acc: 0.8625\n",
      "Epoch 277/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3904 - acc: 0.8393 - val_loss: 0.3403 - val_acc: 0.8625\n",
      "Epoch 278/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3863 - acc: 0.8401 - val_loss: 0.3395 - val_acc: 0.8615\n",
      "Epoch 279/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3935 - acc: 0.8370 - val_loss: 0.3407 - val_acc: 0.8610\n",
      "Epoch 280/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3894 - acc: 0.8399 - val_loss: 0.3412 - val_acc: 0.8605\n",
      "Epoch 281/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3950 - acc: 0.8356 - val_loss: 0.3427 - val_acc: 0.8605\n",
      "Epoch 282/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3888 - acc: 0.8388 - val_loss: 0.3417 - val_acc: 0.8605\n",
      "Epoch 283/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3886 - acc: 0.8395 - val_loss: 0.3409 - val_acc: 0.8605\n",
      "Epoch 284/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3914 - acc: 0.8369 - val_loss: 0.3412 - val_acc: 0.8600\n",
      "Epoch 285/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3925 - acc: 0.8365 - val_loss: 0.3420 - val_acc: 0.8615\n",
      "Epoch 286/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3954 - acc: 0.8360 - val_loss: 0.3426 - val_acc: 0.8630\n",
      "Epoch 287/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3955 - acc: 0.8372 - val_loss: 0.3424 - val_acc: 0.8610\n",
      "Epoch 288/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3897 - acc: 0.8394 - val_loss: 0.3423 - val_acc: 0.8630\n",
      "Epoch 289/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3873 - acc: 0.8400 - val_loss: 0.3418 - val_acc: 0.8615\n",
      "Epoch 290/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3921 - acc: 0.8375 - val_loss: 0.3404 - val_acc: 0.8590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3961 - acc: 0.8351 - val_loss: 0.3409 - val_acc: 0.8600\n",
      "Epoch 292/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3849 - acc: 0.8365 - val_loss: 0.3406 - val_acc: 0.8615\n",
      "Epoch 293/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3925 - acc: 0.8354 - val_loss: 0.3410 - val_acc: 0.8600\n",
      "Epoch 294/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3886 - acc: 0.8388 - val_loss: 0.3403 - val_acc: 0.8610\n",
      "Epoch 295/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3900 - acc: 0.8399 - val_loss: 0.3393 - val_acc: 0.8605\n",
      "Epoch 296/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3909 - acc: 0.8413 - val_loss: 0.3397 - val_acc: 0.8620\n",
      "Epoch 297/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3886 - acc: 0.8404 - val_loss: 0.3403 - val_acc: 0.8615\n",
      "Epoch 298/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3926 - acc: 0.8374 - val_loss: 0.3404 - val_acc: 0.8610\n",
      "Epoch 299/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3872 - acc: 0.8374 - val_loss: 0.3409 - val_acc: 0.8620\n",
      "Epoch 300/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3866 - acc: 0.8381 - val_loss: 0.3397 - val_acc: 0.8600\n",
      "Epoch 301/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3905 - acc: 0.8391 - val_loss: 0.3397 - val_acc: 0.8620\n",
      "Epoch 302/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3898 - acc: 0.8413 - val_loss: 0.3401 - val_acc: 0.8615\n",
      "Epoch 303/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3810 - acc: 0.8425 - val_loss: 0.3384 - val_acc: 0.8625\n",
      "Epoch 304/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3882 - acc: 0.8403 - val_loss: 0.3398 - val_acc: 0.8615\n",
      "Epoch 305/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3888 - acc: 0.8378 - val_loss: 0.3393 - val_acc: 0.8620\n",
      "Epoch 306/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3907 - acc: 0.8372 - val_loss: 0.3402 - val_acc: 0.8605\n",
      "Epoch 307/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3869 - acc: 0.8375 - val_loss: 0.3398 - val_acc: 0.8610\n",
      "Epoch 308/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3857 - acc: 0.8410 - val_loss: 0.3401 - val_acc: 0.8620\n",
      "Epoch 309/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3916 - acc: 0.8376 - val_loss: 0.3410 - val_acc: 0.8610\n",
      "Epoch 310/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3890 - acc: 0.8401 - val_loss: 0.3411 - val_acc: 0.8620\n",
      "Epoch 311/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3926 - acc: 0.8370 - val_loss: 0.3405 - val_acc: 0.8615\n",
      "Epoch 312/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3897 - acc: 0.8395 - val_loss: 0.3401 - val_acc: 0.8605\n",
      "Epoch 313/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3892 - acc: 0.8429 - val_loss: 0.3389 - val_acc: 0.8605\n",
      "Epoch 314/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3836 - acc: 0.8419 - val_loss: 0.3391 - val_acc: 0.8615\n",
      "Epoch 315/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3947 - acc: 0.8395 - val_loss: 0.3412 - val_acc: 0.8635\n",
      "Epoch 316/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3890 - acc: 0.8379 - val_loss: 0.3407 - val_acc: 0.8620\n",
      "Epoch 317/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3922 - acc: 0.8340 - val_loss: 0.3397 - val_acc: 0.8625\n",
      "Epoch 318/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3875 - acc: 0.8405 - val_loss: 0.3392 - val_acc: 0.8615\n",
      "Epoch 319/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3856 - acc: 0.8390 - val_loss: 0.3376 - val_acc: 0.8620\n",
      "Epoch 320/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3784 - acc: 0.8455 - val_loss: 0.3373 - val_acc: 0.8630\n",
      "Epoch 321/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3859 - acc: 0.8431 - val_loss: 0.3375 - val_acc: 0.8615\n",
      "Epoch 322/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3800 - acc: 0.8431 - val_loss: 0.3372 - val_acc: 0.8610\n",
      "Epoch 323/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3880 - acc: 0.8396 - val_loss: 0.3389 - val_acc: 0.8605\n",
      "Epoch 324/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3813 - acc: 0.8459 - val_loss: 0.3391 - val_acc: 0.8590\n",
      "Epoch 325/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3903 - acc: 0.8420 - val_loss: 0.3393 - val_acc: 0.8605\n",
      "Epoch 326/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3853 - acc: 0.8430 - val_loss: 0.3402 - val_acc: 0.8615\n",
      "Epoch 327/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3879 - acc: 0.8432 - val_loss: 0.3390 - val_acc: 0.8610\n",
      "Epoch 328/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3912 - acc: 0.8394 - val_loss: 0.3401 - val_acc: 0.8595\n",
      "Epoch 329/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3853 - acc: 0.8401 - val_loss: 0.3392 - val_acc: 0.8605\n",
      "Epoch 330/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3880 - acc: 0.8401 - val_loss: 0.3386 - val_acc: 0.8605\n",
      "Epoch 331/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3897 - acc: 0.8405 - val_loss: 0.3381 - val_acc: 0.8610\n",
      "Epoch 332/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3837 - acc: 0.8415 - val_loss: 0.3390 - val_acc: 0.8635\n",
      "Epoch 333/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3877 - acc: 0.8406 - val_loss: 0.3402 - val_acc: 0.8620\n",
      "Epoch 334/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3916 - acc: 0.8418 - val_loss: 0.3410 - val_acc: 0.8610\n",
      "Epoch 335/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3902 - acc: 0.8350 - val_loss: 0.3407 - val_acc: 0.8625\n",
      "Epoch 336/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3867 - acc: 0.8401 - val_loss: 0.3402 - val_acc: 0.8605\n",
      "Epoch 337/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3914 - acc: 0.8414 - val_loss: 0.3394 - val_acc: 0.8600\n",
      "Epoch 338/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3880 - acc: 0.8374 - val_loss: 0.3392 - val_acc: 0.8605\n",
      "Epoch 339/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3897 - acc: 0.8375 - val_loss: 0.3407 - val_acc: 0.8610\n",
      "Epoch 340/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3899 - acc: 0.8367 - val_loss: 0.3402 - val_acc: 0.8615\n",
      "Epoch 341/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3904 - acc: 0.8399 - val_loss: 0.3393 - val_acc: 0.8595\n",
      "Epoch 342/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3923 - acc: 0.8405 - val_loss: 0.3396 - val_acc: 0.8615\n",
      "Epoch 343/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3873 - acc: 0.8400 - val_loss: 0.3392 - val_acc: 0.8605\n",
      "Epoch 344/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3842 - acc: 0.8436 - val_loss: 0.3395 - val_acc: 0.8590\n",
      "Epoch 345/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3867 - acc: 0.8415 - val_loss: 0.3401 - val_acc: 0.8590\n",
      "Epoch 346/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3910 - acc: 0.8394 - val_loss: 0.3404 - val_acc: 0.8585\n",
      "Epoch 347/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3879 - acc: 0.8422 - val_loss: 0.3396 - val_acc: 0.8615\n",
      "Epoch 348/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3855 - acc: 0.8430 - val_loss: 0.3390 - val_acc: 0.8620\n",
      "Epoch 349/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3794 - acc: 0.8426 - val_loss: 0.3378 - val_acc: 0.8595\n",
      "Epoch 350/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3921 - acc: 0.8422 - val_loss: 0.3388 - val_acc: 0.8620\n",
      "Epoch 351/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3823 - acc: 0.8432 - val_loss: 0.3374 - val_acc: 0.8600\n",
      "Epoch 352/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3881 - acc: 0.8395 - val_loss: 0.3383 - val_acc: 0.8605\n",
      "Epoch 353/1000\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.3777 - acc: 0.8459 - val_loss: 0.3370 - val_acc: 0.8625\n",
      "Epoch 354/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3888 - acc: 0.8421 - val_loss: 0.3375 - val_acc: 0.8630\n",
      "Epoch 355/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3912 - acc: 0.8386 - val_loss: 0.3384 - val_acc: 0.8635\n",
      "Epoch 356/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3947 - acc: 0.8369 - val_loss: 0.3405 - val_acc: 0.8635\n",
      "Epoch 357/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3868 - acc: 0.8400 - val_loss: 0.3396 - val_acc: 0.8625\n",
      "Epoch 358/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3889 - acc: 0.8428 - val_loss: 0.3393 - val_acc: 0.8630\n",
      "Epoch 359/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3915 - acc: 0.8395 - val_loss: 0.3396 - val_acc: 0.8630\n",
      "Epoch 360/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3927 - acc: 0.8410 - val_loss: 0.3409 - val_acc: 0.8615\n",
      "Epoch 361/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3873 - acc: 0.8441 - val_loss: 0.3406 - val_acc: 0.8605\n",
      "Epoch 362/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3922 - acc: 0.8378 - val_loss: 0.3404 - val_acc: 0.8655\n",
      "Epoch 363/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3956 - acc: 0.8381 - val_loss: 0.3405 - val_acc: 0.8635\n",
      "Epoch 364/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3863 - acc: 0.8406 - val_loss: 0.3400 - val_acc: 0.8630\n",
      "Epoch 365/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3900 - acc: 0.8405 - val_loss: 0.3396 - val_acc: 0.8630\n",
      "Epoch 366/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3877 - acc: 0.8424 - val_loss: 0.3396 - val_acc: 0.8605\n",
      "Epoch 367/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3889 - acc: 0.8395 - val_loss: 0.3406 - val_acc: 0.8610\n",
      "Epoch 368/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3845 - acc: 0.8436 - val_loss: 0.3390 - val_acc: 0.8630\n",
      "Epoch 369/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3924 - acc: 0.8376 - val_loss: 0.3396 - val_acc: 0.8615\n",
      "Epoch 370/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3883 - acc: 0.8391 - val_loss: 0.3395 - val_acc: 0.8620\n",
      "Epoch 371/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3859 - acc: 0.8382 - val_loss: 0.3390 - val_acc: 0.8605\n",
      "Epoch 372/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3871 - acc: 0.8441 - val_loss: 0.3384 - val_acc: 0.8610\n",
      "Epoch 373/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3887 - acc: 0.8436 - val_loss: 0.3395 - val_acc: 0.8600\n",
      "Epoch 374/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3863 - acc: 0.8404 - val_loss: 0.3389 - val_acc: 0.8595\n",
      "Epoch 375/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3888 - acc: 0.8405 - val_loss: 0.3386 - val_acc: 0.8625\n",
      "Epoch 376/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3786 - acc: 0.8482 - val_loss: 0.3388 - val_acc: 0.8625\n",
      "Epoch 377/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3887 - acc: 0.8381 - val_loss: 0.3380 - val_acc: 0.8620\n",
      "Epoch 378/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3910 - acc: 0.838 - 0s 45us/sample - loss: 0.3930 - acc: 0.8375 - val_loss: 0.3378 - val_acc: 0.8620\n",
      "Epoch 379/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3842 - acc: 0.8405 - val_loss: 0.3386 - val_acc: 0.8605\n",
      "Epoch 380/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3891 - acc: 0.8389 - val_loss: 0.3407 - val_acc: 0.8610\n",
      "Epoch 381/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3892 - acc: 0.8399 - val_loss: 0.3397 - val_acc: 0.8605\n",
      "Epoch 382/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3833 - acc: 0.8440 - val_loss: 0.3395 - val_acc: 0.8605\n",
      "Epoch 383/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3922 - acc: 0.8367 - val_loss: 0.3397 - val_acc: 0.8640\n",
      "Epoch 384/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3900 - acc: 0.8385 - val_loss: 0.3408 - val_acc: 0.8620\n",
      "Epoch 385/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3896 - acc: 0.8390 - val_loss: 0.3398 - val_acc: 0.8635\n",
      "Epoch 386/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3895 - acc: 0.8406 - val_loss: 0.3402 - val_acc: 0.8630\n",
      "Epoch 387/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3886 - acc: 0.8394 - val_loss: 0.3399 - val_acc: 0.8610\n",
      "Epoch 388/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3827 - acc: 0.8420 - val_loss: 0.3395 - val_acc: 0.8595\n",
      "Epoch 389/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3910 - acc: 0.8399 - val_loss: 0.3405 - val_acc: 0.8605\n",
      "Epoch 390/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3892 - acc: 0.8382 - val_loss: 0.3406 - val_acc: 0.8615\n",
      "Epoch 391/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3852 - acc: 0.8395 - val_loss: 0.3391 - val_acc: 0.8600\n",
      "Epoch 392/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3925 - acc: 0.8340 - val_loss: 0.3395 - val_acc: 0.8630\n",
      "Epoch 393/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3851 - acc: 0.8429 - val_loss: 0.3389 - val_acc: 0.8595\n",
      "Epoch 394/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3889 - acc: 0.8382 - val_loss: 0.3385 - val_acc: 0.8620\n",
      "Epoch 395/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3921 - acc: 0.8359 - val_loss: 0.3406 - val_acc: 0.8605\n",
      "Epoch 396/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3866 - acc: 0.8406 - val_loss: 0.3387 - val_acc: 0.8590\n",
      "Epoch 397/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3869 - acc: 0.8397 - val_loss: 0.3379 - val_acc: 0.8600\n",
      "Epoch 398/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3863 - acc: 0.8406 - val_loss: 0.3381 - val_acc: 0.8625\n",
      "Epoch 399/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3899 - acc: 0.8404 - val_loss: 0.3385 - val_acc: 0.8635\n",
      "Epoch 400/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3837 - acc: 0.8410 - val_loss: 0.3381 - val_acc: 0.8600\n",
      "Epoch 401/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3857 - acc: 0.8418 - val_loss: 0.3390 - val_acc: 0.8615\n",
      "Epoch 402/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3878 - acc: 0.8391 - val_loss: 0.3385 - val_acc: 0.8625\n",
      "Epoch 403/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3898 - acc: 0.8424 - val_loss: 0.3393 - val_acc: 0.8610\n",
      "Epoch 404/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3954 - acc: 0.8360 - val_loss: 0.3408 - val_acc: 0.8610\n",
      "Epoch 405/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3839 - acc: 0.8435 - val_loss: 0.3373 - val_acc: 0.8600\n",
      "Epoch 406/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3903 - acc: 0.8395 - val_loss: 0.3397 - val_acc: 0.8635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3912 - acc: 0.8385 - val_loss: 0.3389 - val_acc: 0.8635\n",
      "Epoch 408/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3891 - acc: 0.8413 - val_loss: 0.3406 - val_acc: 0.8610\n",
      "Epoch 409/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3891 - acc: 0.8414 - val_loss: 0.3398 - val_acc: 0.8605\n",
      "Epoch 410/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3882 - acc: 0.8419 - val_loss: 0.3384 - val_acc: 0.8600\n",
      "Epoch 411/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3932 - acc: 0.8374 - val_loss: 0.3406 - val_acc: 0.8585\n",
      "Epoch 412/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3946 - acc: 0.8338 - val_loss: 0.3413 - val_acc: 0.8605\n",
      "Epoch 413/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3856 - acc: 0.8395 - val_loss: 0.3385 - val_acc: 0.8610\n",
      "Epoch 414/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3883 - acc: 0.8365 - val_loss: 0.3382 - val_acc: 0.8630\n",
      "Epoch 415/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3908 - acc: 0.8420 - val_loss: 0.3387 - val_acc: 0.8620\n",
      "Epoch 416/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3900 - acc: 0.8367 - val_loss: 0.3386 - val_acc: 0.8610\n",
      "Epoch 417/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3878 - acc: 0.8431 - val_loss: 0.3398 - val_acc: 0.8595\n",
      "Epoch 418/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3954 - acc: 0.8365 - val_loss: 0.3391 - val_acc: 0.8620\n",
      "Epoch 419/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3921 - acc: 0.8379 - val_loss: 0.3397 - val_acc: 0.8615\n",
      "Epoch 420/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3878 - acc: 0.8411 - val_loss: 0.3383 - val_acc: 0.8610\n",
      "Epoch 421/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3906 - acc: 0.8422 - val_loss: 0.3386 - val_acc: 0.8605\n",
      "Epoch 422/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3932 - acc: 0.8381 - val_loss: 0.3392 - val_acc: 0.8605\n",
      "Epoch 423/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3851 - acc: 0.8432 - val_loss: 0.3388 - val_acc: 0.8615\n",
      "Epoch 424/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3924 - acc: 0.8419 - val_loss: 0.3396 - val_acc: 0.8630\n",
      "Epoch 425/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3867 - acc: 0.8416 - val_loss: 0.3386 - val_acc: 0.8610\n",
      "Epoch 426/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3848 - acc: 0.8407 - val_loss: 0.3379 - val_acc: 0.8615\n",
      "Epoch 427/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3845 - acc: 0.8435 - val_loss: 0.3385 - val_acc: 0.8615\n",
      "Epoch 428/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3841 - acc: 0.8434 - val_loss: 0.3365 - val_acc: 0.8615\n",
      "Epoch 429/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3864 - acc: 0.8416 - val_loss: 0.3373 - val_acc: 0.8615\n",
      "Epoch 430/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3919 - acc: 0.8394 - val_loss: 0.3373 - val_acc: 0.8630\n",
      "Epoch 431/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3861 - acc: 0.8390 - val_loss: 0.3380 - val_acc: 0.8625\n",
      "Epoch 432/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3893 - acc: 0.8401 - val_loss: 0.3386 - val_acc: 0.8640\n",
      "Epoch 433/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3850 - acc: 0.8405 - val_loss: 0.3379 - val_acc: 0.8610\n",
      "Epoch 434/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3823 - acc: 0.8445 - val_loss: 0.3376 - val_acc: 0.8600\n",
      "Epoch 435/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3810 - acc: 0.8455 - val_loss: 0.3371 - val_acc: 0.8625\n",
      "Epoch 436/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3893 - acc: 0.8434 - val_loss: 0.3390 - val_acc: 0.8640\n",
      "Epoch 437/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3899 - acc: 0.8401 - val_loss: 0.3396 - val_acc: 0.8630\n",
      "Epoch 438/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3906 - acc: 0.8394 - val_loss: 0.3387 - val_acc: 0.8640\n",
      "Epoch 439/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3897 - acc: 0.8406 - val_loss: 0.3376 - val_acc: 0.8620\n",
      "Epoch 440/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3856 - acc: 0.8385 - val_loss: 0.3378 - val_acc: 0.8625\n",
      "Epoch 441/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3888 - acc: 0.8431 - val_loss: 0.3390 - val_acc: 0.8610\n",
      "Epoch 442/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3832 - acc: 0.8451 - val_loss: 0.3392 - val_acc: 0.8630\n",
      "Epoch 443/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3883 - acc: 0.8407 - val_loss: 0.3401 - val_acc: 0.8630\n",
      "Epoch 444/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3919 - acc: 0.8394 - val_loss: 0.3404 - val_acc: 0.8620\n",
      "Epoch 445/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3898 - acc: 0.8428 - val_loss: 0.3400 - val_acc: 0.8635\n",
      "Epoch 446/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3913 - acc: 0.8390 - val_loss: 0.3392 - val_acc: 0.8620\n",
      "Epoch 447/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3934 - acc: 0.8371 - val_loss: 0.3390 - val_acc: 0.8640\n",
      "Epoch 448/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3896 - acc: 0.8405 - val_loss: 0.3389 - val_acc: 0.8625\n",
      "Epoch 449/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3883 - acc: 0.8413 - val_loss: 0.3397 - val_acc: 0.8630\n",
      "Epoch 450/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3823 - acc: 0.8410 - val_loss: 0.3379 - val_acc: 0.8645\n",
      "Epoch 451/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3850 - acc: 0.8422 - val_loss: 0.3373 - val_acc: 0.8635\n",
      "Epoch 452/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3871 - acc: 0.8419 - val_loss: 0.3375 - val_acc: 0.8615\n",
      "Epoch 453/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3867 - acc: 0.8460 - val_loss: 0.3385 - val_acc: 0.8620\n",
      "Epoch 454/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3849 - acc: 0.8406 - val_loss: 0.3361 - val_acc: 0.8620\n",
      "Epoch 455/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3878 - acc: 0.8393 - val_loss: 0.3379 - val_acc: 0.8625\n",
      "Epoch 456/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3867 - acc: 0.8422 - val_loss: 0.3378 - val_acc: 0.8625\n",
      "Epoch 457/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3856 - acc: 0.8435 - val_loss: 0.3386 - val_acc: 0.8625\n",
      "Epoch 458/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3870 - acc: 0.8406 - val_loss: 0.3375 - val_acc: 0.8625\n",
      "Epoch 459/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3872 - acc: 0.8435 - val_loss: 0.3382 - val_acc: 0.8610\n",
      "Epoch 460/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3874 - acc: 0.8440 - val_loss: 0.3390 - val_acc: 0.8600\n",
      "Epoch 461/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3945 - acc: 0.8385 - val_loss: 0.3394 - val_acc: 0.8620\n",
      "Epoch 462/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3846 - acc: 0.8440 - val_loss: 0.3384 - val_acc: 0.8615\n",
      "Epoch 463/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3894 - acc: 0.8365 - val_loss: 0.3383 - val_acc: 0.8640\n",
      "Epoch 464/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3869 - acc: 0.8446 - val_loss: 0.3375 - val_acc: 0.8655\n",
      "Epoch 465/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3883 - acc: 0.8404 - val_loss: 0.3386 - val_acc: 0.8620\n",
      "Epoch 466/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3869 - acc: 0.8439 - val_loss: 0.3371 - val_acc: 0.8625\n",
      "Epoch 467/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3940 - acc: 0.835 - 0s 50us/sample - loss: 0.3919 - acc: 0.8372 - val_loss: 0.3389 - val_acc: 0.8625\n",
      "Epoch 468/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3924 - acc: 0.8414 - val_loss: 0.3385 - val_acc: 0.8635\n",
      "Epoch 469/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3780 - acc: 0.8426 - val_loss: 0.3379 - val_acc: 0.8625\n",
      "Epoch 470/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3884 - acc: 0.8413 - val_loss: 0.3385 - val_acc: 0.8615\n",
      "Epoch 471/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3851 - acc: 0.8445 - val_loss: 0.3384 - val_acc: 0.8635\n",
      "Epoch 472/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3869 - acc: 0.8425 - val_loss: 0.3393 - val_acc: 0.8615\n",
      "Epoch 473/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3900 - acc: 0.8396 - val_loss: 0.3384 - val_acc: 0.8625\n",
      "Epoch 474/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3870 - acc: 0.8414 - val_loss: 0.3375 - val_acc: 0.8630\n",
      "Epoch 475/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3891 - acc: 0.8420 - val_loss: 0.3376 - val_acc: 0.8630\n",
      "Epoch 476/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3850 - acc: 0.8434 - val_loss: 0.3379 - val_acc: 0.8630\n",
      "Epoch 477/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3852 - acc: 0.8374 - val_loss: 0.3388 - val_acc: 0.8630\n",
      "Epoch 478/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3876 - acc: 0.8419 - val_loss: 0.3393 - val_acc: 0.8635\n",
      "Epoch 479/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3870 - acc: 0.8391 - val_loss: 0.3376 - val_acc: 0.8650\n",
      "Epoch 480/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3818 - acc: 0.8453 - val_loss: 0.3384 - val_acc: 0.8650\n",
      "Epoch 481/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3839 - acc: 0.8439 - val_loss: 0.3378 - val_acc: 0.8620\n",
      "Epoch 482/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3894 - acc: 0.8394 - val_loss: 0.3384 - val_acc: 0.8630\n",
      "Epoch 483/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3908 - acc: 0.8414 - val_loss: 0.3391 - val_acc: 0.8630\n",
      "Epoch 484/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3892 - acc: 0.8395 - val_loss: 0.3386 - val_acc: 0.8640\n",
      "Epoch 485/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3895 - acc: 0.8411 - val_loss: 0.3388 - val_acc: 0.8610\n",
      "Epoch 486/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3853 - acc: 0.8414 - val_loss: 0.3382 - val_acc: 0.8605\n",
      "Epoch 487/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3865 - acc: 0.8390 - val_loss: 0.3383 - val_acc: 0.8625\n",
      "Epoch 488/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3915 - acc: 0.8369 - val_loss: 0.3388 - val_acc: 0.8635\n",
      "Epoch 489/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3843 - acc: 0.8453 - val_loss: 0.3374 - val_acc: 0.8620\n",
      "Epoch 490/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3873 - acc: 0.8421 - val_loss: 0.3383 - val_acc: 0.8600\n",
      "Epoch 491/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3838 - acc: 0.8404 - val_loss: 0.3384 - val_acc: 0.8635\n",
      "Epoch 492/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3836 - acc: 0.8450 - val_loss: 0.3382 - val_acc: 0.8630\n",
      "Epoch 493/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3903 - acc: 0.8416 - val_loss: 0.3400 - val_acc: 0.8625\n",
      "Epoch 494/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3871 - acc: 0.8399 - val_loss: 0.3388 - val_acc: 0.8615\n",
      "Epoch 495/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3832 - acc: 0.8424 - val_loss: 0.3399 - val_acc: 0.8645\n",
      "Epoch 496/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3835 - acc: 0.8419 - val_loss: 0.3390 - val_acc: 0.8620\n",
      "Epoch 497/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3914 - acc: 0.8400 - val_loss: 0.3386 - val_acc: 0.8625\n",
      "Epoch 498/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3851 - acc: 0.8434 - val_loss: 0.3379 - val_acc: 0.8610\n",
      "Epoch 499/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3903 - acc: 0.8382 - val_loss: 0.3374 - val_acc: 0.8605\n",
      "Epoch 500/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3873 - acc: 0.8374 - val_loss: 0.3375 - val_acc: 0.8615\n",
      "Epoch 501/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3844 - acc: 0.8404 - val_loss: 0.3386 - val_acc: 0.8640\n",
      "Epoch 502/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3789 - acc: 0.8466 - val_loss: 0.3363 - val_acc: 0.8630\n",
      "Epoch 503/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3912 - acc: 0.8422 - val_loss: 0.3368 - val_acc: 0.8645\n",
      "Epoch 504/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3873 - acc: 0.8405 - val_loss: 0.3374 - val_acc: 0.8630\n",
      "Epoch 505/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3853 - acc: 0.8431 - val_loss: 0.3383 - val_acc: 0.8625\n",
      "Epoch 506/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3814 - acc: 0.8429 - val_loss: 0.3372 - val_acc: 0.8620\n",
      "Epoch 507/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3891 - acc: 0.8414 - val_loss: 0.3386 - val_acc: 0.8620\n",
      "Epoch 508/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3894 - acc: 0.8406 - val_loss: 0.3398 - val_acc: 0.8620\n",
      "Epoch 509/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3865 - acc: 0.8439 - val_loss: 0.3385 - val_acc: 0.8640\n",
      "Epoch 510/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3869 - acc: 0.8428 - val_loss: 0.3384 - val_acc: 0.8640\n",
      "Epoch 511/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3899 - acc: 0.8378 - val_loss: 0.3385 - val_acc: 0.8630\n",
      "Epoch 512/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3874 - acc: 0.8372 - val_loss: 0.3379 - val_acc: 0.8640\n",
      "Epoch 513/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3820 - acc: 0.8406 - val_loss: 0.3370 - val_acc: 0.8625\n",
      "Epoch 514/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3854 - acc: 0.8435 - val_loss: 0.3366 - val_acc: 0.8620\n",
      "Epoch 515/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3803 - acc: 0.8447 - val_loss: 0.3372 - val_acc: 0.8645\n",
      "Epoch 516/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3850 - acc: 0.8410 - val_loss: 0.3379 - val_acc: 0.8625\n",
      "Epoch 517/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3766 - acc: 0.8462 - val_loss: 0.3361 - val_acc: 0.8645\n",
      "Epoch 518/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3834 - acc: 0.8446 - val_loss: 0.3374 - val_acc: 0.8640\n",
      "Epoch 519/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3823 - acc: 0.8434 - val_loss: 0.3374 - val_acc: 0.8645\n",
      "Epoch 520/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3875 - acc: 0.8397 - val_loss: 0.3374 - val_acc: 0.8615\n",
      "Epoch 521/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3828 - acc: 0.8453 - val_loss: 0.3370 - val_acc: 0.8640\n",
      "Epoch 522/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3852 - acc: 0.8431 - val_loss: 0.3364 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3877 - acc: 0.8416 - val_loss: 0.3372 - val_acc: 0.8660\n",
      "Epoch 524/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3888 - acc: 0.8447 - val_loss: 0.3400 - val_acc: 0.8650\n",
      "Epoch 525/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3819 - acc: 0.8430 - val_loss: 0.3386 - val_acc: 0.8665\n",
      "Epoch 526/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3859 - acc: 0.8422 - val_loss: 0.3388 - val_acc: 0.8625\n",
      "Epoch 527/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3890 - acc: 0.8404 - val_loss: 0.3383 - val_acc: 0.8615\n",
      "Epoch 528/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3880 - acc: 0.8401 - val_loss: 0.3387 - val_acc: 0.8630\n",
      "Epoch 529/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3819 - acc: 0.8425 - val_loss: 0.3381 - val_acc: 0.8640\n",
      "Epoch 530/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3900 - acc: 0.8380 - val_loss: 0.3377 - val_acc: 0.8645\n",
      "Epoch 531/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3853 - acc: 0.8414 - val_loss: 0.3377 - val_acc: 0.8630\n",
      "Epoch 532/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3877 - acc: 0.8420 - val_loss: 0.3372 - val_acc: 0.8630\n",
      "Epoch 533/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3889 - acc: 0.8436 - val_loss: 0.3375 - val_acc: 0.8645\n",
      "Epoch 534/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3863 - acc: 0.8419 - val_loss: 0.3376 - val_acc: 0.8640\n",
      "Epoch 535/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3869 - acc: 0.8384 - val_loss: 0.3372 - val_acc: 0.8615\n",
      "Epoch 536/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3820 - acc: 0.8411 - val_loss: 0.3370 - val_acc: 0.8630\n",
      "Epoch 537/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3905 - acc: 0.8381 - val_loss: 0.3384 - val_acc: 0.8635\n",
      "Epoch 538/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3852 - acc: 0.8422 - val_loss: 0.3380 - val_acc: 0.8625\n",
      "Epoch 539/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3816 - acc: 0.8444 - val_loss: 0.3374 - val_acc: 0.8645\n",
      "Epoch 540/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3867 - acc: 0.8425 - val_loss: 0.3380 - val_acc: 0.8620\n",
      "Epoch 541/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3899 - acc: 0.8365 - val_loss: 0.3389 - val_acc: 0.8630\n",
      "Epoch 542/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3916 - acc: 0.8413 - val_loss: 0.3400 - val_acc: 0.8665\n",
      "Epoch 543/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3867 - acc: 0.8399 - val_loss: 0.3380 - val_acc: 0.8635\n",
      "Epoch 544/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3848 - acc: 0.8440 - val_loss: 0.3372 - val_acc: 0.8630\n",
      "Epoch 545/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3855 - acc: 0.8420 - val_loss: 0.3371 - val_acc: 0.8635\n",
      "Epoch 546/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3822 - acc: 0.8431 - val_loss: 0.3379 - val_acc: 0.8655\n",
      "Epoch 547/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3893 - acc: 0.8407 - val_loss: 0.3379 - val_acc: 0.8660\n",
      "Epoch 548/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3873 - acc: 0.8436 - val_loss: 0.3395 - val_acc: 0.8645\n",
      "Epoch 549/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3845 - acc: 0.8464 - val_loss: 0.3376 - val_acc: 0.8655\n",
      "Epoch 550/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3858 - acc: 0.8422 - val_loss: 0.3380 - val_acc: 0.8640\n",
      "Epoch 551/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3969 - acc: 0.8401 - val_loss: 0.3402 - val_acc: 0.8630\n",
      "Epoch 552/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3885 - acc: 0.8404 - val_loss: 0.3384 - val_acc: 0.8630\n",
      "Epoch 553/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3863 - acc: 0.8429 - val_loss: 0.3380 - val_acc: 0.8645\n",
      "Epoch 554/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3877 - acc: 0.8428 - val_loss: 0.3377 - val_acc: 0.8665\n",
      "Epoch 555/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3882 - acc: 0.8405 - val_loss: 0.3381 - val_acc: 0.8665\n",
      "Epoch 556/1000\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.3825 - acc: 0.8438 - val_loss: 0.3383 - val_acc: 0.8625\n",
      "Epoch 557/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3841 - acc: 0.8441 - val_loss: 0.3383 - val_acc: 0.8640\n",
      "Epoch 558/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3832 - acc: 0.8429 - val_loss: 0.3383 - val_acc: 0.8630\n",
      "Epoch 559/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3832 - acc: 0.8449 - val_loss: 0.3371 - val_acc: 0.8625\n",
      "Epoch 560/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3845 - acc: 0.8434 - val_loss: 0.3368 - val_acc: 0.8625\n",
      "Epoch 561/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3885 - acc: 0.8409 - val_loss: 0.3378 - val_acc: 0.8655\n",
      "Epoch 562/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3893 - acc: 0.8384 - val_loss: 0.3390 - val_acc: 0.8660\n",
      "Epoch 563/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3880 - acc: 0.8405 - val_loss: 0.3385 - val_acc: 0.8655\n",
      "Epoch 564/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3856 - acc: 0.8429 - val_loss: 0.3382 - val_acc: 0.8630\n",
      "Epoch 565/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3882 - acc: 0.8445 - val_loss: 0.3391 - val_acc: 0.8645\n",
      "Epoch 566/1000\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3859 - acc: 0.8456 - val_loss: 0.3374 - val_acc: 0.8655\n",
      "Epoch 567/1000\n",
      "8000/8000 [==============================] - 1s 96us/sample - loss: 0.3864 - acc: 0.8440 - val_loss: 0.3378 - val_acc: 0.8610\n",
      "Epoch 568/1000\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.3895 - acc: 0.8403 - val_loss: 0.3389 - val_acc: 0.8635\n",
      "Epoch 569/1000\n",
      "8000/8000 [==============================] - 1s 125us/sample - loss: 0.3834 - acc: 0.8460 - val_loss: 0.3380 - val_acc: 0.8610\n",
      "Epoch 570/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.3853 - acc: 0.8429 - val_loss: 0.3377 - val_acc: 0.8615\n",
      "Epoch 571/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.3872 - acc: 0.8379 - val_loss: 0.3379 - val_acc: 0.8640\n",
      "Epoch 572/1000\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.3876 - acc: 0.8376 - val_loss: 0.3371 - val_acc: 0.8635\n",
      "Epoch 573/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3842 - acc: 0.8430 - val_loss: 0.3371 - val_acc: 0.8610\n",
      "Epoch 574/1000\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3890 - acc: 0.8378 - val_loss: 0.3377 - val_acc: 0.8620\n",
      "Epoch 575/1000\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.3893 - acc: 0.8415 - val_loss: 0.3386 - val_acc: 0.8610\n",
      "Epoch 576/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3903 - acc: 0.8401 - val_loss: 0.3382 - val_acc: 0.8620\n",
      "Epoch 577/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3844 - acc: 0.8419 - val_loss: 0.3379 - val_acc: 0.8640\n",
      "Epoch 578/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3888 - acc: 0.8447 - val_loss: 0.3394 - val_acc: 0.8630\n",
      "Epoch 579/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3881 - acc: 0.8440 - val_loss: 0.3396 - val_acc: 0.8625\n",
      "Epoch 580/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3873 - acc: 0.8409 - val_loss: 0.3385 - val_acc: 0.8630\n",
      "Epoch 581/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3883 - acc: 0.8413 - val_loss: 0.3372 - val_acc: 0.8605\n",
      "Epoch 582/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3862 - acc: 0.8430 - val_loss: 0.3366 - val_acc: 0.8605\n",
      "Epoch 583/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3891 - acc: 0.8389 - val_loss: 0.3379 - val_acc: 0.8605\n",
      "Epoch 584/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3856 - acc: 0.8414 - val_loss: 0.3369 - val_acc: 0.8620\n",
      "Epoch 585/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3838 - acc: 0.8438 - val_loss: 0.3360 - val_acc: 0.8630\n",
      "Epoch 586/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3874 - acc: 0.8430 - val_loss: 0.3366 - val_acc: 0.8630\n",
      "Epoch 587/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3901 - acc: 0.8385 - val_loss: 0.3386 - val_acc: 0.8635\n",
      "Epoch 588/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3837 - acc: 0.8441 - val_loss: 0.3377 - val_acc: 0.8620\n",
      "Epoch 589/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3858 - acc: 0.8415 - val_loss: 0.3391 - val_acc: 0.8615\n",
      "Epoch 590/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3851 - acc: 0.8429 - val_loss: 0.3384 - val_acc: 0.8640\n",
      "Epoch 591/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3859 - acc: 0.8425 - val_loss: 0.3373 - val_acc: 0.8660\n",
      "Epoch 592/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3859 - acc: 0.8438 - val_loss: 0.3378 - val_acc: 0.8650\n",
      "Epoch 593/1000\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3862 - acc: 0.8453 - val_loss: 0.3379 - val_acc: 0.8640\n",
      "Epoch 594/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3898 - acc: 0.8390 - val_loss: 0.3385 - val_acc: 0.8650\n",
      "Epoch 595/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3801 - acc: 0.8453 - val_loss: 0.3369 - val_acc: 0.8625\n",
      "Epoch 596/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3831 - acc: 0.8475 - val_loss: 0.3366 - val_acc: 0.8645\n",
      "Epoch 597/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3827 - acc: 0.8441 - val_loss: 0.3356 - val_acc: 0.8635\n",
      "Epoch 598/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3841 - acc: 0.8457 - val_loss: 0.3365 - val_acc: 0.8630\n",
      "Epoch 599/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3838 - acc: 0.8445 - val_loss: 0.3368 - val_acc: 0.8635\n",
      "Epoch 600/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3927 - acc: 0.8369 - val_loss: 0.3370 - val_acc: 0.8655\n",
      "Epoch 601/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3880 - acc: 0.8407 - val_loss: 0.3381 - val_acc: 0.8655\n",
      "Epoch 602/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3876 - acc: 0.8419 - val_loss: 0.3380 - val_acc: 0.8660\n",
      "Epoch 603/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3849 - acc: 0.8430 - val_loss: 0.3370 - val_acc: 0.8660\n",
      "Epoch 604/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3792 - acc: 0.8457 - val_loss: 0.3351 - val_acc: 0.8660\n",
      "Epoch 605/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3820 - acc: 0.8446 - val_loss: 0.3362 - val_acc: 0.8645\n",
      "Epoch 606/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3874 - acc: 0.8413 - val_loss: 0.3371 - val_acc: 0.8660\n",
      "Epoch 607/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3845 - acc: 0.8420 - val_loss: 0.3379 - val_acc: 0.8635\n",
      "Epoch 608/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3888 - acc: 0.8406 - val_loss: 0.3380 - val_acc: 0.8630\n",
      "Epoch 609/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3857 - acc: 0.8420 - val_loss: 0.3372 - val_acc: 0.8585\n",
      "Epoch 610/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3818 - acc: 0.8426 - val_loss: 0.3373 - val_acc: 0.8640\n",
      "Epoch 611/1000\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.3898 - acc: 0.8397 - val_loss: 0.3374 - val_acc: 0.8645\n",
      "Epoch 612/1000\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.3905 - acc: 0.8375 - val_loss: 0.3378 - val_acc: 0.8655\n",
      "Epoch 613/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3906 - acc: 0.8357 - val_loss: 0.3383 - val_acc: 0.8660\n",
      "Epoch 614/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3881 - acc: 0.8418 - val_loss: 0.3388 - val_acc: 0.8655\n",
      "Epoch 615/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3847 - acc: 0.8447 - val_loss: 0.3374 - val_acc: 0.8670\n",
      "Epoch 616/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3892 - acc: 0.8401 - val_loss: 0.3395 - val_acc: 0.8660\n",
      "Epoch 617/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3823 - acc: 0.8443 - val_loss: 0.3378 - val_acc: 0.8640\n",
      "Epoch 618/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3786 - acc: 0.8439 - val_loss: 0.3360 - val_acc: 0.8630\n",
      "Epoch 619/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3848 - acc: 0.8443 - val_loss: 0.3385 - val_acc: 0.8650\n",
      "Epoch 620/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3858 - acc: 0.8401 - val_loss: 0.3374 - val_acc: 0.8655\n",
      "Epoch 621/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3849 - acc: 0.8407 - val_loss: 0.3362 - val_acc: 0.8645\n",
      "Epoch 622/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3876 - acc: 0.8434 - val_loss: 0.3376 - val_acc: 0.8640\n",
      "Epoch 623/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3899 - acc: 0.8409 - val_loss: 0.3378 - val_acc: 0.8650\n",
      "Epoch 624/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3865 - acc: 0.8397 - val_loss: 0.3377 - val_acc: 0.8650\n",
      "Epoch 625/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3836 - acc: 0.8444 - val_loss: 0.3368 - val_acc: 0.8640\n",
      "Epoch 626/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3814 - acc: 0.8461 - val_loss: 0.3344 - val_acc: 0.8665\n",
      "Epoch 627/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3880 - acc: 0.8431 - val_loss: 0.3348 - val_acc: 0.8665\n",
      "Epoch 628/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3815 - acc: 0.8438 - val_loss: 0.3343 - val_acc: 0.8635\n",
      "Epoch 629/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3862 - acc: 0.8414 - val_loss: 0.3351 - val_acc: 0.8630\n",
      "Epoch 630/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3874 - acc: 0.8406 - val_loss: 0.3352 - val_acc: 0.8655\n",
      "Epoch 631/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3922 - acc: 0.8367 - val_loss: 0.3378 - val_acc: 0.8655\n",
      "Epoch 632/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3855 - acc: 0.8411 - val_loss: 0.3378 - val_acc: 0.8640\n",
      "Epoch 633/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3860 - acc: 0.8424 - val_loss: 0.3383 - val_acc: 0.8640\n",
      "Epoch 634/1000\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.3816 - acc: 0.8440 - val_loss: 0.3355 - val_acc: 0.8640\n",
      "Epoch 635/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3912 - acc: 0.8393 - val_loss: 0.3372 - val_acc: 0.8645\n",
      "Epoch 636/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3835 - acc: 0.8436 - val_loss: 0.3370 - val_acc: 0.8635\n",
      "Epoch 637/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3817 - acc: 0.8409 - val_loss: 0.3348 - val_acc: 0.8650\n",
      "Epoch 638/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3839 - acc: 0.8434 - val_loss: 0.3359 - val_acc: 0.8680\n",
      "Epoch 639/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3873 - acc: 0.8410 - val_loss: 0.3352 - val_acc: 0.8675\n",
      "Epoch 640/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3936 - acc: 0.8374 - val_loss: 0.3373 - val_acc: 0.8685\n",
      "Epoch 641/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3852 - acc: 0.8403 - val_loss: 0.3373 - val_acc: 0.8680\n",
      "Epoch 642/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3849 - acc: 0.8409 - val_loss: 0.3368 - val_acc: 0.8660\n",
      "Epoch 643/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3873 - acc: 0.8419 - val_loss: 0.3368 - val_acc: 0.8655\n",
      "Epoch 644/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3913 - acc: 0.8388 - val_loss: 0.3379 - val_acc: 0.8660\n",
      "Epoch 645/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3880 - acc: 0.8385 - val_loss: 0.3372 - val_acc: 0.8645\n",
      "Epoch 646/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3841 - acc: 0.8419 - val_loss: 0.3357 - val_acc: 0.8630\n",
      "Epoch 647/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3842 - acc: 0.8418 - val_loss: 0.3357 - val_acc: 0.8645\n",
      "Epoch 648/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3774 - acc: 0.8461 - val_loss: 0.3353 - val_acc: 0.8655\n",
      "Epoch 649/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3718 - acc: 0.8495 - val_loss: 0.3339 - val_acc: 0.8645\n",
      "Epoch 650/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3871 - acc: 0.8422 - val_loss: 0.3360 - val_acc: 0.8645\n",
      "Epoch 651/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3880 - acc: 0.8420 - val_loss: 0.3368 - val_acc: 0.8650\n",
      "Epoch 652/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3862 - acc: 0.8403 - val_loss: 0.3356 - val_acc: 0.8640\n",
      "Epoch 653/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3861 - acc: 0.8430 - val_loss: 0.3370 - val_acc: 0.8640\n",
      "Epoch 654/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3884 - acc: 0.8407 - val_loss: 0.3374 - val_acc: 0.8650\n",
      "Epoch 655/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3937 - acc: 0.8372 - val_loss: 0.3372 - val_acc: 0.8645\n",
      "Epoch 656/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3860 - acc: 0.8435 - val_loss: 0.3362 - val_acc: 0.8635\n",
      "Epoch 657/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3814 - acc: 0.8435 - val_loss: 0.3353 - val_acc: 0.8635\n",
      "Epoch 658/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3830 - acc: 0.8414 - val_loss: 0.3348 - val_acc: 0.8645\n",
      "Epoch 659/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3892 - acc: 0.8390 - val_loss: 0.3349 - val_acc: 0.8645\n",
      "Epoch 660/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3866 - acc: 0.8411 - val_loss: 0.3355 - val_acc: 0.8660\n",
      "Epoch 661/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3850 - acc: 0.8414 - val_loss: 0.3358 - val_acc: 0.8680\n",
      "Epoch 662/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3815 - acc: 0.8469 - val_loss: 0.3347 - val_acc: 0.8655\n",
      "Epoch 663/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3885 - acc: 0.8375 - val_loss: 0.3356 - val_acc: 0.8655\n",
      "Epoch 664/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3886 - acc: 0.8419 - val_loss: 0.3350 - val_acc: 0.8690\n",
      "Epoch 665/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3863 - acc: 0.8422 - val_loss: 0.3352 - val_acc: 0.8675\n",
      "Epoch 666/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3880 - acc: 0.8414 - val_loss: 0.3356 - val_acc: 0.8690\n",
      "Epoch 667/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3903 - acc: 0.8372 - val_loss: 0.3354 - val_acc: 0.8690\n",
      "Epoch 668/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3799 - acc: 0.8460 - val_loss: 0.3346 - val_acc: 0.8665\n",
      "Epoch 669/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3868 - acc: 0.8421 - val_loss: 0.3358 - val_acc: 0.8680\n",
      "Epoch 670/1000\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 0.3935 - acc: 0.8381 - val_loss: 0.3375 - val_acc: 0.8640\n",
      "Epoch 671/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3771 - acc: 0.846 - 1s 65us/sample - loss: 0.3769 - acc: 0.8470 - val_loss: 0.3342 - val_acc: 0.8660\n",
      "Epoch 672/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3848 - acc: 0.8409 - val_loss: 0.3344 - val_acc: 0.8665\n",
      "Epoch 673/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3832 - acc: 0.8445 - val_loss: 0.3342 - val_acc: 0.8685\n",
      "Epoch 674/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3838 - acc: 0.8465 - val_loss: 0.3334 - val_acc: 0.8680\n",
      "Epoch 675/1000\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3849 - acc: 0.8420 - val_loss: 0.3326 - val_acc: 0.8685\n",
      "Epoch 676/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3806 - acc: 0.8441 - val_loss: 0.3336 - val_acc: 0.8675\n",
      "Epoch 677/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3920 - acc: 0.8409 - val_loss: 0.3354 - val_acc: 0.8675\n",
      "Epoch 678/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3842 - acc: 0.8474 - val_loss: 0.3353 - val_acc: 0.8670\n",
      "Epoch 679/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3881 - acc: 0.8409 - val_loss: 0.3368 - val_acc: 0.8645\n",
      "Epoch 680/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3847 - acc: 0.8447 - val_loss: 0.3363 - val_acc: 0.8645\n",
      "Epoch 681/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3826 - acc: 0.8419 - val_loss: 0.3342 - val_acc: 0.8665\n",
      "Epoch 682/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3852 - acc: 0.8432 - val_loss: 0.3334 - val_acc: 0.8655\n",
      "Epoch 683/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3836 - acc: 0.8421 - val_loss: 0.3332 - val_acc: 0.8670\n",
      "Epoch 684/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3902 - acc: 0.8401 - val_loss: 0.3336 - val_acc: 0.8645\n",
      "Epoch 685/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3831 - acc: 0.8441 - val_loss: 0.3331 - val_acc: 0.8655\n",
      "Epoch 686/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3869 - acc: 0.8419 - val_loss: 0.3338 - val_acc: 0.8650\n",
      "Epoch 687/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3852 - acc: 0.8396 - val_loss: 0.3362 - val_acc: 0.8635\n",
      "Epoch 688/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3836 - acc: 0.8444 - val_loss: 0.3360 - val_acc: 0.8635\n",
      "Epoch 689/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3840 - acc: 0.8406 - val_loss: 0.3356 - val_acc: 0.8630\n",
      "Epoch 690/1000\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3808 - acc: 0.8432 - val_loss: 0.3343 - val_acc: 0.8645\n",
      "Epoch 691/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3814 - acc: 0.8457 - val_loss: 0.3347 - val_acc: 0.8640\n",
      "Epoch 692/1000\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 0.3834 - acc: 0.8443 - val_loss: 0.3343 - val_acc: 0.8655\n",
      "Epoch 693/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3836 - acc: 0.8411 - val_loss: 0.3343 - val_acc: 0.8640\n",
      "Epoch 694/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3839 - acc: 0.8422 - val_loss: 0.3341 - val_acc: 0.8630\n",
      "Epoch 695/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3876 - acc: 0.8400 - val_loss: 0.3354 - val_acc: 0.8635\n",
      "Epoch 696/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3869 - acc: 0.8401 - val_loss: 0.3354 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3887 - acc: 0.8400 - val_loss: 0.3360 - val_acc: 0.8635\n",
      "Epoch 698/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3852 - acc: 0.8429 - val_loss: 0.3355 - val_acc: 0.8640\n",
      "Epoch 699/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3845 - acc: 0.8419 - val_loss: 0.3367 - val_acc: 0.8650\n",
      "Epoch 700/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3921 - acc: 0.8389 - val_loss: 0.3380 - val_acc: 0.8615\n",
      "Epoch 701/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3845 - acc: 0.8446 - val_loss: 0.3372 - val_acc: 0.8640\n",
      "Epoch 702/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3850 - acc: 0.8397 - val_loss: 0.3361 - val_acc: 0.8655\n",
      "Epoch 703/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3771 - acc: 0.8491 - val_loss: 0.3352 - val_acc: 0.8675\n",
      "Epoch 704/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3855 - acc: 0.8405 - val_loss: 0.3352 - val_acc: 0.8650\n",
      "Epoch 705/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3843 - acc: 0.8411 - val_loss: 0.3351 - val_acc: 0.8645\n",
      "Epoch 706/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3870 - acc: 0.8393 - val_loss: 0.3361 - val_acc: 0.8640\n",
      "Epoch 707/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3827 - acc: 0.8401 - val_loss: 0.3346 - val_acc: 0.8640\n",
      "Epoch 708/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3830 - acc: 0.8409 - val_loss: 0.3333 - val_acc: 0.8660\n",
      "Epoch 709/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3841 - acc: 0.8420 - val_loss: 0.3350 - val_acc: 0.8630\n",
      "Epoch 710/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3863 - acc: 0.8393 - val_loss: 0.3369 - val_acc: 0.8635\n",
      "Epoch 711/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3839 - acc: 0.8416 - val_loss: 0.3352 - val_acc: 0.8650\n",
      "Epoch 712/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3896 - acc: 0.8386 - val_loss: 0.3351 - val_acc: 0.8645\n",
      "Epoch 713/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3834 - acc: 0.8451 - val_loss: 0.3345 - val_acc: 0.8665\n",
      "Epoch 714/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3865 - acc: 0.8407 - val_loss: 0.3356 - val_acc: 0.8665\n",
      "Epoch 715/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3857 - acc: 0.8414 - val_loss: 0.3369 - val_acc: 0.8635\n",
      "Epoch 716/1000\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.3885 - acc: 0.8410 - val_loss: 0.3359 - val_acc: 0.8650\n",
      "Epoch 717/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3924 - acc: 0.8393 - val_loss: 0.3372 - val_acc: 0.8635\n",
      "Epoch 718/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3875 - acc: 0.8405 - val_loss: 0.3375 - val_acc: 0.8665\n",
      "Epoch 719/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3809 - acc: 0.8432 - val_loss: 0.3345 - val_acc: 0.8675\n",
      "Epoch 720/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3841 - acc: 0.8447 - val_loss: 0.3356 - val_acc: 0.8660\n",
      "Epoch 721/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3824 - acc: 0.8418 - val_loss: 0.3352 - val_acc: 0.8660\n",
      "Epoch 722/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3874 - acc: 0.8434 - val_loss: 0.3360 - val_acc: 0.8675\n",
      "Epoch 723/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3879 - acc: 0.8410 - val_loss: 0.3353 - val_acc: 0.8655\n",
      "Epoch 724/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3855 - acc: 0.8462 - val_loss: 0.3357 - val_acc: 0.8645\n",
      "Epoch 725/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3843 - acc: 0.8446 - val_loss: 0.3354 - val_acc: 0.8630\n",
      "Epoch 726/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3907 - acc: 0.8390 - val_loss: 0.3360 - val_acc: 0.8670\n",
      "Epoch 727/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3835 - acc: 0.8471 - val_loss: 0.3343 - val_acc: 0.8655\n",
      "Epoch 728/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3872 - acc: 0.8406 - val_loss: 0.3345 - val_acc: 0.8680\n",
      "Epoch 729/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3844 - acc: 0.8396 - val_loss: 0.3351 - val_acc: 0.8655\n",
      "Epoch 730/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3803 - acc: 0.8450 - val_loss: 0.3346 - val_acc: 0.8685\n",
      "Epoch 731/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3843 - acc: 0.8399 - val_loss: 0.3356 - val_acc: 0.8660\n",
      "Epoch 732/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3875 - acc: 0.8420 - val_loss: 0.3359 - val_acc: 0.8680\n",
      "Epoch 733/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3802 - acc: 0.8446 - val_loss: 0.3344 - val_acc: 0.8670\n",
      "Epoch 734/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3783 - acc: 0.8462 - val_loss: 0.3343 - val_acc: 0.8650\n",
      "Epoch 735/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3919 - acc: 0.8418 - val_loss: 0.3362 - val_acc: 0.8640\n",
      "Epoch 736/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3854 - acc: 0.8425 - val_loss: 0.3347 - val_acc: 0.8670\n",
      "Epoch 737/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3865 - acc: 0.8400 - val_loss: 0.3351 - val_acc: 0.8665\n",
      "Epoch 738/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3872 - acc: 0.8430 - val_loss: 0.3375 - val_acc: 0.8650\n",
      "Epoch 739/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3841 - acc: 0.8434 - val_loss: 0.3355 - val_acc: 0.8665\n",
      "Epoch 740/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3850 - acc: 0.8372 - val_loss: 0.3350 - val_acc: 0.8670\n",
      "Epoch 741/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3834 - acc: 0.8451 - val_loss: 0.3343 - val_acc: 0.8675\n",
      "Epoch 742/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3810 - acc: 0.8436 - val_loss: 0.3353 - val_acc: 0.8645\n",
      "Epoch 743/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3834 - acc: 0.8434 - val_loss: 0.3361 - val_acc: 0.8685\n",
      "Epoch 744/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3925 - acc: 0.8386 - val_loss: 0.3362 - val_acc: 0.8685\n",
      "Epoch 745/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3869 - acc: 0.837 - 0s 60us/sample - loss: 0.3839 - acc: 0.8399 - val_loss: 0.3358 - val_acc: 0.8685\n",
      "Epoch 746/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3777 - acc: 0.8450 - val_loss: 0.3345 - val_acc: 0.8675\n",
      "Epoch 747/1000\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.3818 - acc: 0.8434 - val_loss: 0.3358 - val_acc: 0.8670\n",
      "Epoch 748/1000\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.3765 - acc: 0.8471 - val_loss: 0.3338 - val_acc: 0.8675\n",
      "Epoch 749/1000\n",
      "8000/8000 [==============================] - 1s 92us/sample - loss: 0.3894 - acc: 0.8400 - val_loss: 0.3357 - val_acc: 0.8690\n",
      "Epoch 750/1000\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.3866 - acc: 0.8400 - val_loss: 0.3351 - val_acc: 0.8685\n",
      "Epoch 751/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3808 - acc: 0.8441 - val_loss: 0.3360 - val_acc: 0.8670\n",
      "Epoch 752/1000\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.3834 - acc: 0.8429 - val_loss: 0.3359 - val_acc: 0.8675\n",
      "Epoch 753/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3859 - acc: 0.8415 - val_loss: 0.3360 - val_acc: 0.8670\n",
      "Epoch 754/1000\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3819 - acc: 0.8471 - val_loss: 0.3348 - val_acc: 0.8670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 755/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3845 - acc: 0.8439 - val_loss: 0.3359 - val_acc: 0.8665\n",
      "Epoch 756/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3787 - acc: 0.8429 - val_loss: 0.3338 - val_acc: 0.8665\n",
      "Epoch 757/1000\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3843 - acc: 0.8476 - val_loss: 0.3359 - val_acc: 0.8670\n",
      "Epoch 758/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3906 - acc: 0.8385 - val_loss: 0.3365 - val_acc: 0.8645\n",
      "Epoch 759/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3874 - acc: 0.8415 - val_loss: 0.3351 - val_acc: 0.8665\n",
      "Epoch 760/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3870 - acc: 0.8445 - val_loss: 0.3352 - val_acc: 0.8660\n",
      "Epoch 761/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3873 - acc: 0.8420 - val_loss: 0.3354 - val_acc: 0.8635\n",
      "Epoch 762/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3807 - acc: 0.8445 - val_loss: 0.3355 - val_acc: 0.8630\n",
      "Epoch 763/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3815 - acc: 0.8429 - val_loss: 0.3347 - val_acc: 0.8650\n",
      "Epoch 764/1000\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3803 - acc: 0.8431 - val_loss: 0.3344 - val_acc: 0.8650\n",
      "Epoch 765/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3828 - acc: 0.8476 - val_loss: 0.3367 - val_acc: 0.8605\n",
      "Epoch 766/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3843 - acc: 0.8406 - val_loss: 0.3339 - val_acc: 0.8650\n",
      "Epoch 767/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3818 - acc: 0.8450 - val_loss: 0.3338 - val_acc: 0.8670\n",
      "Epoch 768/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3872 - acc: 0.8416 - val_loss: 0.3358 - val_acc: 0.8675\n",
      "Epoch 769/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3865 - acc: 0.841 - 1s 64us/sample - loss: 0.3871 - acc: 0.8413 - val_loss: 0.3352 - val_acc: 0.8680\n",
      "Epoch 770/1000\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3881 - acc: 0.8431 - val_loss: 0.3350 - val_acc: 0.8670\n",
      "Epoch 771/1000\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.3848 - acc: 0.8453 - val_loss: 0.3344 - val_acc: 0.8670\n",
      "Epoch 772/1000\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.3861 - acc: 0.8410 - val_loss: 0.3346 - val_acc: 0.8660\n",
      "Epoch 773/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.3895 - acc: 0.8390 - val_loss: 0.3363 - val_acc: 0.8660\n",
      "Epoch 774/1000\n",
      "8000/8000 [==============================] - 1s 89us/sample - loss: 0.3865 - acc: 0.8447 - val_loss: 0.3373 - val_acc: 0.8665\n",
      "Epoch 775/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3788 - acc: 0.8470 - val_loss: 0.3356 - val_acc: 0.8660\n",
      "Epoch 776/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3884 - acc: 0.8405 - val_loss: 0.3359 - val_acc: 0.8650\n",
      "Epoch 777/1000\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.3820 - acc: 0.8414 - val_loss: 0.3346 - val_acc: 0.8655\n",
      "Epoch 778/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3899 - acc: 0.8431 - val_loss: 0.3369 - val_acc: 0.8680\n",
      "Epoch 779/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3871 - acc: 0.8416 - val_loss: 0.3363 - val_acc: 0.8665\n",
      "Epoch 780/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3830 - acc: 0.8443 - val_loss: 0.3350 - val_acc: 0.8670\n",
      "Epoch 781/1000\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.3815 - acc: 0.8454 - val_loss: 0.3361 - val_acc: 0.8665\n",
      "Epoch 782/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3773 - acc: 0.8462 - val_loss: 0.3343 - val_acc: 0.8670\n",
      "Epoch 783/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3862 - acc: 0.8440 - val_loss: 0.3358 - val_acc: 0.8655\n",
      "Epoch 784/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3798 - acc: 0.8428 - val_loss: 0.3350 - val_acc: 0.8660\n",
      "Epoch 785/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3834 - acc: 0.8443 - val_loss: 0.3355 - val_acc: 0.8655\n",
      "Epoch 786/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3840 - acc: 0.8435 - val_loss: 0.3343 - val_acc: 0.8670\n",
      "Epoch 787/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3838 - acc: 0.8434 - val_loss: 0.3353 - val_acc: 0.8675\n",
      "Epoch 788/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3858 - acc: 0.8428 - val_loss: 0.3361 - val_acc: 0.8675\n",
      "Epoch 789/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3865 - acc: 0.8439 - val_loss: 0.3367 - val_acc: 0.8680\n",
      "Epoch 790/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3867 - acc: 0.8435 - val_loss: 0.3363 - val_acc: 0.8660\n",
      "Epoch 791/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3866 - acc: 0.8420 - val_loss: 0.3345 - val_acc: 0.8680\n",
      "Epoch 792/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3868 - acc: 0.8420 - val_loss: 0.3343 - val_acc: 0.8660\n",
      "Epoch 793/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3838 - acc: 0.8421 - val_loss: 0.3346 - val_acc: 0.8660\n",
      "Epoch 794/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3859 - acc: 0.8434 - val_loss: 0.3365 - val_acc: 0.8675\n",
      "Epoch 795/1000\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3839 - acc: 0.8429 - val_loss: 0.3338 - val_acc: 0.8670\n",
      "Epoch 796/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3906 - acc: 0.8404 - val_loss: 0.3348 - val_acc: 0.8650\n",
      "Epoch 797/1000\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.3873 - acc: 0.8397 - val_loss: 0.3348 - val_acc: 0.8655\n",
      "Epoch 798/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3840 - acc: 0.8419 - val_loss: 0.3354 - val_acc: 0.8680\n",
      "Epoch 799/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3791 - acc: 0.8455 - val_loss: 0.3346 - val_acc: 0.8675\n",
      "Epoch 800/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3887 - acc: 0.8386 - val_loss: 0.3358 - val_acc: 0.8685\n",
      "Epoch 801/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3848 - acc: 0.8393 - val_loss: 0.3360 - val_acc: 0.8695\n",
      "Epoch 802/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3841 - acc: 0.8426 - val_loss: 0.3357 - val_acc: 0.8680\n",
      "Epoch 803/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3882 - acc: 0.8406 - val_loss: 0.3355 - val_acc: 0.8670\n",
      "Epoch 804/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3815 - acc: 0.8435 - val_loss: 0.3342 - val_acc: 0.8660\n",
      "Epoch 805/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3829 - acc: 0.8425 - val_loss: 0.3348 - val_acc: 0.8655\n",
      "Epoch 806/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3840 - acc: 0.8419 - val_loss: 0.3347 - val_acc: 0.8675\n",
      "Epoch 807/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3825 - acc: 0.8422 - val_loss: 0.3343 - val_acc: 0.8685\n",
      "Epoch 808/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3895 - acc: 0.8439 - val_loss: 0.3366 - val_acc: 0.8680\n",
      "Epoch 809/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3829 - acc: 0.8456 - val_loss: 0.3348 - val_acc: 0.8675\n",
      "Epoch 810/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3842 - acc: 0.8445 - val_loss: 0.3348 - val_acc: 0.8670\n",
      "Epoch 811/1000\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.3892 - acc: 0.8407 - val_loss: 0.3367 - val_acc: 0.8660\n",
      "Epoch 812/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3877 - acc: 0.8425 - val_loss: 0.3352 - val_acc: 0.8670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 813/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3876 - acc: 0.8416 - val_loss: 0.3355 - val_acc: 0.8655\n",
      "Epoch 814/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3825 - acc: 0.8451 - val_loss: 0.3347 - val_acc: 0.8655\n",
      "Epoch 815/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3771 - acc: 0.8460 - val_loss: 0.3342 - val_acc: 0.8665\n",
      "Epoch 816/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3866 - acc: 0.8404 - val_loss: 0.3339 - val_acc: 0.8665\n",
      "Epoch 817/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3849 - acc: 0.8419 - val_loss: 0.3344 - val_acc: 0.8685\n",
      "Epoch 818/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3854 - acc: 0.8420 - val_loss: 0.3351 - val_acc: 0.8675\n",
      "Epoch 819/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3824 - acc: 0.8445 - val_loss: 0.3338 - val_acc: 0.8670\n",
      "Epoch 820/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3927 - acc: 0.8378 - val_loss: 0.3361 - val_acc: 0.8675\n",
      "Epoch 821/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3830 - acc: 0.8419 - val_loss: 0.3345 - val_acc: 0.8690\n",
      "Epoch 822/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3864 - acc: 0.8405 - val_loss: 0.3342 - val_acc: 0.8710\n",
      "Epoch 823/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3842 - acc: 0.8424 - val_loss: 0.3339 - val_acc: 0.8680\n",
      "Epoch 824/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3861 - acc: 0.8411 - val_loss: 0.3343 - val_acc: 0.8685\n",
      "Epoch 825/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3890 - acc: 0.8413 - val_loss: 0.3352 - val_acc: 0.8675\n",
      "Epoch 826/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3848 - acc: 0.8410 - val_loss: 0.3350 - val_acc: 0.8690\n",
      "Epoch 827/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3805 - acc: 0.8455 - val_loss: 0.3358 - val_acc: 0.8655\n",
      "Epoch 828/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3884 - acc: 0.8416 - val_loss: 0.3361 - val_acc: 0.8655\n",
      "Epoch 829/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3828 - acc: 0.8404 - val_loss: 0.3371 - val_acc: 0.8655\n",
      "Epoch 830/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3834 - acc: 0.8456 - val_loss: 0.3355 - val_acc: 0.8660\n",
      "Epoch 831/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3837 - acc: 0.8440 - val_loss: 0.3353 - val_acc: 0.8670\n",
      "Epoch 832/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3822 - acc: 0.8429 - val_loss: 0.3354 - val_acc: 0.8670\n",
      "Epoch 833/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3845 - acc: 0.8407 - val_loss: 0.3363 - val_acc: 0.8655\n",
      "Epoch 834/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3842 - acc: 0.8440 - val_loss: 0.3367 - val_acc: 0.8665\n",
      "Epoch 835/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3850 - acc: 0.8436 - val_loss: 0.3356 - val_acc: 0.8670\n",
      "Epoch 836/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3873 - acc: 0.8386 - val_loss: 0.3361 - val_acc: 0.8660\n",
      "Epoch 837/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3833 - acc: 0.8455 - val_loss: 0.3352 - val_acc: 0.8655\n",
      "Epoch 838/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3815 - acc: 0.8447 - val_loss: 0.3346 - val_acc: 0.8690\n",
      "Epoch 839/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3819 - acc: 0.8475 - val_loss: 0.3337 - val_acc: 0.8675\n",
      "Epoch 840/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3815 - acc: 0.8481 - val_loss: 0.3342 - val_acc: 0.8690\n",
      "Epoch 841/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3857 - acc: 0.8430 - val_loss: 0.3353 - val_acc: 0.8680\n",
      "Epoch 842/1000\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.3832 - acc: 0.8460 - val_loss: 0.3349 - val_acc: 0.8665\n",
      "Epoch 843/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3843 - acc: 0.8434 - val_loss: 0.3347 - val_acc: 0.8665\n",
      "Epoch 844/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3821 - acc: 0.8450 - val_loss: 0.3332 - val_acc: 0.8665\n",
      "Epoch 845/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3809 - acc: 0.8429 - val_loss: 0.3356 - val_acc: 0.8655\n",
      "Epoch 846/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3882 - acc: 0.8418 - val_loss: 0.3363 - val_acc: 0.8645\n",
      "Epoch 847/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3846 - acc: 0.8443 - val_loss: 0.3372 - val_acc: 0.8650\n",
      "Epoch 848/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3812 - acc: 0.8447 - val_loss: 0.3369 - val_acc: 0.8680\n",
      "Epoch 849/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3783 - acc: 0.8487 - val_loss: 0.3340 - val_acc: 0.8685\n",
      "Epoch 850/1000\n",
      "8000/8000 [==============================] - 1s 89us/sample - loss: 0.3878 - acc: 0.8429 - val_loss: 0.3346 - val_acc: 0.8695\n",
      "Epoch 851/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3846 - acc: 0.8438 - val_loss: 0.3345 - val_acc: 0.8675\n",
      "Epoch 852/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3836 - acc: 0.8456 - val_loss: 0.3349 - val_acc: 0.8660\n",
      "Epoch 853/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3932 - acc: 0.8406 - val_loss: 0.3365 - val_acc: 0.8660\n",
      "Epoch 854/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3805 - acc: 0.8416 - val_loss: 0.3359 - val_acc: 0.8640\n",
      "Epoch 855/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3892 - acc: 0.8391 - val_loss: 0.3356 - val_acc: 0.8650\n",
      "Epoch 856/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3886 - acc: 0.8425 - val_loss: 0.3361 - val_acc: 0.8640\n",
      "Epoch 857/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3817 - acc: 0.8429 - val_loss: 0.3345 - val_acc: 0.8665\n",
      "Epoch 858/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3768 - acc: 0.8482 - val_loss: 0.3346 - val_acc: 0.8650\n",
      "Epoch 859/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3840 - acc: 0.8439 - val_loss: 0.3343 - val_acc: 0.8650\n",
      "Epoch 860/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3875 - acc: 0.8431 - val_loss: 0.3339 - val_acc: 0.8655\n",
      "Epoch 861/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3797 - acc: 0.8451 - val_loss: 0.3322 - val_acc: 0.8650\n",
      "Epoch 862/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3866 - acc: 0.8407 - val_loss: 0.3339 - val_acc: 0.8645\n",
      "Epoch 863/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3868 - acc: 0.8424 - val_loss: 0.3337 - val_acc: 0.8645\n",
      "Epoch 864/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3857 - acc: 0.8434 - val_loss: 0.3349 - val_acc: 0.8645\n",
      "Epoch 865/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3851 - acc: 0.8416 - val_loss: 0.3333 - val_acc: 0.8660\n",
      "Epoch 866/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3801 - acc: 0.8468 - val_loss: 0.3331 - val_acc: 0.8650\n",
      "Epoch 867/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3821 - acc: 0.8438 - val_loss: 0.3338 - val_acc: 0.8645\n",
      "Epoch 868/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3832 - acc: 0.8436 - val_loss: 0.3346 - val_acc: 0.8650\n",
      "Epoch 869/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3812 - acc: 0.8475 - val_loss: 0.3346 - val_acc: 0.8660\n",
      "Epoch 870/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3815 - acc: 0.8449 - val_loss: 0.3353 - val_acc: 0.8650\n",
      "Epoch 871/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3857 - acc: 0.8453 - val_loss: 0.3360 - val_acc: 0.8675\n",
      "Epoch 872/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3867 - acc: 0.8422 - val_loss: 0.3342 - val_acc: 0.8655\n",
      "Epoch 873/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3864 - acc: 0.8419 - val_loss: 0.3354 - val_acc: 0.8655\n",
      "Epoch 874/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3836 - acc: 0.8449 - val_loss: 0.3350 - val_acc: 0.8660\n",
      "Epoch 875/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3819 - acc: 0.8465 - val_loss: 0.3346 - val_acc: 0.8655\n",
      "Epoch 876/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3851 - acc: 0.8464 - val_loss: 0.3339 - val_acc: 0.8670\n",
      "Epoch 877/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3834 - acc: 0.8436 - val_loss: 0.3345 - val_acc: 0.8665\n",
      "Epoch 878/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3807 - acc: 0.8436 - val_loss: 0.3337 - val_acc: 0.8680\n",
      "Epoch 879/1000\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.3862 - acc: 0.8409 - val_loss: 0.3347 - val_acc: 0.8660\n",
      "Epoch 880/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3815 - acc: 0.8443 - val_loss: 0.3348 - val_acc: 0.8655\n",
      "Epoch 881/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3818 - acc: 0.8444 - val_loss: 0.3329 - val_acc: 0.8660\n",
      "Epoch 882/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3809 - acc: 0.8487 - val_loss: 0.3340 - val_acc: 0.8670\n",
      "Epoch 883/1000\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3850 - acc: 0.8403 - val_loss: 0.3326 - val_acc: 0.8660\n",
      "Epoch 884/1000\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3862 - acc: 0.8432 - val_loss: 0.3335 - val_acc: 0.8660\n",
      "Epoch 885/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3864 - acc: 0.8432 - val_loss: 0.3335 - val_acc: 0.8655\n",
      "Epoch 886/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3827 - acc: 0.8445 - val_loss: 0.3336 - val_acc: 0.8645\n",
      "Epoch 887/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3884 - acc: 0.8432 - val_loss: 0.3353 - val_acc: 0.8675\n",
      "Epoch 888/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3858 - acc: 0.8431 - val_loss: 0.3356 - val_acc: 0.8645\n",
      "Epoch 889/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3882 - acc: 0.8429 - val_loss: 0.3353 - val_acc: 0.8665\n",
      "Epoch 890/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3867 - acc: 0.8436 - val_loss: 0.3363 - val_acc: 0.8665\n",
      "Epoch 891/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3812 - acc: 0.8449 - val_loss: 0.3346 - val_acc: 0.8670\n",
      "Epoch 892/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3824 - acc: 0.8432 - val_loss: 0.3348 - val_acc: 0.8675\n",
      "Epoch 893/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3911 - acc: 0.8375 - val_loss: 0.3359 - val_acc: 0.8645\n",
      "Epoch 894/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3793 - acc: 0.8446 - val_loss: 0.3346 - val_acc: 0.8640\n",
      "Epoch 895/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3865 - acc: 0.8439 - val_loss: 0.3335 - val_acc: 0.8660\n",
      "Epoch 896/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3858 - acc: 0.8419 - val_loss: 0.3332 - val_acc: 0.8660\n",
      "Epoch 897/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3857 - acc: 0.8396 - val_loss: 0.3345 - val_acc: 0.8655\n",
      "Epoch 898/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3844 - acc: 0.8409 - val_loss: 0.3334 - val_acc: 0.8655\n",
      "Epoch 899/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3826 - acc: 0.8469 - val_loss: 0.3327 - val_acc: 0.8655\n",
      "Epoch 900/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3760 - acc: 0.8471 - val_loss: 0.3309 - val_acc: 0.8675\n",
      "Epoch 901/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3817 - acc: 0.8441 - val_loss: 0.3317 - val_acc: 0.8650\n",
      "Epoch 902/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3815 - acc: 0.8434 - val_loss: 0.3326 - val_acc: 0.8650\n",
      "Epoch 903/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3848 - acc: 0.8456 - val_loss: 0.3343 - val_acc: 0.8665\n",
      "Epoch 904/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3781 - acc: 0.8459 - val_loss: 0.3330 - val_acc: 0.8650\n",
      "Epoch 905/1000\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.3863 - acc: 0.8438 - val_loss: 0.3339 - val_acc: 0.8655\n",
      "Epoch 906/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3866 - acc: 0.8415 - val_loss: 0.3340 - val_acc: 0.8650\n",
      "Epoch 907/1000\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3809 - acc: 0.8457 - val_loss: 0.3327 - val_acc: 0.8655\n",
      "Epoch 908/1000\n",
      "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3820 - acc: 0.8436 - val_loss: 0.3326 - val_acc: 0.8665\n",
      "Epoch 909/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3819 - acc: 0.8439 - val_loss: 0.3327 - val_acc: 0.8660\n",
      "Epoch 910/1000\n",
      "8000/8000 [==============================] - 1s 87us/sample - loss: 0.3908 - acc: 0.8376 - val_loss: 0.3348 - val_acc: 0.8640\n",
      "Epoch 911/1000\n",
      "8000/8000 [==============================] - 1s 103us/sample - loss: 0.3838 - acc: 0.8446 - val_loss: 0.3348 - val_acc: 0.8645\n",
      "Epoch 912/1000\n",
      "8000/8000 [==============================] - 1s 88us/sample - loss: 0.3896 - acc: 0.8421 - val_loss: 0.3357 - val_acc: 0.8650\n",
      "Epoch 913/1000\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3870 - acc: 0.8449 - val_loss: 0.3346 - val_acc: 0.8665\n",
      "Epoch 914/1000\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.3837 - acc: 0.8413 - val_loss: 0.3337 - val_acc: 0.8650\n",
      "Epoch 915/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3806 - acc: 0.8471 - val_loss: 0.3338 - val_acc: 0.8650\n",
      "Epoch 916/1000\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.3790 - acc: 0.8501 - val_loss: 0.3340 - val_acc: 0.8660\n",
      "Epoch 917/1000\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.3806 - acc: 0.8421 - val_loss: 0.3331 - val_acc: 0.8665\n",
      "Epoch 918/1000\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.3828 - acc: 0.8434 - val_loss: 0.3333 - val_acc: 0.8660\n",
      "Epoch 919/1000\n",
      "8000/8000 [==============================] - 1s 91us/sample - loss: 0.3872 - acc: 0.8446 - val_loss: 0.3330 - val_acc: 0.8660\n",
      "Epoch 920/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.3818 - acc: 0.8431 - val_loss: 0.3329 - val_acc: 0.8675\n",
      "Epoch 921/1000\n",
      "8000/8000 [==============================] - 1s 84us/sample - loss: 0.3841 - acc: 0.8453 - val_loss: 0.3331 - val_acc: 0.8685\n",
      "Epoch 922/1000\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.3856 - acc: 0.8440 - val_loss: 0.3339 - val_acc: 0.8670\n",
      "Epoch 923/1000\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.3782 - acc: 0.8460 - val_loss: 0.3330 - val_acc: 0.8665\n",
      "Epoch 924/1000\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.3837 - acc: 0.8449 - val_loss: 0.3329 - val_acc: 0.8670\n",
      "Epoch 925/1000\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.3909 - acc: 0.8419 - val_loss: 0.3346 - val_acc: 0.8675\n",
      "Epoch 926/1000\n",
      "8000/8000 [==============================] - 1s 106us/sample - loss: 0.3805 - acc: 0.8420 - val_loss: 0.3324 - val_acc: 0.8680\n",
      "Epoch 927/1000\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.3878 - acc: 0.8405 - val_loss: 0.3332 - val_acc: 0.8660\n",
      "Epoch 928/1000\n",
      "8000/8000 [==============================] - 1s 102us/sample - loss: 0.3794 - acc: 0.8478 - val_loss: 0.3331 - val_acc: 0.8680\n",
      "Epoch 929/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3841 - acc: 0.8447 - val_loss: 0.3332 - val_acc: 0.8680\n",
      "Epoch 930/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3893 - acc: 0.8426 - val_loss: 0.3349 - val_acc: 0.8655\n",
      "Epoch 931/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3870 - acc: 0.8420 - val_loss: 0.3352 - val_acc: 0.8660\n",
      "Epoch 932/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3835 - acc: 0.8470 - val_loss: 0.3359 - val_acc: 0.8660\n",
      "Epoch 933/1000\n",
      "8000/8000 [==============================] - 1s 89us/sample - loss: 0.3838 - acc: 0.8441 - val_loss: 0.3349 - val_acc: 0.8670\n",
      "Epoch 934/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3853 - acc: 0.8449 - val_loss: 0.3329 - val_acc: 0.8675\n",
      "Epoch 935/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3849 - acc: 0.8440 - val_loss: 0.3332 - val_acc: 0.8685\n",
      "Epoch 936/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3831 - acc: 0.8404 - val_loss: 0.3321 - val_acc: 0.8675\n",
      "Epoch 937/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3829 - acc: 0.8426 - val_loss: 0.3338 - val_acc: 0.8655\n",
      "Epoch 938/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3804 - acc: 0.8441 - val_loss: 0.3325 - val_acc: 0.8670\n",
      "Epoch 939/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3892 - acc: 0.8420 - val_loss: 0.3356 - val_acc: 0.8655\n",
      "Epoch 940/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3866 - acc: 0.8351 - val_loss: 0.3349 - val_acc: 0.8680\n",
      "Epoch 941/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3877 - acc: 0.8450 - val_loss: 0.3353 - val_acc: 0.8675\n",
      "Epoch 942/1000\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.3861 - acc: 0.8428 - val_loss: 0.3363 - val_acc: 0.8670\n",
      "Epoch 943/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3734 - acc: 0.8479 - val_loss: 0.3320 - val_acc: 0.8680\n",
      "Epoch 944/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3830 - acc: 0.8456 - val_loss: 0.3336 - val_acc: 0.8665\n",
      "Epoch 945/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3802 - acc: 0.8472 - val_loss: 0.3338 - val_acc: 0.8670\n",
      "Epoch 946/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3840 - acc: 0.8480 - val_loss: 0.3357 - val_acc: 0.8660\n",
      "Epoch 947/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3844 - acc: 0.8450 - val_loss: 0.3353 - val_acc: 0.8655\n",
      "Epoch 948/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3855 - acc: 0.8454 - val_loss: 0.3349 - val_acc: 0.8655\n",
      "Epoch 949/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3878 - acc: 0.8406 - val_loss: 0.3356 - val_acc: 0.8660\n",
      "Epoch 950/1000\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.3826 - acc: 0.8459 - val_loss: 0.3356 - val_acc: 0.8660\n",
      "Epoch 951/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3854 - acc: 0.8454 - val_loss: 0.3355 - val_acc: 0.8660\n",
      "Epoch 952/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3835 - acc: 0.8434 - val_loss: 0.3362 - val_acc: 0.8665\n",
      "Epoch 953/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3856 - acc: 0.8440 - val_loss: 0.3347 - val_acc: 0.8655\n",
      "Epoch 954/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3809 - acc: 0.8445 - val_loss: 0.3341 - val_acc: 0.8705\n",
      "Epoch 955/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3900 - acc: 0.8428 - val_loss: 0.3352 - val_acc: 0.8690\n",
      "Epoch 956/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3847 - acc: 0.8439 - val_loss: 0.3346 - val_acc: 0.8655\n",
      "Epoch 957/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3858 - acc: 0.8419 - val_loss: 0.3360 - val_acc: 0.8680\n",
      "Epoch 958/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3876 - acc: 0.8420 - val_loss: 0.3363 - val_acc: 0.8655\n",
      "Epoch 959/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3851 - acc: 0.8413 - val_loss: 0.3349 - val_acc: 0.8660\n",
      "Epoch 960/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3845 - acc: 0.8424 - val_loss: 0.3339 - val_acc: 0.8660\n",
      "Epoch 961/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3851 - acc: 0.8428 - val_loss: 0.3338 - val_acc: 0.8660\n",
      "Epoch 962/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3868 - acc: 0.8410 - val_loss: 0.3367 - val_acc: 0.8665\n",
      "Epoch 963/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3872 - acc: 0.8421 - val_loss: 0.3365 - val_acc: 0.8685\n",
      "Epoch 964/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3883 - acc: 0.8428 - val_loss: 0.3360 - val_acc: 0.8680\n",
      "Epoch 965/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3889 - acc: 0.8420 - val_loss: 0.3360 - val_acc: 0.8680\n",
      "Epoch 966/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3830 - acc: 0.8469 - val_loss: 0.3353 - val_acc: 0.8650\n",
      "Epoch 967/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3837 - acc: 0.8434 - val_loss: 0.3348 - val_acc: 0.8675\n",
      "Epoch 968/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3869 - acc: 0.8444 - val_loss: 0.3352 - val_acc: 0.8660\n",
      "Epoch 969/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3793 - acc: 0.8482 - val_loss: 0.3348 - val_acc: 0.8680\n",
      "Epoch 970/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3823 - acc: 0.848 - 0s 58us/sample - loss: 0.3816 - acc: 0.8489 - val_loss: 0.3339 - val_acc: 0.8660\n",
      "Epoch 971/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3842 - acc: 0.8439 - val_loss: 0.3350 - val_acc: 0.8655\n",
      "Epoch 972/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3811 - acc: 0.8455 - val_loss: 0.3342 - val_acc: 0.8650\n",
      "Epoch 973/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3861 - acc: 0.8444 - val_loss: 0.3351 - val_acc: 0.8665\n",
      "Epoch 974/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3887 - acc: 0.8444 - val_loss: 0.3359 - val_acc: 0.8660\n",
      "Epoch 975/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3872 - acc: 0.8434 - val_loss: 0.3361 - val_acc: 0.8660\n",
      "Epoch 976/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3845 - acc: 0.845 - 1s 63us/sample - loss: 0.3856 - acc: 0.8443 - val_loss: 0.3366 - val_acc: 0.8645\n",
      "Epoch 977/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3881 - acc: 0.8426 - val_loss: 0.3358 - val_acc: 0.8665\n",
      "Epoch 978/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3830 - acc: 0.8466 - val_loss: 0.3358 - val_acc: 0.8645\n",
      "Epoch 979/1000\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.3851 - acc: 0.8439 - val_loss: 0.3352 - val_acc: 0.8650\n",
      "Epoch 980/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3837 - acc: 0.8432 - val_loss: 0.3353 - val_acc: 0.8650\n",
      "Epoch 981/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3892 - acc: 0.844 - 1s 64us/sample - loss: 0.3894 - acc: 0.8445 - val_loss: 0.3356 - val_acc: 0.8655\n",
      "Epoch 982/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3793 - acc: 0.8484 - val_loss: 0.3344 - val_acc: 0.8675\n",
      "Epoch 983/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3776 - acc: 0.8447 - val_loss: 0.3334 - val_acc: 0.8660\n",
      "Epoch 984/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3803 - acc: 0.8440 - val_loss: 0.3348 - val_acc: 0.8640\n",
      "Epoch 985/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3818 - acc: 0.8441 - val_loss: 0.3349 - val_acc: 0.8655\n",
      "Epoch 986/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3835 - acc: 0.8461 - val_loss: 0.3349 - val_acc: 0.8660\n",
      "Epoch 987/1000\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.3823 - acc: 0.8461 - val_loss: 0.3348 - val_acc: 0.8655\n",
      "Epoch 988/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3828 - acc: 0.8451 - val_loss: 0.3353 - val_acc: 0.8640\n",
      "Epoch 989/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3841 - acc: 0.8446 - val_loss: 0.3343 - val_acc: 0.8650\n",
      "Epoch 990/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3789 - acc: 0.8496 - val_loss: 0.3359 - val_acc: 0.8645\n",
      "Epoch 991/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3841 - acc: 0.8396 - val_loss: 0.3350 - val_acc: 0.8655\n",
      "Epoch 992/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3779 - acc: 0.8438 - val_loss: 0.3346 - val_acc: 0.8665\n",
      "Epoch 993/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3822 - acc: 0.8445 - val_loss: 0.3352 - val_acc: 0.8655\n",
      "Epoch 994/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3859 - acc: 0.8419 - val_loss: 0.3351 - val_acc: 0.8645\n",
      "Epoch 995/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3831 - acc: 0.8443 - val_loss: 0.3353 - val_acc: 0.8635\n",
      "Epoch 996/1000\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.3861 - acc: 0.8410 - val_loss: 0.3344 - val_acc: 0.8640\n",
      "Epoch 997/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3829 - acc: 0.8401 - val_loss: 0.3349 - val_acc: 0.8655\n",
      "Epoch 998/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3809 - acc: 0.8447 - val_loss: 0.3339 - val_acc: 0.8660\n",
      "Epoch 999/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3851 - acc: 0.8456 - val_loss: 0.3342 - val_acc: 0.8655\n",
      "Epoch 1000/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3774 - acc: 0.8482 - val_loss: 0.3342 - val_acc: 0.8665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c14bb59240>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=25, mode='min')\n",
    "\n",
    "# Creating the model\n",
    "model_3 = Sequential()\n",
    "\n",
    "# Input/hidder layer\n",
    "model_3.add(Dense(units=X_train.shape[1], activation='relu'))\n",
    "model_3.add(Dropout(rate=0.2))\n",
    "\n",
    "# Hidder layer\n",
    "model_3.add(Dense(units=X_train.shape[1] // 2, activation='relu'))\n",
    "model_3.add(Dropout(rate=0.5))\n",
    "\n",
    "# Output layer\n",
    "model_3.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling\n",
    "model_3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the model\n",
    "model_3.fit(X_train, y_train, batch_size=128, epochs=1000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising (Using only Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.385402</td>\n",
       "      <td>0.845375</td>\n",
       "      <td>0.335451</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>0.383546</td>\n",
       "      <td>0.843375</td>\n",
       "      <td>0.336170</td>\n",
       "      <td>0.8665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0.385603</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.334738</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>0.380922</td>\n",
       "      <td>0.844500</td>\n",
       "      <td>0.334122</td>\n",
       "      <td>0.8705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>0.389969</td>\n",
       "      <td>0.842750</td>\n",
       "      <td>0.335234</td>\n",
       "      <td>0.8690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0.384688</td>\n",
       "      <td>0.843875</td>\n",
       "      <td>0.334636</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.385756</td>\n",
       "      <td>0.841875</td>\n",
       "      <td>0.336030</td>\n",
       "      <td>0.8680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0.387550</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.336349</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.385136</td>\n",
       "      <td>0.841250</td>\n",
       "      <td>0.334890</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>0.384526</td>\n",
       "      <td>0.842375</td>\n",
       "      <td>0.333941</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>0.385112</td>\n",
       "      <td>0.842750</td>\n",
       "      <td>0.333800</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>0.386819</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.336723</td>\n",
       "      <td>0.8665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>0.387172</td>\n",
       "      <td>0.842125</td>\n",
       "      <td>0.336506</td>\n",
       "      <td>0.8685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0.388328</td>\n",
       "      <td>0.842750</td>\n",
       "      <td>0.335960</td>\n",
       "      <td>0.8680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>0.388944</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.336046</td>\n",
       "      <td>0.8680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>0.383018</td>\n",
       "      <td>0.846875</td>\n",
       "      <td>0.335302</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>0.383680</td>\n",
       "      <td>0.843375</td>\n",
       "      <td>0.334799</td>\n",
       "      <td>0.8675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>0.386855</td>\n",
       "      <td>0.844375</td>\n",
       "      <td>0.335204</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>0.379332</td>\n",
       "      <td>0.848250</td>\n",
       "      <td>0.334810</td>\n",
       "      <td>0.8680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>0.381644</td>\n",
       "      <td>0.848875</td>\n",
       "      <td>0.333940</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.384199</td>\n",
       "      <td>0.843875</td>\n",
       "      <td>0.335016</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.381072</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.334197</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.386118</td>\n",
       "      <td>0.844375</td>\n",
       "      <td>0.335114</td>\n",
       "      <td>0.8665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.388745</td>\n",
       "      <td>0.844375</td>\n",
       "      <td>0.335858</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.387153</td>\n",
       "      <td>0.843375</td>\n",
       "      <td>0.336136</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.385636</td>\n",
       "      <td>0.844250</td>\n",
       "      <td>0.336617</td>\n",
       "      <td>0.8645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.388062</td>\n",
       "      <td>0.842625</td>\n",
       "      <td>0.335789</td>\n",
       "      <td>0.8665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.383014</td>\n",
       "      <td>0.846625</td>\n",
       "      <td>0.335810</td>\n",
       "      <td>0.8645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.385060</td>\n",
       "      <td>0.843875</td>\n",
       "      <td>0.335241</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.383709</td>\n",
       "      <td>0.843250</td>\n",
       "      <td>0.335268</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.389358</td>\n",
       "      <td>0.844500</td>\n",
       "      <td>0.335551</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.379323</td>\n",
       "      <td>0.848375</td>\n",
       "      <td>0.334445</td>\n",
       "      <td>0.8675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.377634</td>\n",
       "      <td>0.844750</td>\n",
       "      <td>0.333357</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.380265</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.334802</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.381777</td>\n",
       "      <td>0.844125</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.383532</td>\n",
       "      <td>0.846125</td>\n",
       "      <td>0.334929</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.382318</td>\n",
       "      <td>0.846125</td>\n",
       "      <td>0.334839</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.382820</td>\n",
       "      <td>0.845125</td>\n",
       "      <td>0.335251</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.384087</td>\n",
       "      <td>0.844625</td>\n",
       "      <td>0.334331</td>\n",
       "      <td>0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.378881</td>\n",
       "      <td>0.849625</td>\n",
       "      <td>0.335931</td>\n",
       "      <td>0.8645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.384086</td>\n",
       "      <td>0.839625</td>\n",
       "      <td>0.335007</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.377851</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.334629</td>\n",
       "      <td>0.8665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.382244</td>\n",
       "      <td>0.844500</td>\n",
       "      <td>0.335224</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.385890</td>\n",
       "      <td>0.841875</td>\n",
       "      <td>0.335051</td>\n",
       "      <td>0.8645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.383140</td>\n",
       "      <td>0.844250</td>\n",
       "      <td>0.335319</td>\n",
       "      <td>0.8635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.386129</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.334379</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.382901</td>\n",
       "      <td>0.840125</td>\n",
       "      <td>0.334866</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.380906</td>\n",
       "      <td>0.844750</td>\n",
       "      <td>0.333877</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.385090</td>\n",
       "      <td>0.845625</td>\n",
       "      <td>0.334183</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.377446</td>\n",
       "      <td>0.848250</td>\n",
       "      <td>0.334194</td>\n",
       "      <td>0.8665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       acc  val_loss  val_acc\n",
       "950  0.385402  0.845375  0.335451   0.8660\n",
       "951  0.383546  0.843375  0.336170   0.8665\n",
       "952  0.385603  0.844000  0.334738   0.8655\n",
       "953  0.380922  0.844500  0.334122   0.8705\n",
       "954  0.389969  0.842750  0.335234   0.8690\n",
       "955  0.384688  0.843875  0.334636   0.8655\n",
       "956  0.385756  0.841875  0.336030   0.8680\n",
       "957  0.387550  0.842000  0.336349   0.8655\n",
       "958  0.385136  0.841250  0.334890   0.8660\n",
       "959  0.384526  0.842375  0.333941   0.8660\n",
       "960  0.385112  0.842750  0.333800   0.8660\n",
       "961  0.386819  0.841000  0.336723   0.8665\n",
       "962  0.387172  0.842125  0.336506   0.8685\n",
       "963  0.388328  0.842750  0.335960   0.8680\n",
       "964  0.388944  0.842000  0.336046   0.8680\n",
       "965  0.383018  0.846875  0.335302   0.8650\n",
       "966  0.383680  0.843375  0.334799   0.8675\n",
       "967  0.386855  0.844375  0.335204   0.8660\n",
       "968  0.379332  0.848250  0.334810   0.8680\n",
       "969  0.381644  0.848875  0.333940   0.8660\n",
       "970  0.384199  0.843875  0.335016   0.8655\n",
       "971  0.381072  0.845500  0.334197   0.8650\n",
       "972  0.386118  0.844375  0.335114   0.8665\n",
       "973  0.388745  0.844375  0.335858   0.8660\n",
       "974  0.387153  0.843375  0.336136   0.8660\n",
       "975  0.385636  0.844250  0.336617   0.8645\n",
       "976  0.388062  0.842625  0.335789   0.8665\n",
       "977  0.383014  0.846625  0.335810   0.8645\n",
       "978  0.385060  0.843875  0.335241   0.8650\n",
       "979  0.383709  0.843250  0.335268   0.8650\n",
       "980  0.389358  0.844500  0.335551   0.8655\n",
       "981  0.379323  0.848375  0.334445   0.8675\n",
       "982  0.377634  0.844750  0.333357   0.8660\n",
       "983  0.380265  0.844000  0.334802   0.8640\n",
       "984  0.381777  0.844125  0.334878   0.8655\n",
       "985  0.383532  0.846125  0.334929   0.8660\n",
       "986  0.382318  0.846125  0.334839   0.8655\n",
       "987  0.382820  0.845125  0.335251   0.8640\n",
       "988  0.384087  0.844625  0.334331   0.8650\n",
       "989  0.378881  0.849625  0.335931   0.8645\n",
       "990  0.384086  0.839625  0.335007   0.8655\n",
       "991  0.377851  0.843750  0.334629   0.8665\n",
       "992  0.382244  0.844500  0.335224   0.8655\n",
       "993  0.385890  0.841875  0.335051   0.8645\n",
       "994  0.383140  0.844250  0.335319   0.8635\n",
       "995  0.386129  0.841000  0.334379   0.8640\n",
       "996  0.382901  0.840125  0.334866   0.8655\n",
       "997  0.380906  0.844750  0.333877   0.8660\n",
       "998  0.385090  0.845625  0.334183   0.8655\n",
       "999  0.377446  0.848250  0.334194   0.8665"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_3 = pd.DataFrame(model_3.history.history)\n",
    "losses_3[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c14de05be0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_3.plot(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the DFF_NN (Using neither Dropout nor EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1000\n",
      "8000/8000 [==============================] - 3s 358us/sample - loss: 0.6461 - acc: 0.6481 - val_loss: 0.5884 - val_acc: 0.7445\n",
      "Epoch 2/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.5557 - acc: 0.7684 - val_loss: 0.5120 - val_acc: 0.7870\n",
      "Epoch 3/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.4897 - acc: 0.7924 - val_loss: 0.4649 - val_acc: 0.7975\n",
      "Epoch 4/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.4560 - acc: 0.8011 - val_loss: 0.4441 - val_acc: 0.8035\n",
      "Epoch 5/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.4406 - acc: 0.8087 - val_loss: 0.4322 - val_acc: 0.8150\n",
      "Epoch 6/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.4309 - acc: 0.8124 - val_loss: 0.4234 - val_acc: 0.8190\n",
      "Epoch 7/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.4236 - acc: 0.8180 - val_loss: 0.4158 - val_acc: 0.8230\n",
      "Epoch 8/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.4173 - acc: 0.8189 - val_loss: 0.4094 - val_acc: 0.8315\n",
      "Epoch 9/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.4117 - acc: 0.8225 - val_loss: 0.4034 - val_acc: 0.8355\n",
      "Epoch 10/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.4065 - acc: 0.8255 - val_loss: 0.3979 - val_acc: 0.8375\n",
      "Epoch 11/1000\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.4018 - acc: 0.8292 - val_loss: 0.3925 - val_acc: 0.8395\n",
      "Epoch 12/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3971 - acc: 0.8322 - val_loss: 0.3878 - val_acc: 0.8400\n",
      "Epoch 13/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3928 - acc: 0.8371 - val_loss: 0.3831 - val_acc: 0.8450\n",
      "Epoch 14/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3881 - acc: 0.8395 - val_loss: 0.3775 - val_acc: 0.8465\n",
      "Epoch 15/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3836 - acc: 0.8411 - val_loss: 0.3726 - val_acc: 0.8490\n",
      "Epoch 16/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3791 - acc: 0.8443 - val_loss: 0.3668 - val_acc: 0.8525\n",
      "Epoch 17/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3744 - acc: 0.8447 - val_loss: 0.3621 - val_acc: 0.8545\n",
      "Epoch 18/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3700 - acc: 0.8465 - val_loss: 0.3585 - val_acc: 0.8545\n",
      "Epoch 19/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3658 - acc: 0.8499 - val_loss: 0.3544 - val_acc: 0.8550\n",
      "Epoch 20/1000\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.3621 - acc: 0.8510 - val_loss: 0.3509 - val_acc: 0.8605\n",
      "Epoch 21/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3587 - acc: 0.8525 - val_loss: 0.3480 - val_acc: 0.8615\n",
      "Epoch 22/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3557 - acc: 0.8547 - val_loss: 0.3460 - val_acc: 0.8615\n",
      "Epoch 23/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3533 - acc: 0.8547 - val_loss: 0.3437 - val_acc: 0.8620\n",
      "Epoch 24/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3511 - acc: 0.8565 - val_loss: 0.3420 - val_acc: 0.8630\n",
      "Epoch 25/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3496 - acc: 0.8574 - val_loss: 0.3407 - val_acc: 0.8615\n",
      "Epoch 26/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3480 - acc: 0.8577 - val_loss: 0.3419 - val_acc: 0.8610\n",
      "Epoch 27/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3467 - acc: 0.8584 - val_loss: 0.3393 - val_acc: 0.8605\n",
      "Epoch 28/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3458 - acc: 0.8602 - val_loss: 0.3380 - val_acc: 0.8630\n",
      "Epoch 29/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3445 - acc: 0.8591 - val_loss: 0.3372 - val_acc: 0.8645\n",
      "Epoch 30/1000\n",
      "8000/8000 [==============================] - 1s 67us/sample - loss: 0.3435 - acc: 0.8597 - val_loss: 0.3377 - val_acc: 0.8635\n",
      "Epoch 31/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3426 - acc: 0.8608 - val_loss: 0.3365 - val_acc: 0.8610\n",
      "Epoch 32/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3418 - acc: 0.8621 - val_loss: 0.3358 - val_acc: 0.8665\n",
      "Epoch 33/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3414 - acc: 0.8605 - val_loss: 0.3359 - val_acc: 0.8640\n",
      "Epoch 34/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3406 - acc: 0.8624 - val_loss: 0.3345 - val_acc: 0.8655\n",
      "Epoch 35/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3403 - acc: 0.8616 - val_loss: 0.3340 - val_acc: 0.8645\n",
      "Epoch 36/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3396 - acc: 0.8621 - val_loss: 0.3345 - val_acc: 0.8645\n",
      "Epoch 37/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3395 - acc: 0.8616 - val_loss: 0.3351 - val_acc: 0.8635\n",
      "Epoch 38/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3388 - acc: 0.8627 - val_loss: 0.3337 - val_acc: 0.8630\n",
      "Epoch 39/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3383 - acc: 0.8619 - val_loss: 0.3336 - val_acc: 0.8625\n",
      "Epoch 40/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3380 - acc: 0.8619 - val_loss: 0.3336 - val_acc: 0.8635\n",
      "Epoch 41/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3375 - acc: 0.8634 - val_loss: 0.3333 - val_acc: 0.8645\n",
      "Epoch 42/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3370 - acc: 0.8624 - val_loss: 0.3333 - val_acc: 0.8620\n",
      "Epoch 43/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3367 - acc: 0.8630 - val_loss: 0.3346 - val_acc: 0.8625\n",
      "Epoch 44/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3365 - acc: 0.8611 - val_loss: 0.3342 - val_acc: 0.8620\n",
      "Epoch 45/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3359 - acc: 0.8625 - val_loss: 0.3331 - val_acc: 0.8620\n",
      "Epoch 46/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3361 - acc: 0.8641 - val_loss: 0.3329 - val_acc: 0.8615\n",
      "Epoch 47/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3357 - acc: 0.8629 - val_loss: 0.3332 - val_acc: 0.8635\n",
      "Epoch 48/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3355 - acc: 0.8618 - val_loss: 0.3331 - val_acc: 0.8620\n",
      "Epoch 49/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3353 - acc: 0.8622 - val_loss: 0.3340 - val_acc: 0.8625\n",
      "Epoch 50/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3353 - acc: 0.8633 - val_loss: 0.3328 - val_acc: 0.8615\n",
      "Epoch 51/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3347 - acc: 0.8629 - val_loss: 0.3345 - val_acc: 0.8625\n",
      "Epoch 52/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3348 - acc: 0.8633 - val_loss: 0.3331 - val_acc: 0.8620\n",
      "Epoch 53/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3347 - acc: 0.8633 - val_loss: 0.3340 - val_acc: 0.8630\n",
      "Epoch 54/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3343 - acc: 0.8634 - val_loss: 0.3343 - val_acc: 0.8635\n",
      "Epoch 55/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3341 - acc: 0.8636 - val_loss: 0.3340 - val_acc: 0.8655\n",
      "Epoch 56/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3339 - acc: 0.8641 - val_loss: 0.3349 - val_acc: 0.8625\n",
      "Epoch 57/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3339 - acc: 0.8631 - val_loss: 0.3331 - val_acc: 0.8625\n",
      "Epoch 58/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3337 - acc: 0.8645 - val_loss: 0.3326 - val_acc: 0.8615\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3340 - acc: 0.8627 - val_loss: 0.3339 - val_acc: 0.8615\n",
      "Epoch 60/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3334 - acc: 0.8641 - val_loss: 0.3328 - val_acc: 0.8620\n",
      "Epoch 61/1000\n",
      "8000/8000 [==============================] - 1s 78us/sample - loss: 0.3333 - acc: 0.8625 - val_loss: 0.3338 - val_acc: 0.8610\n",
      "Epoch 62/1000\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.3333 - acc: 0.8640 - val_loss: 0.3333 - val_acc: 0.8615\n",
      "Epoch 63/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3331 - acc: 0.8645 - val_loss: 0.3333 - val_acc: 0.8630\n",
      "Epoch 64/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3332 - acc: 0.8634 - val_loss: 0.3349 - val_acc: 0.8620\n",
      "Epoch 65/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3331 - acc: 0.8622 - val_loss: 0.3326 - val_acc: 0.8610\n",
      "Epoch 66/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3330 - acc: 0.8637 - val_loss: 0.3327 - val_acc: 0.8610\n",
      "Epoch 67/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3326 - acc: 0.8633 - val_loss: 0.3346 - val_acc: 0.8600\n",
      "Epoch 68/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3323 - acc: 0.8643 - val_loss: 0.3322 - val_acc: 0.8610\n",
      "Epoch 69/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3328 - acc: 0.8635 - val_loss: 0.3331 - val_acc: 0.8620\n",
      "Epoch 70/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3324 - acc: 0.8633 - val_loss: 0.3331 - val_acc: 0.8615\n",
      "Epoch 71/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3323 - acc: 0.8637 - val_loss: 0.3348 - val_acc: 0.8625\n",
      "Epoch 72/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3323 - acc: 0.8639 - val_loss: 0.3326 - val_acc: 0.8595\n",
      "Epoch 73/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3328 - acc: 0.8635- ETA: 0s - loss: 0.3207 - acc: - 0s 60us/sample - loss: 0.3321 - acc: 0.8636 - val_loss: 0.3339 - val_acc: 0.8625\n",
      "Epoch 74/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3319 - acc: 0.8645 - val_loss: 0.3337 - val_acc: 0.8620\n",
      "Epoch 75/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3320 - acc: 0.8644 - val_loss: 0.3341 - val_acc: 0.8615 - loss: 0.3315 - acc: 0.8\n",
      "Epoch 76/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3318 - acc: 0.8629 - val_loss: 0.3340 - val_acc: 0.8630\n",
      "Epoch 77/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3319 - acc: 0.8640 - val_loss: 0.3348 - val_acc: 0.8615\n",
      "Epoch 78/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3315 - acc: 0.8635 - val_loss: 0.3358 - val_acc: 0.8600\n",
      "Epoch 79/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3320 - acc: 0.8635 - val_loss: 0.3345 - val_acc: 0.8605\n",
      "Epoch 80/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3314 - acc: 0.8654 - val_loss: 0.3353 - val_acc: 0.8595\n",
      "Epoch 81/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3317 - acc: 0.8648 - val_loss: 0.3348 - val_acc: 0.8625\n",
      "Epoch 82/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3313 - acc: 0.8645 - val_loss: 0.3327 - val_acc: 0.8620\n",
      "Epoch 83/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3316 - acc: 0.8631 - val_loss: 0.3333 - val_acc: 0.8640\n",
      "Epoch 84/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3310 - acc: 0.8637 - val_loss: 0.3337 - val_acc: 0.8635\n",
      "Epoch 85/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3313 - acc: 0.8627 - val_loss: 0.3339 - val_acc: 0.8615\n",
      "Epoch 86/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3310 - acc: 0.8643 - val_loss: 0.3337 - val_acc: 0.8635\n",
      "Epoch 87/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3309 - acc: 0.8639 - val_loss: 0.3334 - val_acc: 0.8620\n",
      "Epoch 88/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3309 - acc: 0.8633 - val_loss: 0.3337 - val_acc: 0.8630\n",
      "Epoch 89/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3307 - acc: 0.8644 - val_loss: 0.3332 - val_acc: 0.8615\n",
      "Epoch 90/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3311 - acc: 0.8641 - val_loss: 0.3342 - val_acc: 0.8620\n",
      "Epoch 91/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3307 - acc: 0.8637 - val_loss: 0.3347 - val_acc: 0.8625\n",
      "Epoch 92/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3308 - acc: 0.8636 - val_loss: 0.3343 - val_acc: 0.8625\n",
      "Epoch 93/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3305 - acc: 0.8641 - val_loss: 0.3343 - val_acc: 0.8635\n",
      "Epoch 94/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3306 - acc: 0.8641 - val_loss: 0.3338 - val_acc: 0.8635\n",
      "Epoch 95/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3307 - acc: 0.8641 - val_loss: 0.3350 - val_acc: 0.8620\n",
      "Epoch 96/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3309 - acc: 0.8636 - val_loss: 0.3357 - val_acc: 0.8610\n",
      "Epoch 97/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3305 - acc: 0.8634 - val_loss: 0.3351 - val_acc: 0.8600\n",
      "Epoch 98/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3305 - acc: 0.8629 - val_loss: 0.3331 - val_acc: 0.8615\n",
      "Epoch 99/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3309 - acc: 0.8643 - val_loss: 0.3328 - val_acc: 0.8635\n",
      "Epoch 100/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3303 - acc: 0.8640 - val_loss: 0.3349 - val_acc: 0.8620\n",
      "Epoch 101/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3301 - acc: 0.863 - 0s 58us/sample - loss: 0.3304 - acc: 0.8635 - val_loss: 0.3335 - val_acc: 0.8620\n",
      "Epoch 102/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3306 - acc: 0.8641 - val_loss: 0.3337 - val_acc: 0.8625\n",
      "Epoch 103/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3301 - acc: 0.8641 - val_loss: 0.3349 - val_acc: 0.8605\n",
      "Epoch 104/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3300 - acc: 0.8636 - val_loss: 0.3332 - val_acc: 0.8625\n",
      "Epoch 105/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3299 - acc: 0.8640 - val_loss: 0.3337 - val_acc: 0.8620\n",
      "Epoch 106/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3302 - acc: 0.8639 - val_loss: 0.3354 - val_acc: 0.8600\n",
      "Epoch 107/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3306 - acc: 0.8645 - val_loss: 0.3364 - val_acc: 0.8595\n",
      "Epoch 108/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3308 - acc: 0.8627 - val_loss: 0.3369 - val_acc: 0.8610\n",
      "Epoch 109/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3301 - acc: 0.8639 - val_loss: 0.3351 - val_acc: 0.8600\n",
      "Epoch 110/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3297 - acc: 0.8645 - val_loss: 0.3369 - val_acc: 0.8610\n",
      "Epoch 111/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3301 - acc: 0.8635 - val_loss: 0.3335 - val_acc: 0.8615\n",
      "Epoch 112/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3306 - acc: 0.8636 - val_loss: 0.3338 - val_acc: 0.8625\n",
      "Epoch 113/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3301 - acc: 0.8641 - val_loss: 0.3347 - val_acc: 0.8610\n",
      "Epoch 114/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3299 - acc: 0.8627 - val_loss: 0.3342 - val_acc: 0.8620\n",
      "Epoch 115/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3298 - acc: 0.8643 - val_loss: 0.3347 - val_acc: 0.8610\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3300 - acc: 0.8635 - val_loss: 0.3346 - val_acc: 0.8620\n",
      "Epoch 117/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3300 - acc: 0.8661 - val_loss: 0.3330 - val_acc: 0.8630\n",
      "Epoch 118/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3300 - acc: 0.8640 - val_loss: 0.3351 - val_acc: 0.8610\n",
      "Epoch 119/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3295 - acc: 0.8655 - val_loss: 0.3341 - val_acc: 0.8615\n",
      "Epoch 120/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3296 - acc: 0.8639 - val_loss: 0.3365 - val_acc: 0.8600\n",
      "Epoch 121/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3301 - acc: 0.8643 - val_loss: 0.3355 - val_acc: 0.8615\n",
      "Epoch 122/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3295 - acc: 0.8644 - val_loss: 0.3359 - val_acc: 0.8600\n",
      "Epoch 123/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3298 - acc: 0.8646 - val_loss: 0.3356 - val_acc: 0.8630\n",
      "Epoch 124/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3294 - acc: 0.8636 - val_loss: 0.3338 - val_acc: 0.8620\n",
      "Epoch 125/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3297 - acc: 0.8644 - val_loss: 0.3343 - val_acc: 0.8630\n",
      "Epoch 126/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3296 - acc: 0.8639 - val_loss: 0.3365 - val_acc: 0.8605\n",
      "Epoch 127/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3296 - acc: 0.8651 - val_loss: 0.3341 - val_acc: 0.8615\n",
      "Epoch 128/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3298 - acc: 0.8631 - val_loss: 0.3352 - val_acc: 0.8610\n",
      "Epoch 129/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3293 - acc: 0.8630 - val_loss: 0.3348 - val_acc: 0.8595\n",
      "Epoch 130/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3295 - acc: 0.8648 - val_loss: 0.3350 - val_acc: 0.8610\n",
      "Epoch 131/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3292 - acc: 0.8645 - val_loss: 0.3355 - val_acc: 0.8605\n",
      "Epoch 132/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3292 - acc: 0.8640 - val_loss: 0.3357 - val_acc: 0.8590\n",
      "Epoch 133/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3290 - acc: 0.8644 - val_loss: 0.3365 - val_acc: 0.8615\n",
      "Epoch 134/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3291 - acc: 0.8641 - val_loss: 0.3345 - val_acc: 0.8615\n",
      "Epoch 135/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3292 - acc: 0.8649 - val_loss: 0.3346 - val_acc: 0.8620\n",
      "Epoch 136/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3293 - acc: 0.8636 - val_loss: 0.3356 - val_acc: 0.8610\n",
      "Epoch 137/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3290 - acc: 0.8635 - val_loss: 0.3384 - val_acc: 0.8605\n",
      "Epoch 138/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3290 - acc: 0.8635 - val_loss: 0.3346 - val_acc: 0.8610\n",
      "Epoch 139/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3291 - acc: 0.8650 - val_loss: 0.3353 - val_acc: 0.8600\n",
      "Epoch 140/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3288 - acc: 0.8641 - val_loss: 0.3357 - val_acc: 0.8610\n",
      "Epoch 141/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3287 - acc: 0.8648 - val_loss: 0.3353 - val_acc: 0.8610\n",
      "Epoch 142/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3289 - acc: 0.8644 - val_loss: 0.3366 - val_acc: 0.8590\n",
      "Epoch 143/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3288 - acc: 0.8648 - val_loss: 0.3361 - val_acc: 0.8600\n",
      "Epoch 144/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3289 - acc: 0.8645 - val_loss: 0.3369 - val_acc: 0.8615\n",
      "Epoch 145/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3288 - acc: 0.8649 - val_loss: 0.3359 - val_acc: 0.8595\n",
      "Epoch 146/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3287 - acc: 0.8639 - val_loss: 0.3367 - val_acc: 0.8590\n",
      "Epoch 147/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3288 - acc: 0.8650 - val_loss: 0.3370 - val_acc: 0.8615\n",
      "Epoch 148/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3288 - acc: 0.8651 - val_loss: 0.3364 - val_acc: 0.8600\n",
      "Epoch 149/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3286 - acc: 0.8652 - val_loss: 0.3351 - val_acc: 0.8595\n",
      "Epoch 150/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3285 - acc: 0.8660 - val_loss: 0.3354 - val_acc: 0.8605\n",
      "Epoch 151/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3284 - acc: 0.8656 - val_loss: 0.3370 - val_acc: 0.8590\n",
      "Epoch 152/1000\n",
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3288 - acc: 0.8649 - val_loss: 0.3370 - val_acc: 0.8600\n",
      "Epoch 153/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3284 - acc: 0.8639 - val_loss: 0.3379 - val_acc: 0.8610\n",
      "Epoch 154/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3284 - acc: 0.8654 - val_loss: 0.3368 - val_acc: 0.8600\n",
      "Epoch 155/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3283 - acc: 0.8645 - val_loss: 0.3353 - val_acc: 0.8585\n",
      "Epoch 156/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3284 - acc: 0.8646 - val_loss: 0.3364 - val_acc: 0.8600\n",
      "Epoch 157/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3283 - acc: 0.8635 - val_loss: 0.3370 - val_acc: 0.8595\n",
      "Epoch 158/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3284 - acc: 0.8646 - val_loss: 0.3363 - val_acc: 0.8580\n",
      "Epoch 159/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3281 - acc: 0.8650 - val_loss: 0.3364 - val_acc: 0.8575\n",
      "Epoch 160/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3283 - acc: 0.8654 - val_loss: 0.3368 - val_acc: 0.8585\n",
      "Epoch 161/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3293 - acc: 0.866 - 0s 58us/sample - loss: 0.3281 - acc: 0.8666 - val_loss: 0.3382 - val_acc: 0.8600\n",
      "Epoch 162/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3282 - acc: 0.8646 - val_loss: 0.3367 - val_acc: 0.8575\n",
      "Epoch 163/1000\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.3281 - acc: 0.8658 - val_loss: 0.3375 - val_acc: 0.8580\n",
      "Epoch 164/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3281 - acc: 0.8650 - val_loss: 0.3374 - val_acc: 0.8590\n",
      "Epoch 165/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3279 - acc: 0.8648 - val_loss: 0.3382 - val_acc: 0.8585\n",
      "Epoch 166/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3282 - acc: 0.8643 - val_loss: 0.3393 - val_acc: 0.8605\n",
      "Epoch 167/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3280 - acc: 0.8658 - val_loss: 0.3365 - val_acc: 0.8605\n",
      "Epoch 168/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3280 - acc: 0.8639 - val_loss: 0.3368 - val_acc: 0.8585\n",
      "Epoch 169/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3278 - acc: 0.8652 - val_loss: 0.3377 - val_acc: 0.8590\n",
      "Epoch 170/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3278 - acc: 0.8649 - val_loss: 0.3374 - val_acc: 0.8580\n",
      "Epoch 171/1000\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3278 - acc: 0.8658 - val_loss: 0.3372 - val_acc: 0.8585\n",
      "Epoch 172/1000\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3278 - acc: 0.8644 - val_loss: 0.3380 - val_acc: 0.8570\n",
      "Epoch 173/1000\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3279 - acc: 0.8658 - val_loss: 0.3379 - val_acc: 0.8570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3279 - acc: 0.8656 - val_loss: 0.3380 - val_acc: 0.8585\n",
      "Epoch 175/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3275 - acc: 0.8661 - val_loss: 0.3375 - val_acc: 0.8570\n",
      "Epoch 176/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3277 - acc: 0.8654 - val_loss: 0.3372 - val_acc: 0.8590\n",
      "Epoch 177/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3276 - acc: 0.8644 - val_loss: 0.3382 - val_acc: 0.8565\n",
      "Epoch 178/1000\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3276 - acc: 0.8654 - val_loss: 0.3374 - val_acc: 0.8595\n",
      "Epoch 179/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3274 - acc: 0.8668 - val_loss: 0.3372 - val_acc: 0.8580\n",
      "Epoch 180/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3274 - acc: 0.8660 - val_loss: 0.3372 - val_acc: 0.8575\n",
      "Epoch 181/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3275 - acc: 0.8659 - val_loss: 0.3376 - val_acc: 0.8575\n",
      "Epoch 182/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3273 - acc: 0.8656 - val_loss: 0.3364 - val_acc: 0.8570\n",
      "Epoch 183/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3275 - acc: 0.8658 - val_loss: 0.3371 - val_acc: 0.8585\n",
      "Epoch 184/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3273 - acc: 0.8640 - val_loss: 0.3398 - val_acc: 0.8595\n",
      "Epoch 185/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3278 - acc: 0.8648 - val_loss: 0.3399 - val_acc: 0.8595\n",
      "Epoch 186/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3278 - acc: 0.8655 - val_loss: 0.3372 - val_acc: 0.8575\n",
      "Epoch 187/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3273 - acc: 0.8644 - val_loss: 0.3378 - val_acc: 0.8600\n",
      "Epoch 188/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3274 - acc: 0.8652 - val_loss: 0.3378 - val_acc: 0.8590\n",
      "Epoch 189/1000\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3274 - acc: 0.8654 - val_loss: 0.3380 - val_acc: 0.8580\n",
      "Epoch 190/1000\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3275 - acc: 0.8651 - val_loss: 0.3371 - val_acc: 0.8590\n",
      "Epoch 191/1000\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3271 - acc: 0.8646 - val_loss: 0.3380 - val_acc: 0.8600\n",
      "Epoch 192/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3272 - acc: 0.8651 - val_loss: 0.3394 - val_acc: 0.8600\n",
      "Epoch 193/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3270 - acc: 0.8656 - val_loss: 0.3368 - val_acc: 0.8580\n",
      "Epoch 194/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3274 - acc: 0.8661 - val_loss: 0.3371 - val_acc: 0.8590\n",
      "Epoch 195/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3271 - acc: 0.8659 - val_loss: 0.3385 - val_acc: 0.8595\n",
      "Epoch 196/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3272 - acc: 0.8641 - val_loss: 0.3391 - val_acc: 0.8590\n",
      "Epoch 197/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3271 - acc: 0.8656 - val_loss: 0.3376 - val_acc: 0.8575\n",
      "Epoch 198/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3272 - acc: 0.8644 - val_loss: 0.3384 - val_acc: 0.8600\n",
      "Epoch 199/1000\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3271 - acc: 0.8665 - val_loss: 0.3368 - val_acc: 0.8595\n",
      "Epoch 200/1000\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3270 - acc: 0.8658 - val_loss: 0.3389 - val_acc: 0.8605\n",
      "Epoch 201/1000\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3273 - acc: 0.8650 - val_loss: 0.3390 - val_acc: 0.8585\n",
      "Epoch 202/1000\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3269 - acc: 0.8651 - val_loss: 0.3386 - val_acc: 0.8600\n",
      "Epoch 203/1000\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3270 - acc: 0.8664 - val_loss: 0.3377 - val_acc: 0.8590\n",
      "Epoch 204/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3273 - acc: 0.8654 - val_loss: 0.3390 - val_acc: 0.8590\n",
      "Epoch 205/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3271 - acc: 0.8645 - val_loss: 0.3394 - val_acc: 0.8585\n",
      "Epoch 206/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3270 - acc: 0.8656 - val_loss: 0.3368 - val_acc: 0.8585\n",
      "Epoch 207/1000\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3270 - acc: 0.8641 - val_loss: 0.3391 - val_acc: 0.8585\n",
      "Epoch 208/1000\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3270 - acc: 0.8655 - val_loss: 0.3381 - val_acc: 0.8600\n",
      "Epoch 209/1000\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3268 - acc: 0.8662 - val_loss: 0.3371 - val_acc: 0.8570\n",
      "Epoch 210/1000\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3269 - acc: 0.8658 - val_loss: 0.3389 - val_acc: 0.8595\n",
      "Epoch 211/1000\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3268 - acc: 0.8660 - val_loss: 0.3372 - val_acc: 0.8590\n",
      "Epoch 212/1000\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3272 - acc: 0.8666 - val_loss: 0.3370 - val_acc: 0.8605\n",
      "Epoch 213/1000\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3269 - acc: 0.8661 - val_loss: 0.3388 - val_acc: 0.8595\n",
      "Epoch 214/1000\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3269 - acc: 0.8650 - val_loss: 0.3379 - val_acc: 0.8590\n",
      "Epoch 215/1000\n",
      "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3270 - acc: 0.8673 - val_loss: 0.3384 - val_acc: 0.8570\n",
      "Epoch 216/1000\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3269 - acc: 0.8662 - val_loss: 0.3379 - val_acc: 0.8605\n",
      "Epoch 217/1000\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3268 - acc: 0.8656 - val_loss: 0.3401 - val_acc: 0.8585\n",
      "Epoch 218/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3268 - acc: 0.8664 - val_loss: 0.3389 - val_acc: 0.8605\n",
      "Epoch 219/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3267 - acc: 0.8664 - val_loss: 0.3371 - val_acc: 0.8585\n",
      "Epoch 220/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3266 - acc: 0.8656 - val_loss: 0.3382 - val_acc: 0.8605\n",
      "Epoch 221/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3267 - acc: 0.8661 - val_loss: 0.3383 - val_acc: 0.8595\n",
      "Epoch 222/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3267 - acc: 0.8666 - val_loss: 0.3366 - val_acc: 0.8600\n",
      "Epoch 223/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3266 - acc: 0.8666 - val_loss: 0.3381 - val_acc: 0.8590\n",
      "Epoch 224/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3266 - acc: 0.8655 - val_loss: 0.3371 - val_acc: 0.8590\n",
      "Epoch 225/1000\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.3265 - acc: 0.8664 - val_loss: 0.3372 - val_acc: 0.8580\n",
      "Epoch 226/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3268 - acc: 0.8652 - val_loss: 0.3374 - val_acc: 0.8580\n",
      "Epoch 227/1000\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.3266 - acc: 0.8649 - val_loss: 0.3375 - val_acc: 0.8580\n",
      "Epoch 228/1000\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.3267 - acc: 0.8669 - val_loss: 0.3375 - val_acc: 0.8575\n",
      "Epoch 229/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3265 - acc: 0.8679 - val_loss: 0.3374 - val_acc: 0.8600\n",
      "Epoch 230/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3268 - acc: 0.8659 - val_loss: 0.3370 - val_acc: 0.8580\n",
      "Epoch 231/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3264 - acc: 0.8659 - val_loss: 0.3390 - val_acc: 0.8595\n",
      "Epoch 232/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3264 - acc: 0.8668 - val_loss: 0.3374 - val_acc: 0.8565\n",
      "Epoch 233/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3269 - acc: 0.8665 - val_loss: 0.3379 - val_acc: 0.8590\n",
      "Epoch 234/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3268 - acc: 0.8652 - val_loss: 0.3371 - val_acc: 0.8570\n",
      "Epoch 235/1000\n",
      "8000/8000 [==============================] - 1s 86us/sample - loss: 0.3266 - acc: 0.8665 - val_loss: 0.3371 - val_acc: 0.8590\n",
      "Epoch 236/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3265 - acc: 0.8670 - val_loss: 0.3392 - val_acc: 0.8585\n",
      "Epoch 237/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3264 - acc: 0.8670 - val_loss: 0.3371 - val_acc: 0.8605\n",
      "Epoch 238/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3269 - acc: 0.8660 - val_loss: 0.3378 - val_acc: 0.8595\n",
      "Epoch 239/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3263 - acc: 0.8670 - val_loss: 0.3379 - val_acc: 0.8590\n",
      "Epoch 240/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3264 - acc: 0.8665 - val_loss: 0.3379 - val_acc: 0.8585\n",
      "Epoch 241/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3266 - acc: 0.8648 - val_loss: 0.3402 - val_acc: 0.8570\n",
      "Epoch 242/1000\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3265 - acc: 0.8677 - val_loss: 0.3377 - val_acc: 0.8605\n",
      "Epoch 243/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3264 - acc: 0.8671 - val_loss: 0.3379 - val_acc: 0.8595\n",
      "Epoch 244/1000\n",
      "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3267 - acc: 0.8661 - val_loss: 0.3372 - val_acc: 0.8595\n",
      "Epoch 245/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3267 - acc: 0.8661 - val_loss: 0.3378 - val_acc: 0.8595\n",
      "Epoch 246/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3253 - acc: 0.867 - 0s 44us/sample - loss: 0.3264 - acc: 0.8680 - val_loss: 0.3371 - val_acc: 0.8570\n",
      "Epoch 247/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3265 - acc: 0.8662 - val_loss: 0.3381 - val_acc: 0.8590\n",
      "Epoch 248/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3267 - acc: 0.8671 - val_loss: 0.3382 - val_acc: 0.8580\n",
      "Epoch 249/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3264 - acc: 0.8668 - val_loss: 0.3371 - val_acc: 0.8590\n",
      "Epoch 250/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3262 - acc: 0.8664 - val_loss: 0.3378 - val_acc: 0.8595\n",
      "Epoch 251/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3267 - acc: 0.8675 - val_loss: 0.3382 - val_acc: 0.8605\n",
      "Epoch 252/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3265 - acc: 0.8668 - val_loss: 0.3383 - val_acc: 0.8595\n",
      "Epoch 253/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3263 - acc: 0.8661 - val_loss: 0.3378 - val_acc: 0.8570\n",
      "Epoch 254/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3262 - acc: 0.8679 - val_loss: 0.3364 - val_acc: 0.8590\n",
      "Epoch 255/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3262 - acc: 0.8661 - val_loss: 0.3403 - val_acc: 0.8580\n",
      "Epoch 256/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3263 - acc: 0.8662 - val_loss: 0.3375 - val_acc: 0.8590\n",
      "Epoch 257/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3262 - acc: 0.8658 - val_loss: 0.3378 - val_acc: 0.8610\n",
      "Epoch 258/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3292 - acc: 0.864 - 0s 44us/sample - loss: 0.3263 - acc: 0.8668 - val_loss: 0.3370 - val_acc: 0.8580\n",
      "Epoch 259/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3259 - acc: 0.8668 - val_loss: 0.3371 - val_acc: 0.8590\n",
      "Epoch 260/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3265 - acc: 0.8681 - val_loss: 0.3366 - val_acc: 0.8585\n",
      "Epoch 261/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3258 - acc: 0.865 - 0s 39us/sample - loss: 0.3261 - acc: 0.8656 - val_loss: 0.3408 - val_acc: 0.8595\n",
      "Epoch 262/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3263 - acc: 0.8675 - val_loss: 0.3366 - val_acc: 0.8580\n",
      "Epoch 263/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3261 - acc: 0.8664 - val_loss: 0.3389 - val_acc: 0.8605\n",
      "Epoch 264/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3261 - acc: 0.8669 - val_loss: 0.3369 - val_acc: 0.8590\n",
      "Epoch 265/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3264 - acc: 0.8661 - val_loss: 0.3378 - val_acc: 0.8605\n",
      "Epoch 266/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3261 - acc: 0.8662 - val_loss: 0.3363 - val_acc: 0.8575\n",
      "Epoch 267/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3267 - acc: 0.8662 - val_loss: 0.3376 - val_acc: 0.8595\n",
      "Epoch 268/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3264 - acc: 0.8673 - val_loss: 0.3371 - val_acc: 0.8580\n",
      "Epoch 269/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3263 - acc: 0.8669 - val_loss: 0.3374 - val_acc: 0.8595\n",
      "Epoch 270/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3250 - acc: 0.868 - 0s 42us/sample - loss: 0.3262 - acc: 0.8668 - val_loss: 0.3375 - val_acc: 0.8605\n",
      "Epoch 271/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3265 - acc: 0.8660 - val_loss: 0.3378 - val_acc: 0.8590\n",
      "Epoch 272/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3263 - acc: 0.8664 - val_loss: 0.3379 - val_acc: 0.8620\n",
      "Epoch 273/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3264 - acc: 0.8668 - val_loss: 0.3369 - val_acc: 0.8580\n",
      "Epoch 274/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3263 - acc: 0.8671 - val_loss: 0.3374 - val_acc: 0.8600\n",
      "Epoch 275/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3259 - acc: 0.8673 - val_loss: 0.3376 - val_acc: 0.8600\n",
      "Epoch 276/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3261 - acc: 0.8673 - val_loss: 0.3380 - val_acc: 0.8620\n",
      "Epoch 277/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3260 - acc: 0.8676 - val_loss: 0.3376 - val_acc: 0.8610\n",
      "Epoch 278/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3260 - acc: 0.8673 - val_loss: 0.3374 - val_acc: 0.8600\n",
      "Epoch 279/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3261 - acc: 0.8664 - val_loss: 0.3388 - val_acc: 0.8585\n",
      "Epoch 280/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3261 - acc: 0.8668 - val_loss: 0.3376 - val_acc: 0.8600\n",
      "Epoch 281/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3257 - acc: 0.8673 - val_loss: 0.3371 - val_acc: 0.8585\n",
      "Epoch 282/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3259 - acc: 0.8666 - val_loss: 0.3371 - val_acc: 0.8610\n",
      "Epoch 283/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3261 - acc: 0.8666 - val_loss: 0.3384 - val_acc: 0.8590\n",
      "Epoch 284/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3258 - acc: 0.8679 - val_loss: 0.3390 - val_acc: 0.8605\n",
      "Epoch 285/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3261 - acc: 0.8668 - val_loss: 0.3375 - val_acc: 0.8590\n",
      "Epoch 286/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3260 - acc: 0.8665 - val_loss: 0.3367 - val_acc: 0.8580\n",
      "Epoch 287/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3258 - acc: 0.8670 - val_loss: 0.3382 - val_acc: 0.8615\n",
      "Epoch 288/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3260 - acc: 0.8673 - val_loss: 0.3372 - val_acc: 0.8590\n",
      "Epoch 289/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3260 - acc: 0.8677 - val_loss: 0.3375 - val_acc: 0.8600\n",
      "Epoch 290/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3261 - acc: 0.8675 - val_loss: 0.3373 - val_acc: 0.8605\n",
      "Epoch 291/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3262 - acc: 0.8669 - val_loss: 0.3383 - val_acc: 0.8605\n",
      "Epoch 292/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3260 - acc: 0.8665 - val_loss: 0.3378 - val_acc: 0.8585\n",
      "Epoch 293/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3260 - acc: 0.8662 - val_loss: 0.3371 - val_acc: 0.8610\n",
      "Epoch 294/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3258 - acc: 0.8662 - val_loss: 0.3390 - val_acc: 0.8610\n",
      "Epoch 295/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3260 - acc: 0.8676 - val_loss: 0.3363 - val_acc: 0.8590\n",
      "Epoch 296/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3260 - acc: 0.8664 - val_loss: 0.3367 - val_acc: 0.8610\n",
      "Epoch 297/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3261 - acc: 0.8671 - val_loss: 0.3375 - val_acc: 0.8605\n",
      "Epoch 298/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3258 - acc: 0.8673 - val_loss: 0.3385 - val_acc: 0.8590\n",
      "Epoch 299/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3259 - acc: 0.8677 - val_loss: 0.3387 - val_acc: 0.8595\n",
      "Epoch 300/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3258 - acc: 0.8662 - val_loss: 0.3367 - val_acc: 0.8600\n",
      "Epoch 301/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3258 - acc: 0.8668 - val_loss: 0.3368 - val_acc: 0.8610\n",
      "Epoch 302/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3258 - acc: 0.8671 - val_loss: 0.3374 - val_acc: 0.8595\n",
      "Epoch 303/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3260 - acc: 0.8668 - val_loss: 0.3357 - val_acc: 0.8595\n",
      "Epoch 304/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3258 - acc: 0.8676 - val_loss: 0.3382 - val_acc: 0.8595\n",
      "Epoch 305/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3258 - acc: 0.8664 - val_loss: 0.3374 - val_acc: 0.8600\n",
      "Epoch 306/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3261 - acc: 0.8675 - val_loss: 0.3373 - val_acc: 0.8560\n",
      "Epoch 307/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3260 - acc: 0.8668 - val_loss: 0.3368 - val_acc: 0.8590\n",
      "Epoch 308/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3258 - acc: 0.8669 - val_loss: 0.3368 - val_acc: 0.8595\n",
      "Epoch 309/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3258 - acc: 0.8674 - val_loss: 0.3371 - val_acc: 0.8595\n",
      "Epoch 310/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3257 - acc: 0.8660 - val_loss: 0.3383 - val_acc: 0.8590\n",
      "Epoch 311/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3254 - acc: 0.8677 - val_loss: 0.3360 - val_acc: 0.8590\n",
      "Epoch 312/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3257 - acc: 0.8675 - val_loss: 0.3365 - val_acc: 0.8615\n",
      "Epoch 313/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3256 - acc: 0.8666 - val_loss: 0.3378 - val_acc: 0.8595\n",
      "Epoch 314/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3258 - acc: 0.8677 - val_loss: 0.3376 - val_acc: 0.8600\n",
      "Epoch 315/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3256 - acc: 0.8666 - val_loss: 0.3388 - val_acc: 0.8575\n",
      "Epoch 316/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3259 - acc: 0.866 - 0s 42us/sample - loss: 0.3260 - acc: 0.8677 - val_loss: 0.3378 - val_acc: 0.8605\n",
      "Epoch 317/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3256 - acc: 0.8671 - val_loss: 0.3381 - val_acc: 0.8595\n",
      "Epoch 318/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3258 - acc: 0.8659 - val_loss: 0.3378 - val_acc: 0.8590\n",
      "Epoch 319/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3255 - acc: 0.8679 - val_loss: 0.3362 - val_acc: 0.8605\n",
      "Epoch 320/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3256 - acc: 0.8664 - val_loss: 0.3365 - val_acc: 0.8605\n",
      "Epoch 321/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3255 - acc: 0.8675 - val_loss: 0.3361 - val_acc: 0.8595\n",
      "Epoch 322/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3257 - acc: 0.8670 - val_loss: 0.3364 - val_acc: 0.8585\n",
      "Epoch 323/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3255 - acc: 0.8673 - val_loss: 0.3370 - val_acc: 0.8590\n",
      "Epoch 324/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3254 - acc: 0.8673 - val_loss: 0.3372 - val_acc: 0.8590\n",
      "Epoch 325/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3254 - acc: 0.8666 - val_loss: 0.3364 - val_acc: 0.8595\n",
      "Epoch 326/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3260 - acc: 0.8662 - val_loss: 0.3359 - val_acc: 0.8600\n",
      "Epoch 327/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3254 - acc: 0.8673 - val_loss: 0.3359 - val_acc: 0.8605\n",
      "Epoch 328/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3255 - acc: 0.8671 - val_loss: 0.3362 - val_acc: 0.8590\n",
      "Epoch 329/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3253 - acc: 0.8655 - val_loss: 0.3365 - val_acc: 0.8585\n",
      "Epoch 330/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3255 - acc: 0.8679 - val_loss: 0.3364 - val_acc: 0.8590\n",
      "Epoch 331/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3254 - acc: 0.8666 - val_loss: 0.3360 - val_acc: 0.8600\n",
      "Epoch 332/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3256 - acc: 0.8679 - val_loss: 0.3357 - val_acc: 0.8595\n",
      "Epoch 333/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3256 - acc: 0.8676 - val_loss: 0.3369 - val_acc: 0.8595\n",
      "Epoch 334/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3256 - acc: 0.8660 - val_loss: 0.3373 - val_acc: 0.8580\n",
      "Epoch 335/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3256 - acc: 0.8671 - val_loss: 0.3364 - val_acc: 0.8615\n",
      "Epoch 336/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3255 - acc: 0.8676 - val_loss: 0.3362 - val_acc: 0.8585\n",
      "Epoch 337/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3253 - acc: 0.8673 - val_loss: 0.3362 - val_acc: 0.8615\n",
      "Epoch 338/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3256 - acc: 0.8671 - val_loss: 0.3377 - val_acc: 0.8590\n",
      "Epoch 339/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3256 - acc: 0.8673 - val_loss: 0.3360 - val_acc: 0.8585\n",
      "Epoch 340/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3253 - acc: 0.8668 - val_loss: 0.3366 - val_acc: 0.8590\n",
      "Epoch 341/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3258 - acc: 0.8676 - val_loss: 0.3380 - val_acc: 0.8590\n",
      "Epoch 342/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3255 - acc: 0.8675 - val_loss: 0.3361 - val_acc: 0.8585\n",
      "Epoch 343/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3254 - acc: 0.8671 - val_loss: 0.3361 - val_acc: 0.8605\n",
      "Epoch 344/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3253 - acc: 0.8660 - val_loss: 0.3356 - val_acc: 0.8575\n",
      "Epoch 345/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3254 - acc: 0.8674 - val_loss: 0.3371 - val_acc: 0.8590\n",
      "Epoch 346/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3253 - acc: 0.8662 - val_loss: 0.3371 - val_acc: 0.8590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3256 - acc: 0.8660 - val_loss: 0.3370 - val_acc: 0.8575\n",
      "Epoch 348/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3253 - acc: 0.8669 - val_loss: 0.3365 - val_acc: 0.8590\n",
      "Epoch 349/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3255 - acc: 0.8666 - val_loss: 0.3388 - val_acc: 0.8600\n",
      "Epoch 350/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3253 - acc: 0.8679 - val_loss: 0.3360 - val_acc: 0.8590\n",
      "Epoch 351/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3252 - acc: 0.8670 - val_loss: 0.3356 - val_acc: 0.8585\n",
      "Epoch 352/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3254 - acc: 0.8673 - val_loss: 0.3364 - val_acc: 0.8580\n",
      "Epoch 353/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3249 - acc: 0.8669 - val_loss: 0.3359 - val_acc: 0.8590\n",
      "Epoch 354/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3251 - acc: 0.8664 - val_loss: 0.3369 - val_acc: 0.8580\n",
      "Epoch 355/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3251 - acc: 0.8681 - val_loss: 0.3368 - val_acc: 0.8585\n",
      "Epoch 356/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3253 - acc: 0.8665 - val_loss: 0.3365 - val_acc: 0.8580\n",
      "Epoch 357/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3251 - acc: 0.8675 - val_loss: 0.3362 - val_acc: 0.8600\n",
      "Epoch 358/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3255 - acc: 0.8669 - val_loss: 0.3357 - val_acc: 0.8595\n",
      "Epoch 359/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3249 - acc: 0.8673 - val_loss: 0.3354 - val_acc: 0.8580\n",
      "Epoch 360/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3253 - acc: 0.8665 - val_loss: 0.3385 - val_acc: 0.8565\n",
      "Epoch 361/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3251 - acc: 0.8673 - val_loss: 0.3380 - val_acc: 0.8580\n",
      "Epoch 362/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3248 - acc: 0.8684 - val_loss: 0.3355 - val_acc: 0.8605\n",
      "Epoch 363/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3251 - acc: 0.8673 - val_loss: 0.3370 - val_acc: 0.8585\n",
      "Epoch 364/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3251 - acc: 0.8658 - val_loss: 0.3353 - val_acc: 0.8605\n",
      "Epoch 365/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3249 - acc: 0.8661 - val_loss: 0.3357 - val_acc: 0.8595\n",
      "Epoch 366/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3253 - acc: 0.8680 - val_loss: 0.3356 - val_acc: 0.8585\n",
      "Epoch 367/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3252 - acc: 0.8681 - val_loss: 0.3362 - val_acc: 0.8605\n",
      "Epoch 368/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3250 - acc: 0.8670 - val_loss: 0.3357 - val_acc: 0.8605\n",
      "Epoch 369/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3249 - acc: 0.8677 - val_loss: 0.3363 - val_acc: 0.8595\n",
      "Epoch 370/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3247 - acc: 0.8676 - val_loss: 0.3354 - val_acc: 0.8600\n",
      "Epoch 371/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3249 - acc: 0.8669 - val_loss: 0.3376 - val_acc: 0.8605\n",
      "Epoch 372/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3250 - acc: 0.8674 - val_loss: 0.3358 - val_acc: 0.8590\n",
      "Epoch 373/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3248 - acc: 0.8671 - val_loss: 0.3364 - val_acc: 0.8600\n",
      "Epoch 374/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3247 - acc: 0.8671 - val_loss: 0.3349 - val_acc: 0.8585\n",
      "Epoch 375/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3248 - acc: 0.8670 - val_loss: 0.3393 - val_acc: 0.8590\n",
      "Epoch 376/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3249 - acc: 0.8670 - val_loss: 0.3361 - val_acc: 0.8595\n",
      "Epoch 377/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3252 - acc: 0.8669 - val_loss: 0.3355 - val_acc: 0.8585\n",
      "Epoch 378/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3249 - acc: 0.8681 - val_loss: 0.3363 - val_acc: 0.8575\n",
      "Epoch 379/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3248 - acc: 0.8673 - val_loss: 0.3370 - val_acc: 0.8580\n",
      "Epoch 380/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3248 - acc: 0.8684 - val_loss: 0.3355 - val_acc: 0.8580\n",
      "Epoch 381/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3247 - acc: 0.8671 - val_loss: 0.3355 - val_acc: 0.8585\n",
      "Epoch 382/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3247 - acc: 0.8671 - val_loss: 0.3349 - val_acc: 0.8590\n",
      "Epoch 383/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3247 - acc: 0.8677 - val_loss: 0.3368 - val_acc: 0.8595\n",
      "Epoch 384/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3249 - acc: 0.8675 - val_loss: 0.3353 - val_acc: 0.8585\n",
      "Epoch 385/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3249 - acc: 0.8675 - val_loss: 0.3366 - val_acc: 0.8585\n",
      "Epoch 386/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3249 - acc: 0.8664 - val_loss: 0.3351 - val_acc: 0.8595\n",
      "Epoch 387/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3251 - acc: 0.8684 - val_loss: 0.3373 - val_acc: 0.8585\n",
      "Epoch 388/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3245 - acc: 0.8680 - val_loss: 0.3345 - val_acc: 0.8595\n",
      "Epoch 389/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3248 - acc: 0.8668 - val_loss: 0.3345 - val_acc: 0.8585\n",
      "Epoch 390/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3253 - acc: 0.8669 - val_loss: 0.3371 - val_acc: 0.8585\n",
      "Epoch 391/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3245 - acc: 0.8669 - val_loss: 0.3359 - val_acc: 0.8595\n",
      "Epoch 392/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3246 - acc: 0.8680 - val_loss: 0.3353 - val_acc: 0.8595\n",
      "Epoch 393/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3247 - acc: 0.8673 - val_loss: 0.3363 - val_acc: 0.8580\n",
      "Epoch 394/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3246 - acc: 0.8674 - val_loss: 0.3355 - val_acc: 0.8600\n",
      "Epoch 395/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3247 - acc: 0.8679 - val_loss: 0.3362 - val_acc: 0.8590\n",
      "Epoch 396/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3247 - acc: 0.8676 - val_loss: 0.3375 - val_acc: 0.8595\n",
      "Epoch 397/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3247 - acc: 0.8683 - val_loss: 0.3358 - val_acc: 0.8585\n",
      "Epoch 398/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3250 - acc: 0.8660 - val_loss: 0.3348 - val_acc: 0.8595\n",
      "Epoch 399/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3249 - acc: 0.8677 - val_loss: 0.3354 - val_acc: 0.8595\n",
      "Epoch 400/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3248 - acc: 0.8679 - val_loss: 0.3367 - val_acc: 0.8580\n",
      "Epoch 401/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3246 - acc: 0.8665 - val_loss: 0.3392 - val_acc: 0.8570\n",
      "Epoch 402/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3247 - acc: 0.8683 - val_loss: 0.3363 - val_acc: 0.8570\n",
      "Epoch 403/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3245 - acc: 0.8670 - val_loss: 0.3365 - val_acc: 0.8570\n",
      "Epoch 404/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3231 - acc: 0.870 - 0s 44us/sample - loss: 0.3243 - acc: 0.8686 - val_loss: 0.3362 - val_acc: 0.8580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3246 - acc: 0.8683 - val_loss: 0.3358 - val_acc: 0.8585\n",
      "Epoch 406/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3249 - acc: 0.8681 - val_loss: 0.3354 - val_acc: 0.8595\n",
      "Epoch 407/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3247 - acc: 0.8679 - val_loss: 0.3356 - val_acc: 0.8595\n",
      "Epoch 408/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3252 - acc: 0.8676 - val_loss: 0.3391 - val_acc: 0.8600\n",
      "Epoch 409/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3247 - acc: 0.8676 - val_loss: 0.3361 - val_acc: 0.8595\n",
      "Epoch 410/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3244 - acc: 0.8691 - val_loss: 0.3350 - val_acc: 0.8585\n",
      "Epoch 411/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3246 - acc: 0.8677 - val_loss: 0.3358 - val_acc: 0.8600\n",
      "Epoch 412/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3244 - acc: 0.8670 - val_loss: 0.3362 - val_acc: 0.8590\n",
      "Epoch 413/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3243 - acc: 0.8691 - val_loss: 0.3344 - val_acc: 0.8605\n",
      "Epoch 414/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3242 - acc: 0.8679 - val_loss: 0.3378 - val_acc: 0.8585\n",
      "Epoch 415/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3245 - acc: 0.8675 - val_loss: 0.3355 - val_acc: 0.8595\n",
      "Epoch 416/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3242 - acc: 0.8666 - val_loss: 0.3368 - val_acc: 0.8585\n",
      "Epoch 417/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3245 - acc: 0.8680 - val_loss: 0.3361 - val_acc: 0.8590\n",
      "Epoch 418/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3245 - acc: 0.8683 - val_loss: 0.3359 - val_acc: 0.8570\n",
      "Epoch 419/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3244 - acc: 0.8677 - val_loss: 0.3346 - val_acc: 0.8585\n",
      "Epoch 420/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3243 - acc: 0.8679 - val_loss: 0.3364 - val_acc: 0.8565\n",
      "Epoch 421/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3243 - acc: 0.8677 - val_loss: 0.3356 - val_acc: 0.8580\n",
      "Epoch 422/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3246 - acc: 0.8685 - val_loss: 0.3353 - val_acc: 0.8580\n",
      "Epoch 423/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3245 - acc: 0.8676 - val_loss: 0.3357 - val_acc: 0.8580\n",
      "Epoch 424/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3243 - acc: 0.8675 - val_loss: 0.3357 - val_acc: 0.8600\n",
      "Epoch 425/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3245 - acc: 0.8677 - val_loss: 0.3356 - val_acc: 0.8585\n",
      "Epoch 426/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3243 - acc: 0.8674 - val_loss: 0.3350 - val_acc: 0.8590\n",
      "Epoch 427/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3243 - acc: 0.8671 - val_loss: 0.3351 - val_acc: 0.8570\n",
      "Epoch 428/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3241 - acc: 0.8668 - val_loss: 0.3356 - val_acc: 0.8570\n",
      "Epoch 429/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3244 - acc: 0.8666 - val_loss: 0.3354 - val_acc: 0.8590\n",
      "Epoch 430/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3243 - acc: 0.8680 - val_loss: 0.3350 - val_acc: 0.8585\n",
      "Epoch 431/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3245 - acc: 0.8679 - val_loss: 0.3361 - val_acc: 0.8585\n",
      "Epoch 432/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3243 - acc: 0.8680 - val_loss: 0.3360 - val_acc: 0.8590\n",
      "Epoch 433/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3243 - acc: 0.8686 - val_loss: 0.3361 - val_acc: 0.8565\n",
      "Epoch 434/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3238 - acc: 0.8679 - val_loss: 0.3355 - val_acc: 0.8575\n",
      "Epoch 435/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3243 - acc: 0.8675 - val_loss: 0.3358 - val_acc: 0.8580\n",
      "Epoch 436/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3243 - acc: 0.8680 - val_loss: 0.3367 - val_acc: 0.8575\n",
      "Epoch 437/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3243 - acc: 0.8671 - val_loss: 0.3366 - val_acc: 0.8575\n",
      "Epoch 438/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3241 - acc: 0.8676 - val_loss: 0.3372 - val_acc: 0.8590\n",
      "Epoch 439/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3245 - acc: 0.8691 - val_loss: 0.3373 - val_acc: 0.8590\n",
      "Epoch 440/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3242 - acc: 0.8675 - val_loss: 0.3388 - val_acc: 0.8595\n",
      "Epoch 441/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3244 - acc: 0.8677 - val_loss: 0.3359 - val_acc: 0.8575\n",
      "Epoch 442/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3242 - acc: 0.8677 - val_loss: 0.3353 - val_acc: 0.8575\n",
      "Epoch 443/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3240 - acc: 0.8677 - val_loss: 0.3378 - val_acc: 0.8580\n",
      "Epoch 444/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3240 - acc: 0.8684 - val_loss: 0.3350 - val_acc: 0.8570\n",
      "Epoch 445/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3240 - acc: 0.8676 - val_loss: 0.3358 - val_acc: 0.8570\n",
      "Epoch 446/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3241 - acc: 0.8675 - val_loss: 0.3351 - val_acc: 0.8585\n",
      "Epoch 447/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3240 - acc: 0.8675 - val_loss: 0.3364 - val_acc: 0.8580\n",
      "Epoch 448/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3239 - acc: 0.8683 - val_loss: 0.3358 - val_acc: 0.8585\n",
      "Epoch 449/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3239 - acc: 0.8671 - val_loss: 0.3343 - val_acc: 0.8590\n",
      "Epoch 450/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3241 - acc: 0.8676 - val_loss: 0.3368 - val_acc: 0.8590\n",
      "Epoch 451/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3243 - acc: 0.8685 - val_loss: 0.3355 - val_acc: 0.8575\n",
      "Epoch 452/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3241 - acc: 0.8670 - val_loss: 0.3345 - val_acc: 0.8580\n",
      "Epoch 453/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3244 - acc: 0.8673 - val_loss: 0.3348 - val_acc: 0.8595\n",
      "Epoch 454/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3239 - acc: 0.8674 - val_loss: 0.3351 - val_acc: 0.8580\n",
      "Epoch 455/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3238 - acc: 0.8687 - val_loss: 0.3366 - val_acc: 0.8570\n",
      "Epoch 456/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3240 - acc: 0.8673 - val_loss: 0.3367 - val_acc: 0.8570\n",
      "Epoch 457/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3239 - acc: 0.8673 - val_loss: 0.3352 - val_acc: 0.8590\n",
      "Epoch 458/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3236 - acc: 0.8689 - val_loss: 0.3377 - val_acc: 0.8570\n",
      "Epoch 459/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3240 - acc: 0.8669 - val_loss: 0.3350 - val_acc: 0.8575\n",
      "Epoch 460/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3240 - acc: 0.8677 - val_loss: 0.3359 - val_acc: 0.8590\n",
      "Epoch 461/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3239 - acc: 0.8699 - val_loss: 0.3356 - val_acc: 0.8590\n",
      "Epoch 462/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3236 - acc: 0.8679 - val_loss: 0.3362 - val_acc: 0.8575\n",
      "Epoch 463/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3238 - acc: 0.8675 - val_loss: 0.3365 - val_acc: 0.8580\n",
      "Epoch 464/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3239 - acc: 0.8675 - val_loss: 0.3380 - val_acc: 0.8575\n",
      "Epoch 465/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3239 - acc: 0.8675 - val_loss: 0.3355 - val_acc: 0.8590\n",
      "Epoch 466/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3237 - acc: 0.8681 - val_loss: 0.3373 - val_acc: 0.8595\n",
      "Epoch 467/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3237 - acc: 0.8671 - val_loss: 0.3351 - val_acc: 0.8580\n",
      "Epoch 468/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3237 - acc: 0.8669 - val_loss: 0.3345 - val_acc: 0.8575\n",
      "Epoch 469/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3237 - acc: 0.8685 - val_loss: 0.3356 - val_acc: 0.8585\n",
      "Epoch 470/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3236 - acc: 0.8684 - val_loss: 0.3373 - val_acc: 0.8575\n",
      "Epoch 471/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3239 - acc: 0.8673 - val_loss: 0.3359 - val_acc: 0.8570\n",
      "Epoch 472/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3237 - acc: 0.8684 - val_loss: 0.3381 - val_acc: 0.8580\n",
      "Epoch 473/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3236 - acc: 0.8685 - val_loss: 0.3350 - val_acc: 0.8580\n",
      "Epoch 474/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3236 - acc: 0.8687 - val_loss: 0.3354 - val_acc: 0.8565\n",
      "Epoch 475/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3239 - acc: 0.8676 - val_loss: 0.3356 - val_acc: 0.8580\n",
      "Epoch 476/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3240 - acc: 0.8670 - val_loss: 0.3358 - val_acc: 0.8585\n",
      "Epoch 477/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3235 - acc: 0.8677 - val_loss: 0.3351 - val_acc: 0.8575\n",
      "Epoch 478/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3236 - acc: 0.8679 - val_loss: 0.3359 - val_acc: 0.8585\n",
      "Epoch 479/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3238 - acc: 0.8677 - val_loss: 0.3363 - val_acc: 0.8590\n",
      "Epoch 480/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3236 - acc: 0.8687 - val_loss: 0.3363 - val_acc: 0.8585\n",
      "Epoch 481/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3236 - acc: 0.8671 - val_loss: 0.3368 - val_acc: 0.8585\n",
      "Epoch 482/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3241 - acc: 0.8666 - val_loss: 0.3383 - val_acc: 0.8605\n",
      "Epoch 483/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3235 - acc: 0.8675 - val_loss: 0.3380 - val_acc: 0.8585\n",
      "Epoch 484/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3236 - acc: 0.8679 - val_loss: 0.3357 - val_acc: 0.8590\n",
      "Epoch 485/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3239 - acc: 0.8680 - val_loss: 0.3376 - val_acc: 0.8585\n",
      "Epoch 486/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3237 - acc: 0.8669 - val_loss: 0.3369 - val_acc: 0.8600\n",
      "Epoch 487/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3235 - acc: 0.8690 - val_loss: 0.3349 - val_acc: 0.8580\n",
      "Epoch 488/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3235 - acc: 0.8685 - val_loss: 0.3387 - val_acc: 0.8610\n",
      "Epoch 489/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3234 - acc: 0.8686 - val_loss: 0.3359 - val_acc: 0.8560\n",
      "Epoch 490/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3233 - acc: 0.8675 - val_loss: 0.3366 - val_acc: 0.8585\n",
      "Epoch 491/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3237 - acc: 0.8677 - val_loss: 0.3364 - val_acc: 0.8580\n",
      "Epoch 492/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3233 - acc: 0.8671 - val_loss: 0.3353 - val_acc: 0.8565\n",
      "Epoch 493/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3234 - acc: 0.8674 - val_loss: 0.3373 - val_acc: 0.8590\n",
      "Epoch 494/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3236 - acc: 0.8687 - val_loss: 0.3357 - val_acc: 0.8560\n",
      "Epoch 495/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3238 - acc: 0.8675 - val_loss: 0.3350 - val_acc: 0.8560\n",
      "Epoch 496/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3235 - acc: 0.8683 - val_loss: 0.3372 - val_acc: 0.8575\n",
      "Epoch 497/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3232 - acc: 0.8691 - val_loss: 0.3359 - val_acc: 0.8565\n",
      "Epoch 498/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3236 - acc: 0.8685 - val_loss: 0.3367 - val_acc: 0.8580\n",
      "Epoch 499/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3233 - acc: 0.8685 - val_loss: 0.3361 - val_acc: 0.8575\n",
      "Epoch 500/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3232 - acc: 0.8676 - val_loss: 0.3353 - val_acc: 0.8580\n",
      "Epoch 501/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3236 - acc: 0.8674 - val_loss: 0.3351 - val_acc: 0.8565\n",
      "Epoch 502/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3234 - acc: 0.8681 - val_loss: 0.3370 - val_acc: 0.8565\n",
      "Epoch 503/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3235 - acc: 0.8677 - val_loss: 0.3354 - val_acc: 0.8565\n",
      "Epoch 504/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3233 - acc: 0.8690 - val_loss: 0.3353 - val_acc: 0.8550\n",
      "Epoch 505/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3233 - acc: 0.8681 - val_loss: 0.3369 - val_acc: 0.8595\n",
      "Epoch 506/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3231 - acc: 0.8670 - val_loss: 0.3352 - val_acc: 0.8580\n",
      "Epoch 507/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3235 - acc: 0.8664 - val_loss: 0.3363 - val_acc: 0.8580\n",
      "Epoch 508/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3233 - acc: 0.8690 - val_loss: 0.3355 - val_acc: 0.8585\n",
      "Epoch 509/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3234 - acc: 0.8670 - val_loss: 0.3393 - val_acc: 0.8610\n",
      "Epoch 510/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3236 - acc: 0.8673 - val_loss: 0.3365 - val_acc: 0.8570\n",
      "Epoch 511/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3236 - acc: 0.8680 - val_loss: 0.3360 - val_acc: 0.8565\n",
      "Epoch 512/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3235 - acc: 0.8674 - val_loss: 0.3351 - val_acc: 0.8570\n",
      "Epoch 513/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3231 - acc: 0.8686 - val_loss: 0.3381 - val_acc: 0.8615\n",
      "Epoch 514/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3233 - acc: 0.8689 - val_loss: 0.3359 - val_acc: 0.8560\n",
      "Epoch 515/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3235 - acc: 0.8686 - val_loss: 0.3379 - val_acc: 0.8610\n",
      "Epoch 516/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3230 - acc: 0.8686 - val_loss: 0.3352 - val_acc: 0.8555\n",
      "Epoch 517/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3233 - acc: 0.8689 - val_loss: 0.3355 - val_acc: 0.8580\n",
      "Epoch 518/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3232 - acc: 0.8680 - val_loss: 0.3363 - val_acc: 0.8565\n",
      "Epoch 519/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3231 - acc: 0.8677 - val_loss: 0.3372 - val_acc: 0.8580\n",
      "Epoch 520/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3231 - acc: 0.8680 - val_loss: 0.3362 - val_acc: 0.8560\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3230 - acc: 0.8674 - val_loss: 0.3363 - val_acc: 0.8570\n",
      "Epoch 522/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3231 - acc: 0.8685 - val_loss: 0.3353 - val_acc: 0.8585\n",
      "Epoch 523/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3230 - acc: 0.8684 - val_loss: 0.3365 - val_acc: 0.8610\n",
      "Epoch 524/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3230 - acc: 0.8684 - val_loss: 0.3367 - val_acc: 0.8585\n",
      "Epoch 525/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3231 - acc: 0.8686 - val_loss: 0.3360 - val_acc: 0.8590\n",
      "Epoch 526/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3231 - acc: 0.8679 - val_loss: 0.3359 - val_acc: 0.8575\n",
      "Epoch 527/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3232 - acc: 0.8676 - val_loss: 0.3360 - val_acc: 0.8580\n",
      "Epoch 528/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3231 - acc: 0.8686 - val_loss: 0.3346 - val_acc: 0.8565\n",
      "Epoch 529/1000\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3233 - acc: 0.8694 - val_loss: 0.3353 - val_acc: 0.8565\n",
      "Epoch 530/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3234 - acc: 0.8687 - val_loss: 0.3355 - val_acc: 0.8580\n",
      "Epoch 531/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3232 - acc: 0.8684 - val_loss: 0.3361 - val_acc: 0.8565\n",
      "Epoch 532/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3229 - acc: 0.8680 - val_loss: 0.3353 - val_acc: 0.8550\n",
      "Epoch 533/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3232 - acc: 0.8674 - val_loss: 0.3352 - val_acc: 0.8590\n",
      "Epoch 534/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3232 - acc: 0.8679 - val_loss: 0.3362 - val_acc: 0.8575\n",
      "Epoch 535/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3232 - acc: 0.8685 - val_loss: 0.3343 - val_acc: 0.8575\n",
      "Epoch 536/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3231 - acc: 0.8695 - val_loss: 0.3349 - val_acc: 0.8565\n",
      "Epoch 537/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3233 - acc: 0.8673 - val_loss: 0.3358 - val_acc: 0.8580\n",
      "Epoch 538/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3230 - acc: 0.8692 - val_loss: 0.3383 - val_acc: 0.8555\n",
      "Epoch 539/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3232 - acc: 0.8684 - val_loss: 0.3354 - val_acc: 0.8555\n",
      "Epoch 540/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3231 - acc: 0.8687 - val_loss: 0.3380 - val_acc: 0.8610\n",
      "Epoch 541/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3230 - acc: 0.8696 - val_loss: 0.3369 - val_acc: 0.8590\n",
      "Epoch 542/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3229 - acc: 0.8673 - val_loss: 0.3362 - val_acc: 0.8575\n",
      "Epoch 543/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3232 - acc: 0.8676 - val_loss: 0.3370 - val_acc: 0.8585\n",
      "Epoch 544/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3230 - acc: 0.8679 - val_loss: 0.3352 - val_acc: 0.8570\n",
      "Epoch 545/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3228 - acc: 0.8691 - val_loss: 0.3346 - val_acc: 0.8570\n",
      "Epoch 546/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3230 - acc: 0.8677 - val_loss: 0.3349 - val_acc: 0.8580\n",
      "Epoch 547/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3232 - acc: 0.8676 - val_loss: 0.3375 - val_acc: 0.8595\n",
      "Epoch 548/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3232 - acc: 0.8680 - val_loss: 0.3364 - val_acc: 0.8560\n",
      "Epoch 549/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3229 - acc: 0.8681 - val_loss: 0.3356 - val_acc: 0.8575\n",
      "Epoch 550/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3230 - acc: 0.8687 - val_loss: 0.3344 - val_acc: 0.8570\n",
      "Epoch 551/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3231 - acc: 0.8668 - val_loss: 0.3356 - val_acc: 0.8565\n",
      "Epoch 552/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3230 - acc: 0.8670 - val_loss: 0.3357 - val_acc: 0.8570\n",
      "Epoch 553/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3231 - acc: 0.8673 - val_loss: 0.3369 - val_acc: 0.8585\n",
      "Epoch 554/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3229 - acc: 0.8679 - val_loss: 0.3355 - val_acc: 0.8570\n",
      "Epoch 555/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3231 - acc: 0.8687 - val_loss: 0.3357 - val_acc: 0.8555\n",
      "Epoch 556/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3231 - acc: 0.8683 - val_loss: 0.3361 - val_acc: 0.8585\n",
      "Epoch 557/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3229 - acc: 0.8676 - val_loss: 0.3356 - val_acc: 0.8565\n",
      "Epoch 558/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3228 - acc: 0.8685 - val_loss: 0.3345 - val_acc: 0.8575\n",
      "Epoch 559/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3228 - acc: 0.8686 - val_loss: 0.3354 - val_acc: 0.8570\n",
      "Epoch 560/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3231 - acc: 0.8676 - val_loss: 0.3347 - val_acc: 0.8590\n",
      "Epoch 561/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3229 - acc: 0.8674 - val_loss: 0.3374 - val_acc: 0.8600\n",
      "Epoch 562/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3230 - acc: 0.8679 - val_loss: 0.3374 - val_acc: 0.8610\n",
      "Epoch 563/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3230 - acc: 0.8683 - val_loss: 0.3362 - val_acc: 0.8550\n",
      "Epoch 564/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3228 - acc: 0.8680 - val_loss: 0.3373 - val_acc: 0.8605\n",
      "Epoch 565/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3228 - acc: 0.8679 - val_loss: 0.3349 - val_acc: 0.8570\n",
      "Epoch 566/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3230 - acc: 0.8686 - val_loss: 0.3375 - val_acc: 0.8615\n",
      "Epoch 567/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3230 - acc: 0.8684 - val_loss: 0.3348 - val_acc: 0.8555\n",
      "Epoch 568/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3225 - acc: 0.8689 - val_loss: 0.3364 - val_acc: 0.8570\n",
      "Epoch 569/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3228 - acc: 0.8674 - val_loss: 0.3373 - val_acc: 0.8585\n",
      "Epoch 570/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3228 - acc: 0.8684 - val_loss: 0.3357 - val_acc: 0.8560\n",
      "Epoch 571/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3226 - acc: 0.8686 - val_loss: 0.3355 - val_acc: 0.8565\n",
      "Epoch 572/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3229 - acc: 0.8674 - val_loss: 0.3376 - val_acc: 0.8600\n",
      "Epoch 573/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3229 - acc: 0.8684 - val_loss: 0.3383 - val_acc: 0.8605\n",
      "Epoch 574/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3227 - acc: 0.8685 - val_loss: 0.3349 - val_acc: 0.8590\n",
      "Epoch 575/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3228 - acc: 0.8670 - val_loss: 0.3349 - val_acc: 0.8575\n",
      "Epoch 576/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3231 - acc: 0.8675 - val_loss: 0.3346 - val_acc: 0.8570\n",
      "Epoch 577/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3225 - acc: 0.8680 - val_loss: 0.3366 - val_acc: 0.8570\n",
      "Epoch 578/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3226 - acc: 0.8670 - val_loss: 0.3356 - val_acc: 0.8580\n",
      "Epoch 579/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3227 - acc: 0.8679 - val_loss: 0.3369 - val_acc: 0.8590\n",
      "Epoch 580/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3229 - acc: 0.8669 - val_loss: 0.3371 - val_acc: 0.8600\n",
      "Epoch 581/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3243 - acc: 0.867 - 0s 44us/sample - loss: 0.3228 - acc: 0.8674 - val_loss: 0.3357 - val_acc: 0.8565\n",
      "Epoch 582/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3223 - acc: 0.8670 - val_loss: 0.3341 - val_acc: 0.8575\n",
      "Epoch 583/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3230 - acc: 0.8680 - val_loss: 0.3368 - val_acc: 0.8550\n",
      "Epoch 584/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3227 - acc: 0.8670 - val_loss: 0.3386 - val_acc: 0.8605\n",
      "Epoch 585/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3229 - acc: 0.8670 - val_loss: 0.3362 - val_acc: 0.8570\n",
      "Epoch 586/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3228 - acc: 0.8684 - val_loss: 0.3352 - val_acc: 0.8565\n",
      "Epoch 587/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3229 - acc: 0.8694 - val_loss: 0.3345 - val_acc: 0.8575\n",
      "Epoch 588/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3230 - acc: 0.8686 - val_loss: 0.3360 - val_acc: 0.8565\n",
      "Epoch 589/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3230 - acc: 0.8671 - val_loss: 0.3370 - val_acc: 0.8570\n",
      "Epoch 590/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3227 - acc: 0.8670 - val_loss: 0.3357 - val_acc: 0.8570\n",
      "Epoch 591/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3224 - acc: 0.8686 - val_loss: 0.3359 - val_acc: 0.8575\n",
      "Epoch 592/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3225 - acc: 0.8673 - val_loss: 0.3358 - val_acc: 0.8560\n",
      "Epoch 593/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3229 - acc: 0.8673 - val_loss: 0.3364 - val_acc: 0.8560\n",
      "Epoch 594/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3230 - acc: 0.8675 - val_loss: 0.3372 - val_acc: 0.8595\n",
      "Epoch 595/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3229 - acc: 0.8684 - val_loss: 0.3367 - val_acc: 0.8575\n",
      "Epoch 596/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3227 - acc: 0.8680 - val_loss: 0.3373 - val_acc: 0.8550\n",
      "Epoch 597/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3228 - acc: 0.8681 - val_loss: 0.3362 - val_acc: 0.8565\n",
      "Epoch 598/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3225 - acc: 0.8679 - val_loss: 0.3371 - val_acc: 0.8580\n",
      "Epoch 599/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3229 - acc: 0.8664 - val_loss: 0.3360 - val_acc: 0.8590\n",
      "Epoch 600/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3226 - acc: 0.8679 - val_loss: 0.3364 - val_acc: 0.8550\n",
      "Epoch 601/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3226 - acc: 0.8679 - val_loss: 0.3361 - val_acc: 0.8605\n",
      "Epoch 602/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3227 - acc: 0.8684 - val_loss: 0.3358 - val_acc: 0.8550\n",
      "Epoch 603/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3228 - acc: 0.8666 - val_loss: 0.3365 - val_acc: 0.8560\n",
      "Epoch 604/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3225 - acc: 0.8684 - val_loss: 0.3359 - val_acc: 0.8545\n",
      "Epoch 605/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3229 - acc: 0.8662 - val_loss: 0.3353 - val_acc: 0.8575\n",
      "Epoch 606/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3226 - acc: 0.8673 - val_loss: 0.3356 - val_acc: 0.8590\n",
      "Epoch 607/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3227 - acc: 0.8674 - val_loss: 0.3367 - val_acc: 0.8590\n",
      "Epoch 608/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3224 - acc: 0.867 - 0s 46us/sample - loss: 0.3226 - acc: 0.8670 - val_loss: 0.3358 - val_acc: 0.8560\n",
      "Epoch 609/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3226 - acc: 0.8670 - val_loss: 0.3356 - val_acc: 0.8565\n",
      "Epoch 610/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3225 - acc: 0.8680 - val_loss: 0.3362 - val_acc: 0.8555\n",
      "Epoch 611/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3225 - acc: 0.8679 - val_loss: 0.3364 - val_acc: 0.8545\n",
      "Epoch 612/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3226 - acc: 0.8670 - val_loss: 0.3351 - val_acc: 0.8560\n",
      "Epoch 613/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3223 - acc: 0.8683 - val_loss: 0.3387 - val_acc: 0.8600\n",
      "Epoch 614/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3228 - acc: 0.8685 - val_loss: 0.3389 - val_acc: 0.8610\n",
      "Epoch 615/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3226 - acc: 0.8681 - val_loss: 0.3357 - val_acc: 0.8555\n",
      "Epoch 616/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3225 - acc: 0.8684 - val_loss: 0.3382 - val_acc: 0.8600\n",
      "Epoch 617/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3228 - acc: 0.8675 - val_loss: 0.3364 - val_acc: 0.8545\n",
      "Epoch 618/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3226 - acc: 0.8677 - val_loss: 0.3357 - val_acc: 0.8580\n",
      "Epoch 619/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3227 - acc: 0.8676 - val_loss: 0.3354 - val_acc: 0.8555\n",
      "Epoch 620/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3227 - acc: 0.8685 - val_loss: 0.3348 - val_acc: 0.8550\n",
      "Epoch 621/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3225 - acc: 0.8684 - val_loss: 0.3376 - val_acc: 0.8585\n",
      "Epoch 622/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3229 - acc: 0.8685 - val_loss: 0.3358 - val_acc: 0.8545\n",
      "Epoch 623/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3224 - acc: 0.8685 - val_loss: 0.3361 - val_acc: 0.8545\n",
      "Epoch 624/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3226 - acc: 0.8670 - val_loss: 0.3367 - val_acc: 0.8570\n",
      "Epoch 625/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3227 - acc: 0.8687 - val_loss: 0.3371 - val_acc: 0.8570\n",
      "Epoch 626/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3226 - acc: 0.8681 - val_loss: 0.3359 - val_acc: 0.8545\n",
      "Epoch 627/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3225 - acc: 0.8677 - val_loss: 0.3354 - val_acc: 0.8570\n",
      "Epoch 628/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3222 - acc: 0.8687 - val_loss: 0.3357 - val_acc: 0.8555\n",
      "Epoch 629/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3227 - acc: 0.8675 - val_loss: 0.3361 - val_acc: 0.8570\n",
      "Epoch 630/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3226 - acc: 0.8680 - val_loss: 0.3369 - val_acc: 0.8550\n",
      "Epoch 631/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3223 - acc: 0.8679 - val_loss: 0.3373 - val_acc: 0.8580\n",
      "Epoch 632/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3223 - acc: 0.8686 - val_loss: 0.3365 - val_acc: 0.8555\n",
      "Epoch 633/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3223 - acc: 0.8690 - val_loss: 0.3371 - val_acc: 0.8565\n",
      "Epoch 634/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3225 - acc: 0.8683 - val_loss: 0.3361 - val_acc: 0.8570\n",
      "Epoch 635/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3225 - acc: 0.8677 - val_loss: 0.3353 - val_acc: 0.8560\n",
      "Epoch 636/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3225 - acc: 0.8675 - val_loss: 0.3374 - val_acc: 0.8555\n",
      "Epoch 637/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3223 - acc: 0.8666 - val_loss: 0.3367 - val_acc: 0.8560\n",
      "Epoch 638/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3223 - acc: 0.8673 - val_loss: 0.3367 - val_acc: 0.8565\n",
      "Epoch 639/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3225 - acc: 0.8681 - val_loss: 0.3370 - val_acc: 0.8565\n",
      "Epoch 640/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3224 - acc: 0.8677 - val_loss: 0.3366 - val_acc: 0.8560\n",
      "Epoch 641/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3223 - acc: 0.8677 - val_loss: 0.3349 - val_acc: 0.8555\n",
      "Epoch 642/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3225 - acc: 0.8677 - val_loss: 0.3361 - val_acc: 0.8555\n",
      "Epoch 643/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3223 - acc: 0.8683 - val_loss: 0.3359 - val_acc: 0.8550\n",
      "Epoch 644/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3224 - acc: 0.8679 - val_loss: 0.3360 - val_acc: 0.8555\n",
      "Epoch 645/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3224 - acc: 0.8689 - val_loss: 0.3378 - val_acc: 0.8570\n",
      "Epoch 646/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3221 - acc: 0.8676 - val_loss: 0.3382 - val_acc: 0.8580\n",
      "Epoch 647/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3225 - acc: 0.8681 - val_loss: 0.3372 - val_acc: 0.8580\n",
      "Epoch 648/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3221 - acc: 0.8684 - val_loss: 0.3351 - val_acc: 0.8550\n",
      "Epoch 649/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3228 - acc: 0.8680 - val_loss: 0.3357 - val_acc: 0.8555\n",
      "Epoch 650/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3222 - acc: 0.8671 - val_loss: 0.3357 - val_acc: 0.8580\n",
      "Epoch 651/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3225 - acc: 0.8676 - val_loss: 0.3366 - val_acc: 0.8580\n",
      "Epoch 652/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3223 - acc: 0.8670 - val_loss: 0.3360 - val_acc: 0.8570\n",
      "Epoch 653/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3223 - acc: 0.8689 - val_loss: 0.3357 - val_acc: 0.8550\n",
      "Epoch 654/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3224 - acc: 0.8683 - val_loss: 0.3367 - val_acc: 0.8560\n",
      "Epoch 655/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3223 - acc: 0.8677 - val_loss: 0.3366 - val_acc: 0.8555\n",
      "Epoch 656/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3226 - acc: 0.8699 - val_loss: 0.3368 - val_acc: 0.8565\n",
      "Epoch 657/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3222 - acc: 0.8669 - val_loss: 0.3353 - val_acc: 0.8560\n",
      "Epoch 658/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3223 - acc: 0.8686 - val_loss: 0.3374 - val_acc: 0.8565\n",
      "Epoch 659/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3229 - acc: 0.8679 - val_loss: 0.3356 - val_acc: 0.8565\n",
      "Epoch 660/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3223 - acc: 0.8676 - val_loss: 0.3367 - val_acc: 0.8565\n",
      "Epoch 661/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3225 - acc: 0.8670 - val_loss: 0.3377 - val_acc: 0.8585\n",
      "Epoch 662/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3221 - acc: 0.8683 - val_loss: 0.3354 - val_acc: 0.8575\n",
      "Epoch 663/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3225 - acc: 0.8674 - val_loss: 0.3361 - val_acc: 0.8550\n",
      "Epoch 664/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3223 - acc: 0.8676 - val_loss: 0.3371 - val_acc: 0.8550\n",
      "Epoch 665/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3223 - acc: 0.8683 - val_loss: 0.3357 - val_acc: 0.8550\n",
      "Epoch 666/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3222 - acc: 0.8673 - val_loss: 0.3372 - val_acc: 0.8590\n",
      "Epoch 667/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3224 - acc: 0.8681 - val_loss: 0.3357 - val_acc: 0.8545\n",
      "Epoch 668/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3225 - acc: 0.8690 - val_loss: 0.3363 - val_acc: 0.8545\n",
      "Epoch 669/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3221 - acc: 0.8681 - val_loss: 0.3369 - val_acc: 0.8560\n",
      "Epoch 670/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3224 - acc: 0.8679 - val_loss: 0.3364 - val_acc: 0.8565\n",
      "Epoch 671/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3221 - acc: 0.8683 - val_loss: 0.3388 - val_acc: 0.8585\n",
      "Epoch 672/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3221 - acc: 0.8686 - val_loss: 0.3376 - val_acc: 0.8585\n",
      "Epoch 673/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3223 - acc: 0.8677 - val_loss: 0.3361 - val_acc: 0.8555\n",
      "Epoch 674/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3223 - acc: 0.8681 - val_loss: 0.3357 - val_acc: 0.8545\n",
      "Epoch 675/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3226 - acc: 0.8674 - val_loss: 0.3347 - val_acc: 0.8555\n",
      "Epoch 676/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3222 - acc: 0.8681 - val_loss: 0.3359 - val_acc: 0.8555\n",
      "Epoch 677/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3221 - acc: 0.8691 - val_loss: 0.3364 - val_acc: 0.8575\n",
      "Epoch 678/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3228 - acc: 0.8665 - val_loss: 0.3363 - val_acc: 0.8560\n",
      "Epoch 679/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3221 - acc: 0.8683 - val_loss: 0.3351 - val_acc: 0.8565\n",
      "Epoch 680/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3227 - acc: 0.8674 - val_loss: 0.3375 - val_acc: 0.8590\n",
      "Epoch 681/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3224 - acc: 0.8689 - val_loss: 0.3369 - val_acc: 0.8535\n",
      "Epoch 682/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3221 - acc: 0.8685 - val_loss: 0.3364 - val_acc: 0.8555\n",
      "Epoch 683/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3220 - acc: 0.8679 - val_loss: 0.3349 - val_acc: 0.8565\n",
      "Epoch 684/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3222 - acc: 0.8684 - val_loss: 0.3350 - val_acc: 0.8555\n",
      "Epoch 685/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3223 - acc: 0.8685 - val_loss: 0.3351 - val_acc: 0.8555\n",
      "Epoch 686/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3221 - acc: 0.8684 - val_loss: 0.3360 - val_acc: 0.8545\n",
      "Epoch 687/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3224 - acc: 0.8679 - val_loss: 0.3368 - val_acc: 0.8555\n",
      "Epoch 688/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3223 - acc: 0.8677 - val_loss: 0.3361 - val_acc: 0.8575\n",
      "Epoch 689/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3223 - acc: 0.8685 - val_loss: 0.3368 - val_acc: 0.8565\n",
      "Epoch 690/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3223 - acc: 0.8681 - val_loss: 0.3360 - val_acc: 0.8555\n",
      "Epoch 691/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3222 - acc: 0.8679 - val_loss: 0.3354 - val_acc: 0.8550\n",
      "Epoch 692/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3221 - acc: 0.8680 - val_loss: 0.3366 - val_acc: 0.8560\n",
      "Epoch 693/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3221 - acc: 0.8679 - val_loss: 0.3369 - val_acc: 0.8570\n",
      "Epoch 694/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3220 - acc: 0.8681 - val_loss: 0.3369 - val_acc: 0.8570\n",
      "Epoch 695/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3219 - acc: 0.8685 - val_loss: 0.3360 - val_acc: 0.8560\n",
      "Epoch 696/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3220 - acc: 0.8684 - val_loss: 0.3352 - val_acc: 0.8550\n",
      "Epoch 697/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3221 - acc: 0.8675 - val_loss: 0.3357 - val_acc: 0.8545\n",
      "Epoch 698/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3222 - acc: 0.8684 - val_loss: 0.3361 - val_acc: 0.8565\n",
      "Epoch 699/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3222 - acc: 0.8686 - val_loss: 0.3351 - val_acc: 0.8550\n",
      "Epoch 700/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3221 - acc: 0.8686 - val_loss: 0.3369 - val_acc: 0.8590\n",
      "Epoch 701/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3219 - acc: 0.8671 - val_loss: 0.3347 - val_acc: 0.8540\n",
      "Epoch 702/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3225 - acc: 0.8690 - val_loss: 0.3368 - val_acc: 0.8560\n",
      "Epoch 703/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3220 - acc: 0.8694 - val_loss: 0.3380 - val_acc: 0.8590\n",
      "Epoch 704/1000\n",
      "8000/8000 [==============================] - 0s 62us/sample - loss: 0.3222 - acc: 0.8676 - val_loss: 0.3357 - val_acc: 0.8575\n",
      "Epoch 705/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3223 - acc: 0.8671 - val_loss: 0.3358 - val_acc: 0.8550\n",
      "Epoch 706/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3220 - acc: 0.8685 - val_loss: 0.3346 - val_acc: 0.8560\n",
      "Epoch 707/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3222 - acc: 0.8692 - val_loss: 0.3356 - val_acc: 0.8545\n",
      "Epoch 708/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3218 - acc: 0.8681 - val_loss: 0.3355 - val_acc: 0.8550\n",
      "Epoch 709/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3217 - acc: 0.8679 - val_loss: 0.3375 - val_acc: 0.8575\n",
      "Epoch 710/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3221 - acc: 0.8679 - val_loss: 0.3348 - val_acc: 0.8560\n",
      "Epoch 711/1000\n",
      "8000/8000 [==============================] - 0s 60us/sample - loss: 0.3220 - acc: 0.8692 - val_loss: 0.3368 - val_acc: 0.8580\n",
      "Epoch 712/1000\n",
      "8000/8000 [==============================] - 1s 66us/sample - loss: 0.3221 - acc: 0.8677 - val_loss: 0.3375 - val_acc: 0.8560\n",
      "Epoch 713/1000\n",
      "8000/8000 [==============================] - 1s 65us/sample - loss: 0.3222 - acc: 0.8686 - val_loss: 0.3363 - val_acc: 0.8565\n",
      "Epoch 714/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3220 - acc: 0.8687 - val_loss: 0.3366 - val_acc: 0.8560\n",
      "Epoch 715/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3222 - acc: 0.8692 - val_loss: 0.3368 - val_acc: 0.8555\n",
      "Epoch 716/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3225 - acc: 0.8676 - val_loss: 0.3365 - val_acc: 0.8560\n",
      "Epoch 717/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3216 - acc: 0.8673 - val_loss: 0.3366 - val_acc: 0.8575\n",
      "Epoch 718/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3222 - acc: 0.8680 - val_loss: 0.3374 - val_acc: 0.8575\n",
      "Epoch 719/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3222 - acc: 0.8673 - val_loss: 0.3380 - val_acc: 0.8580\n",
      "Epoch 720/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3221 - acc: 0.8681 - val_loss: 0.3369 - val_acc: 0.8580\n",
      "Epoch 721/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3219 - acc: 0.8685 - val_loss: 0.3366 - val_acc: 0.8570\n",
      "Epoch 722/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3220 - acc: 0.8687 - val_loss: 0.3359 - val_acc: 0.8550\n",
      "Epoch 723/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3221 - acc: 0.8679 - val_loss: 0.3359 - val_acc: 0.8555\n",
      "Epoch 724/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3221 - acc: 0.8680 - val_loss: 0.3344 - val_acc: 0.8550\n",
      "Epoch 725/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3223 - acc: 0.8686 - val_loss: 0.3367 - val_acc: 0.8560\n",
      "Epoch 726/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3220 - acc: 0.8680 - val_loss: 0.3364 - val_acc: 0.8550\n",
      "Epoch 727/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3222 - acc: 0.8692 - val_loss: 0.3381 - val_acc: 0.8565\n",
      "Epoch 728/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3220 - acc: 0.8673 - val_loss: 0.3356 - val_acc: 0.8545\n",
      "Epoch 729/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3218 - acc: 0.8690 - val_loss: 0.3357 - val_acc: 0.8555\n",
      "Epoch 730/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3218 - acc: 0.8695 - val_loss: 0.3352 - val_acc: 0.8550\n",
      "Epoch 731/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3222 - acc: 0.8684 - val_loss: 0.3362 - val_acc: 0.8545\n",
      "Epoch 732/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3218 - acc: 0.8681 - val_loss: 0.3354 - val_acc: 0.8555\n",
      "Epoch 733/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3220 - acc: 0.8670 - val_loss: 0.3375 - val_acc: 0.8580\n",
      "Epoch 734/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3221 - acc: 0.8677 - val_loss: 0.3380 - val_acc: 0.8585\n",
      "Epoch 735/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3221 - acc: 0.8677 - val_loss: 0.3361 - val_acc: 0.8535\n",
      "Epoch 736/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3222 - acc: 0.8677 - val_loss: 0.3353 - val_acc: 0.8540\n",
      "Epoch 737/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3222 - acc: 0.8674 - val_loss: 0.3350 - val_acc: 0.8530\n",
      "Epoch 738/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3221 - acc: 0.8675 - val_loss: 0.3352 - val_acc: 0.8545\n",
      "Epoch 739/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3221 - acc: 0.8681 - val_loss: 0.3360 - val_acc: 0.8555\n",
      "Epoch 740/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3218 - acc: 0.8683 - val_loss: 0.3360 - val_acc: 0.8540\n",
      "Epoch 741/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3219 - acc: 0.8686 - val_loss: 0.3356 - val_acc: 0.8550\n",
      "Epoch 742/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3221 - acc: 0.8685 - val_loss: 0.3347 - val_acc: 0.8540\n",
      "Epoch 743/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3220 - acc: 0.8679 - val_loss: 0.3365 - val_acc: 0.8565\n",
      "Epoch 744/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3219 - acc: 0.8677 - val_loss: 0.3368 - val_acc: 0.8555\n",
      "Epoch 745/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3219 - acc: 0.8687 - val_loss: 0.3370 - val_acc: 0.8570\n",
      "Epoch 746/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3218 - acc: 0.8694 - val_loss: 0.3378 - val_acc: 0.8580\n",
      "Epoch 747/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3222 - acc: 0.8669 - val_loss: 0.3347 - val_acc: 0.8555\n",
      "Epoch 748/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3223 - acc: 0.8689 - val_loss: 0.3365 - val_acc: 0.8580\n",
      "Epoch 749/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3217 - acc: 0.8675 - val_loss: 0.3355 - val_acc: 0.8535\n",
      "Epoch 750/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3221 - acc: 0.8671 - val_loss: 0.3375 - val_acc: 0.8555\n",
      "Epoch 751/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3221 - acc: 0.8680 - val_loss: 0.3364 - val_acc: 0.8550\n",
      "Epoch 752/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3225 - acc: 0.8686 - val_loss: 0.3365 - val_acc: 0.8580\n",
      "Epoch 753/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3217 - acc: 0.8696 - val_loss: 0.3347 - val_acc: 0.8550\n",
      "Epoch 754/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3221 - acc: 0.8686 - val_loss: 0.3347 - val_acc: 0.8545\n",
      "Epoch 755/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3222 - acc: 0.8680 - val_loss: 0.3358 - val_acc: 0.8555\n",
      "Epoch 756/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3220 - acc: 0.8691 - val_loss: 0.3380 - val_acc: 0.8580\n",
      "Epoch 757/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3225 - acc: 0.8689 - val_loss: 0.3379 - val_acc: 0.8590\n",
      "Epoch 758/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3219 - acc: 0.8685 - val_loss: 0.3377 - val_acc: 0.8585\n",
      "Epoch 759/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3221 - acc: 0.8687 - val_loss: 0.3356 - val_acc: 0.8555\n",
      "Epoch 760/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3219 - acc: 0.8673 - val_loss: 0.3364 - val_acc: 0.8545\n",
      "Epoch 761/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3220 - acc: 0.8677 - val_loss: 0.3386 - val_acc: 0.8575\n",
      "Epoch 762/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3219 - acc: 0.8683 - val_loss: 0.3365 - val_acc: 0.8575\n",
      "Epoch 763/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3219 - acc: 0.8690 - val_loss: 0.3363 - val_acc: 0.8550\n",
      "Epoch 764/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3218 - acc: 0.8677 - val_loss: 0.3356 - val_acc: 0.8555\n",
      "Epoch 765/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3221 - acc: 0.8677 - val_loss: 0.3366 - val_acc: 0.8560\n",
      "Epoch 766/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3221 - acc: 0.8689 - val_loss: 0.3373 - val_acc: 0.8570\n",
      "Epoch 767/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3222 - acc: 0.8669 - val_loss: 0.3365 - val_acc: 0.8565\n",
      "Epoch 768/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3219 - acc: 0.8689 - val_loss: 0.3361 - val_acc: 0.8560\n",
      "Epoch 769/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3223 - acc: 0.8692 - val_loss: 0.3364 - val_acc: 0.8550\n",
      "Epoch 770/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3217 - acc: 0.8689 - val_loss: 0.3350 - val_acc: 0.8535\n",
      "Epoch 771/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3219 - acc: 0.8679 - val_loss: 0.3349 - val_acc: 0.8555\n",
      "Epoch 772/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3220 - acc: 0.8685 - val_loss: 0.3366 - val_acc: 0.8570\n",
      "Epoch 773/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3222 - acc: 0.8679 - val_loss: 0.3357 - val_acc: 0.8540\n",
      "Epoch 774/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3218 - acc: 0.8681 - val_loss: 0.3363 - val_acc: 0.8575\n",
      "Epoch 775/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3223 - acc: 0.8683 - val_loss: 0.3366 - val_acc: 0.8565\n",
      "Epoch 776/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3217 - acc: 0.8692 - val_loss: 0.3351 - val_acc: 0.8550\n",
      "Epoch 777/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3224 - acc: 0.8681 - val_loss: 0.3354 - val_acc: 0.8560\n",
      "Epoch 778/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3219 - acc: 0.8689 - val_loss: 0.3372 - val_acc: 0.8545\n",
      "Epoch 779/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3220 - acc: 0.8683 - val_loss: 0.3360 - val_acc: 0.8550\n",
      "Epoch 780/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3216 - acc: 0.8692 - val_loss: 0.3366 - val_acc: 0.8565\n",
      "Epoch 781/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3215 - acc: 0.8677 - val_loss: 0.3352 - val_acc: 0.8560\n",
      "Epoch 782/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3225 - acc: 0.8696 - val_loss: 0.3359 - val_acc: 0.8535\n",
      "Epoch 783/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3218 - acc: 0.8680 - val_loss: 0.3350 - val_acc: 0.8550\n",
      "Epoch 784/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3217 - acc: 0.8687 - val_loss: 0.3393 - val_acc: 0.8600\n",
      "Epoch 785/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3220 - acc: 0.8690 - val_loss: 0.3351 - val_acc: 0.8555\n",
      "Epoch 786/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3218 - acc: 0.8677 - val_loss: 0.3386 - val_acc: 0.8560\n",
      "Epoch 787/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3221 - acc: 0.8684 - val_loss: 0.3373 - val_acc: 0.8555\n",
      "Epoch 788/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3218 - acc: 0.8685 - val_loss: 0.3361 - val_acc: 0.8555\n",
      "Epoch 789/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3221 - acc: 0.8677 - val_loss: 0.3396 - val_acc: 0.8570\n",
      "Epoch 790/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3218 - acc: 0.8673 - val_loss: 0.3350 - val_acc: 0.8545\n",
      "Epoch 791/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3219 - acc: 0.8691 - val_loss: 0.3363 - val_acc: 0.8575\n",
      "Epoch 792/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3218 - acc: 0.8681 - val_loss: 0.3366 - val_acc: 0.8580\n",
      "Epoch 793/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3217 - acc: 0.8689 - val_loss: 0.3349 - val_acc: 0.8550\n",
      "Epoch 794/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3219 - acc: 0.8685 - val_loss: 0.3367 - val_acc: 0.8570\n",
      "Epoch 795/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3217 - acc: 0.8699 - val_loss: 0.3370 - val_acc: 0.8545\n",
      "Epoch 796/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3218 - acc: 0.8687 - val_loss: 0.3351 - val_acc: 0.8570\n",
      "Epoch 797/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3219 - acc: 0.8687 - val_loss: 0.3367 - val_acc: 0.8580\n",
      "Epoch 798/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3217 - acc: 0.8685 - val_loss: 0.3367 - val_acc: 0.8545\n",
      "Epoch 799/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3219 - acc: 0.8684 - val_loss: 0.3362 - val_acc: 0.8550\n",
      "Epoch 800/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3219 - acc: 0.8681 - val_loss: 0.3355 - val_acc: 0.8545\n",
      "Epoch 801/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3220 - acc: 0.8676 - val_loss: 0.3362 - val_acc: 0.8550\n",
      "Epoch 802/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3218 - acc: 0.8691 - val_loss: 0.3359 - val_acc: 0.8535\n",
      "Epoch 803/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3218 - acc: 0.8687 - val_loss: 0.3362 - val_acc: 0.8545\n",
      "Epoch 804/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3224 - acc: 0.8685 - val_loss: 0.3371 - val_acc: 0.8535\n",
      "Epoch 805/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3217 - acc: 0.8683 - val_loss: 0.3359 - val_acc: 0.8560\n",
      "Epoch 806/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3217 - acc: 0.8685 - val_loss: 0.3359 - val_acc: 0.8570\n",
      "Epoch 807/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3217 - acc: 0.8683 - val_loss: 0.3373 - val_acc: 0.8565\n",
      "Epoch 808/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3219 - acc: 0.8694 - val_loss: 0.3359 - val_acc: 0.8565\n",
      "Epoch 809/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3217 - acc: 0.8683 - val_loss: 0.3360 - val_acc: 0.8535\n",
      "Epoch 810/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3221 - acc: 0.8674 - val_loss: 0.3361 - val_acc: 0.8550\n",
      "Epoch 811/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3218 - acc: 0.8674 - val_loss: 0.3359 - val_acc: 0.8545\n",
      "Epoch 812/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3218 - acc: 0.8679 - val_loss: 0.3357 - val_acc: 0.8555\n",
      "Epoch 813/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3217 - acc: 0.8686 - val_loss: 0.3381 - val_acc: 0.8585\n",
      "Epoch 814/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3217 - acc: 0.8690 - val_loss: 0.3363 - val_acc: 0.8550\n",
      "Epoch 815/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3218 - acc: 0.8683 - val_loss: 0.3357 - val_acc: 0.8555\n",
      "Epoch 816/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3219 - acc: 0.8694 - val_loss: 0.3380 - val_acc: 0.8555\n",
      "Epoch 817/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3217 - acc: 0.8692 - val_loss: 0.3359 - val_acc: 0.8550\n",
      "Epoch 818/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3217 - acc: 0.8680 - val_loss: 0.3369 - val_acc: 0.8560\n",
      "Epoch 819/1000\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3217 - acc: 0.8681 - val_loss: 0.3361 - val_acc: 0.8535\n",
      "Epoch 820/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3219 - acc: 0.8680 - val_loss: 0.3358 - val_acc: 0.8560\n",
      "Epoch 821/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3219 - acc: 0.8679 - val_loss: 0.3354 - val_acc: 0.8545\n",
      "Epoch 822/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3220 - acc: 0.8691 - val_loss: 0.3359 - val_acc: 0.8550\n",
      "Epoch 823/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3218 - acc: 0.8684 - val_loss: 0.3371 - val_acc: 0.8580\n",
      "Epoch 824/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3219 - acc: 0.8711 - val_loss: 0.3362 - val_acc: 0.8540\n",
      "Epoch 825/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3219 - acc: 0.8675 - val_loss: 0.3366 - val_acc: 0.8550\n",
      "Epoch 826/1000\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3217 - acc: 0.8679 - val_loss: 0.3374 - val_acc: 0.8550\n",
      "Epoch 827/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3221 - acc: 0.8674 - val_loss: 0.3361 - val_acc: 0.8540\n",
      "Epoch 828/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3219 - acc: 0.8692 - val_loss: 0.3378 - val_acc: 0.8570\n",
      "Epoch 829/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3215 - acc: 0.8694 - val_loss: 0.3358 - val_acc: 0.8560\n",
      "Epoch 830/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3219 - acc: 0.8687 - val_loss: 0.3358 - val_acc: 0.8535\n",
      "Epoch 831/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3218 - acc: 0.8684 - val_loss: 0.3371 - val_acc: 0.8560\n",
      "Epoch 832/1000\n",
      "8000/8000 [==============================] - 0s 54us/sample - loss: 0.3218 - acc: 0.8689 - val_loss: 0.3353 - val_acc: 0.8580\n",
      "Epoch 833/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3218 - acc: 0.8686 - val_loss: 0.3348 - val_acc: 0.8550\n",
      "Epoch 834/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3216 - acc: 0.8681 - val_loss: 0.3379 - val_acc: 0.8575\n",
      "Epoch 835/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3222 - acc: 0.8665 - val_loss: 0.3377 - val_acc: 0.8550\n",
      "Epoch 836/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3216 - acc: 0.8690 - val_loss: 0.3387 - val_acc: 0.8570\n",
      "Epoch 837/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3218 - acc: 0.8679 - val_loss: 0.3366 - val_acc: 0.8555\n",
      "Epoch 838/1000\n",
      "8000/8000 [==============================] - 1s 63us/sample - loss: 0.3217 - acc: 0.8685 - val_loss: 0.3353 - val_acc: 0.8550\n",
      "Epoch 839/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3217 - acc: 0.8685 - val_loss: 0.3361 - val_acc: 0.8540\n",
      "Epoch 840/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3221 - acc: 0.8686 - val_loss: 0.3351 - val_acc: 0.8550\n",
      "Epoch 841/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3219 - acc: 0.8696 - val_loss: 0.3388 - val_acc: 0.8590\n",
      "Epoch 842/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3217 - acc: 0.8683 - val_loss: 0.3354 - val_acc: 0.8555\n",
      "Epoch 843/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3216 - acc: 0.8683 - val_loss: 0.3369 - val_acc: 0.8550\n",
      "Epoch 844/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3217 - acc: 0.8679 - val_loss: 0.3353 - val_acc: 0.8565\n",
      "Epoch 845/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3215 - acc: 0.8685 - val_loss: 0.3376 - val_acc: 0.8560\n",
      "Epoch 846/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3217 - acc: 0.8681 - val_loss: 0.3348 - val_acc: 0.8570\n",
      "Epoch 847/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3215 - acc: 0.8683 - val_loss: 0.3388 - val_acc: 0.8575\n",
      "Epoch 848/1000\n",
      "8000/8000 [==============================] - 1s 64us/sample - loss: 0.3216 - acc: 0.8684 - val_loss: 0.3362 - val_acc: 0.8555\n",
      "Epoch 849/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3217 - acc: 0.8696 - val_loss: 0.3357 - val_acc: 0.8545\n",
      "Epoch 850/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3215 - acc: 0.8687 - val_loss: 0.3387 - val_acc: 0.8555\n",
      "Epoch 851/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3217 - acc: 0.8683 - val_loss: 0.3389 - val_acc: 0.8565\n",
      "Epoch 852/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3219 - acc: 0.8683 - val_loss: 0.3362 - val_acc: 0.8550\n",
      "Epoch 853/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: 0.3217 - acc: 0.8684 - val_loss: 0.3364 - val_acc: 0.8550\n",
      "Epoch 854/1000\n",
      "8000/8000 [==============================] - 0s 55us/sample - loss: 0.3215 - acc: 0.8685 - val_loss: 0.3365 - val_acc: 0.8555\n",
      "Epoch 855/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3216 - acc: 0.8675 - val_loss: 0.3362 - val_acc: 0.8540\n",
      "Epoch 856/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3215 - acc: 0.8680 - val_loss: 0.3356 - val_acc: 0.8545\n",
      "Epoch 857/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3223 - acc: 0.8676 - val_loss: 0.3355 - val_acc: 0.8565\n",
      "Epoch 858/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3217 - acc: 0.8681 - val_loss: 0.3376 - val_acc: 0.8545\n",
      "Epoch 859/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3216 - acc: 0.8684 - val_loss: 0.3361 - val_acc: 0.8540\n",
      "Epoch 860/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3218 - acc: 0.8681 - val_loss: 0.3348 - val_acc: 0.8540\n",
      "Epoch 861/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3220 - acc: 0.8680 - val_loss: 0.3355 - val_acc: 0.8540\n",
      "Epoch 862/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3213 - acc: 0.8684 - val_loss: 0.3350 - val_acc: 0.8555\n",
      "Epoch 863/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3220 - acc: 0.8691 - val_loss: 0.3365 - val_acc: 0.8560\n",
      "Epoch 864/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3220 - acc: 0.8679 - val_loss: 0.3359 - val_acc: 0.8550\n",
      "Epoch 865/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3217 - acc: 0.8690 - val_loss: 0.3356 - val_acc: 0.8540\n",
      "Epoch 866/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3219 - acc: 0.8689 - val_loss: 0.3365 - val_acc: 0.8540\n",
      "Epoch 867/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3217 - acc: 0.8683 - val_loss: 0.3361 - val_acc: 0.8545\n",
      "Epoch 868/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 59us/sample - loss: 0.3216 - acc: 0.8685 - val_loss: 0.3373 - val_acc: 0.8565\n",
      "Epoch 869/1000\n",
      "8000/8000 [==============================] - 0s 57us/sample - loss: 0.3217 - acc: 0.8694 - val_loss: 0.3360 - val_acc: 0.8545\n",
      "Epoch 870/1000\n",
      "8000/8000 [==============================] - 0s 58us/sample - loss: 0.3221 - acc: 0.8679 - val_loss: 0.3376 - val_acc: 0.8545\n",
      "Epoch 871/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3218 - acc: 0.8684 - val_loss: 0.3382 - val_acc: 0.8605\n",
      "Epoch 872/1000\n",
      "8000/8000 [==============================] - 0s 61us/sample - loss: 0.3219 - acc: 0.8680 - val_loss: 0.3380 - val_acc: 0.8545\n",
      "Epoch 873/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3216 - acc: 0.8690 - val_loss: 0.3370 - val_acc: 0.8570\n",
      "Epoch 874/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3218 - acc: 0.8685 - val_loss: 0.3352 - val_acc: 0.8540\n",
      "Epoch 875/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3214 - acc: 0.8690 - val_loss: 0.3360 - val_acc: 0.8545\n",
      "Epoch 876/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3217 - acc: 0.8679 - val_loss: 0.3367 - val_acc: 0.8560\n",
      "Epoch 877/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3218 - acc: 0.8695 - val_loss: 0.3358 - val_acc: 0.8550\n",
      "Epoch 878/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3216 - acc: 0.8690 - val_loss: 0.3380 - val_acc: 0.8560\n",
      "Epoch 879/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3243 - acc: 0.867 - 0s 50us/sample - loss: 0.3223 - acc: 0.8684 - val_loss: 0.3363 - val_acc: 0.8545\n",
      "Epoch 880/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3220 - acc: 0.8679 - val_loss: 0.3365 - val_acc: 0.8560\n",
      "Epoch 881/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3217 - acc: 0.8677 - val_loss: 0.3378 - val_acc: 0.8565\n",
      "Epoch 882/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3214 - acc: 0.8696 - val_loss: 0.3367 - val_acc: 0.8545\n",
      "Epoch 883/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3215 - acc: 0.8680 - val_loss: 0.3364 - val_acc: 0.8540\n",
      "Epoch 884/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3216 - acc: 0.8669 - val_loss: 0.3367 - val_acc: 0.8565\n",
      "Epoch 885/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3217 - acc: 0.8687 - val_loss: 0.3354 - val_acc: 0.8560\n",
      "Epoch 886/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3219 - acc: 0.8675 - val_loss: 0.3353 - val_acc: 0.8540\n",
      "Epoch 887/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3218 - acc: 0.8689 - val_loss: 0.3355 - val_acc: 0.8540\n",
      "Epoch 888/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3214 - acc: 0.8695 - val_loss: 0.3378 - val_acc: 0.8575\n",
      "Epoch 889/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3214 - acc: 0.8676 - val_loss: 0.3356 - val_acc: 0.8535\n",
      "Epoch 890/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3215 - acc: 0.8705 - val_loss: 0.3356 - val_acc: 0.8540\n",
      "Epoch 891/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3219 - acc: 0.8681 - val_loss: 0.3354 - val_acc: 0.8535\n",
      "Epoch 892/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3215 - acc: 0.8684 - val_loss: 0.3385 - val_acc: 0.8565\n",
      "Epoch 893/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3215 - acc: 0.8680 - val_loss: 0.3381 - val_acc: 0.8555\n",
      "Epoch 894/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3216 - acc: 0.8689 - val_loss: 0.3368 - val_acc: 0.8545\n",
      "Epoch 895/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3217 - acc: 0.8686 - val_loss: 0.3351 - val_acc: 0.8545\n",
      "Epoch 896/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3155 - acc: 0.872 - 0s 51us/sample - loss: 0.3215 - acc: 0.8692 - val_loss: 0.3380 - val_acc: 0.8560\n",
      "Epoch 897/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3214 - acc: 0.8685 - val_loss: 0.3360 - val_acc: 0.8545\n",
      "Epoch 898/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3215 - acc: 0.8691 - val_loss: 0.3372 - val_acc: 0.8565\n",
      "Epoch 899/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3216 - acc: 0.8689 - val_loss: 0.3363 - val_acc: 0.8540\n",
      "Epoch 900/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3214 - acc: 0.8686 - val_loss: 0.3360 - val_acc: 0.8550\n",
      "Epoch 901/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3214 - acc: 0.8680 - val_loss: 0.3380 - val_acc: 0.8560\n",
      "Epoch 902/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3217 - acc: 0.8671 - val_loss: 0.3366 - val_acc: 0.8535\n",
      "Epoch 903/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3215 - acc: 0.8676 - val_loss: 0.3353 - val_acc: 0.8550\n",
      "Epoch 904/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3205 - acc: 0.868 - 0s 38us/sample - loss: 0.3216 - acc: 0.8681 - val_loss: 0.3353 - val_acc: 0.8540\n",
      "Epoch 905/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3218 - acc: 0.8690 - val_loss: 0.3360 - val_acc: 0.8540\n",
      "Epoch 906/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3218 - acc: 0.8691 - val_loss: 0.3367 - val_acc: 0.8535\n",
      "Epoch 907/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3219 - acc: 0.8681 - val_loss: 0.3386 - val_acc: 0.8580\n",
      "Epoch 908/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3216 - acc: 0.8687 - val_loss: 0.3354 - val_acc: 0.8550\n",
      "Epoch 909/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3216 - acc: 0.8695 - val_loss: 0.3390 - val_acc: 0.8550\n",
      "Epoch 910/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3217 - acc: 0.8681 - val_loss: 0.3369 - val_acc: 0.8570\n",
      "Epoch 911/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3215 - acc: 0.8690 - val_loss: 0.3380 - val_acc: 0.8565\n",
      "Epoch 912/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3213 - acc: 0.8683 - val_loss: 0.3373 - val_acc: 0.8555\n",
      "Epoch 913/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3216 - acc: 0.8700 - val_loss: 0.3358 - val_acc: 0.8545\n",
      "Epoch 914/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3218 - acc: 0.8687 - val_loss: 0.3370 - val_acc: 0.8555\n",
      "Epoch 915/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3214 - acc: 0.8680 - val_loss: 0.3370 - val_acc: 0.8560\n",
      "Epoch 916/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3215 - acc: 0.8681 - val_loss: 0.3368 - val_acc: 0.8565\n",
      "Epoch 917/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3213 - acc: 0.8695 - val_loss: 0.3366 - val_acc: 0.8565\n",
      "Epoch 918/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3221 - acc: 0.8676 - val_loss: 0.3374 - val_acc: 0.8570\n",
      "Epoch 919/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3215 - acc: 0.8686 - val_loss: 0.3354 - val_acc: 0.8535\n",
      "Epoch 920/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3214 - acc: 0.8691 - val_loss: 0.3374 - val_acc: 0.8530\n",
      "Epoch 921/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3220 - acc: 0.8694 - val_loss: 0.3359 - val_acc: 0.8515\n",
      "Epoch 922/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3219 - acc: 0.8675 - val_loss: 0.3362 - val_acc: 0.8565\n",
      "Epoch 923/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3217 - acc: 0.8691 - val_loss: 0.3378 - val_acc: 0.8565\n",
      "Epoch 924/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3213 - acc: 0.8671 - val_loss: 0.3371 - val_acc: 0.8545\n",
      "Epoch 925/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3216 - acc: 0.8675 - val_loss: 0.3364 - val_acc: 0.8535\n",
      "Epoch 926/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3216 - acc: 0.8676 - val_loss: 0.3352 - val_acc: 0.8540\n",
      "Epoch 927/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3218 - acc: 0.8685 - val_loss: 0.3357 - val_acc: 0.8555\n",
      "Epoch 928/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3215 - acc: 0.8686 - val_loss: 0.3383 - val_acc: 0.8580\n",
      "Epoch 929/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3214 - acc: 0.8662 - val_loss: 0.3356 - val_acc: 0.8550\n",
      "Epoch 930/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3216 - acc: 0.8694 - val_loss: 0.3351 - val_acc: 0.8540\n",
      "Epoch 931/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3219 - acc: 0.8685 - val_loss: 0.3354 - val_acc: 0.8535\n",
      "Epoch 932/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3217 - acc: 0.8687 - val_loss: 0.3362 - val_acc: 0.8540\n",
      "Epoch 933/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3215 - acc: 0.8683 - val_loss: 0.3365 - val_acc: 0.8580\n",
      "Epoch 934/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3216 - acc: 0.8692 - val_loss: 0.3363 - val_acc: 0.8565\n",
      "Epoch 935/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3213 - acc: 0.8699 - val_loss: 0.3375 - val_acc: 0.8575\n",
      "Epoch 936/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3213 - acc: 0.8684 - val_loss: 0.3355 - val_acc: 0.8550\n",
      "Epoch 937/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3213 - acc: 0.8679 - val_loss: 0.3374 - val_acc: 0.8565\n",
      "Epoch 938/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3214 - acc: 0.8676 - val_loss: 0.3360 - val_acc: 0.8570\n",
      "Epoch 939/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3215 - acc: 0.8694 - val_loss: 0.3393 - val_acc: 0.8610\n",
      "Epoch 940/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3214 - acc: 0.8695 - val_loss: 0.3364 - val_acc: 0.8540\n",
      "Epoch 941/1000\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3215 - acc: 0.8677 - val_loss: 0.3358 - val_acc: 0.8555\n",
      "Epoch 942/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3215 - acc: 0.8699 - val_loss: 0.3387 - val_acc: 0.8575\n",
      "Epoch 943/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3219 - acc: 0.8681 - val_loss: 0.3364 - val_acc: 0.8540\n",
      "Epoch 944/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3215 - acc: 0.8679 - val_loss: 0.3373 - val_acc: 0.8545\n",
      "Epoch 945/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3213 - acc: 0.8692 - val_loss: 0.3373 - val_acc: 0.8580\n",
      "Epoch 946/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3215 - acc: 0.8681 - val_loss: 0.3355 - val_acc: 0.8560\n",
      "Epoch 947/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3214 - acc: 0.8699 - val_loss: 0.3358 - val_acc: 0.8535\n",
      "Epoch 948/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3216 - acc: 0.8687 - val_loss: 0.3369 - val_acc: 0.8580\n",
      "Epoch 949/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3212 - acc: 0.8685 - val_loss: 0.3348 - val_acc: 0.8585\n",
      "Epoch 950/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3214 - acc: 0.8689 - val_loss: 0.3361 - val_acc: 0.8540\n",
      "Epoch 951/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3217 - acc: 0.8676 - val_loss: 0.3365 - val_acc: 0.8570\n",
      "Epoch 952/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3212 - acc: 0.8677 - val_loss: 0.3371 - val_acc: 0.8570\n",
      "Epoch 953/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3213 - acc: 0.8679 - val_loss: 0.3362 - val_acc: 0.8550\n",
      "Epoch 954/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3212 - acc: 0.8679 - val_loss: 0.3355 - val_acc: 0.8540\n",
      "Epoch 955/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3215 - acc: 0.8692 - val_loss: 0.3370 - val_acc: 0.8550\n",
      "Epoch 956/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3213 - acc: 0.8684 - val_loss: 0.3378 - val_acc: 0.8565\n",
      "Epoch 957/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3215 - acc: 0.8680 - val_loss: 0.3369 - val_acc: 0.8555\n",
      "Epoch 958/1000\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3212 - acc: 0.8684 - val_loss: 0.3360 - val_acc: 0.8545\n",
      "Epoch 959/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3216 - acc: 0.8692 - val_loss: 0.3371 - val_acc: 0.8560\n",
      "Epoch 960/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3214 - acc: 0.8683 - val_loss: 0.3357 - val_acc: 0.8545\n",
      "Epoch 961/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3212 - acc: 0.8706 - val_loss: 0.3380 - val_acc: 0.8555\n",
      "Epoch 962/1000\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3215 - acc: 0.8687 - val_loss: 0.3368 - val_acc: 0.8560\n",
      "Epoch 963/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3215 - acc: 0.8699 - val_loss: 0.3355 - val_acc: 0.8535\n",
      "Epoch 964/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3214 - acc: 0.8690 - val_loss: 0.3360 - val_acc: 0.8565\n",
      "Epoch 965/1000\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3214 - acc: 0.8683 - val_loss: 0.3364 - val_acc: 0.8570\n",
      "Epoch 966/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3215 - acc: 0.8684 - val_loss: 0.3386 - val_acc: 0.8565\n",
      "Epoch 967/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3214 - acc: 0.8690 - val_loss: 0.3375 - val_acc: 0.8550\n",
      "Epoch 968/1000\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3213 - acc: 0.8687 - val_loss: 0.3358 - val_acc: 0.8535\n",
      "Epoch 969/1000\n",
      "8000/8000 [==============================] - 0s 47us/sample - loss: 0.3214 - acc: 0.8691 - val_loss: 0.3354 - val_acc: 0.8550\n",
      "Epoch 970/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3213 - acc: 0.8675 - val_loss: 0.3358 - val_acc: 0.8545\n",
      "Epoch 971/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3213 - acc: 0.8676 - val_loss: 0.3368 - val_acc: 0.8555\n",
      "Epoch 972/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3213 - acc: 0.8695 - val_loss: 0.3362 - val_acc: 0.8540\n",
      "Epoch 973/1000\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3216 - acc: 0.8676 - val_loss: 0.3374 - val_acc: 0.8570\n",
      "Epoch 974/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3216 - acc: 0.8675 - val_loss: 0.3377 - val_acc: 0.8540\n",
      "Epoch 975/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3214 - acc: 0.8689 - val_loss: 0.3352 - val_acc: 0.8545\n",
      "Epoch 976/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3213 - acc: 0.8694 - val_loss: 0.3351 - val_acc: 0.8540\n",
      "Epoch 977/1000\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3213 - acc: 0.8691 - val_loss: 0.3363 - val_acc: 0.8540\n",
      "Epoch 978/1000\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3212 - acc: 0.8687 - val_loss: 0.3363 - val_acc: 0.8565\n",
      "Epoch 979/1000\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3213 - acc: 0.8694 - val_loss: 0.3381 - val_acc: 0.8570\n",
      "Epoch 980/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3206 - acc: 0.869 - 0s 44us/sample - loss: 0.3213 - acc: 0.8685 - val_loss: 0.3360 - val_acc: 0.8540\n",
      "Epoch 981/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3213 - acc: 0.8690 - val_loss: 0.3381 - val_acc: 0.8560\n",
      "Epoch 982/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3213 - acc: 0.8681 - val_loss: 0.3363 - val_acc: 0.8550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 983/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3213 - acc: 0.8698 - val_loss: 0.3379 - val_acc: 0.8550\n",
      "Epoch 984/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3215 - acc: 0.8683 - val_loss: 0.3363 - val_acc: 0.8530\n",
      "Epoch 985/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3214 - acc: 0.8681 - val_loss: 0.3361 - val_acc: 0.8565\n",
      "Epoch 986/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3214 - acc: 0.8681 - val_loss: 0.3391 - val_acc: 0.8545\n",
      "Epoch 987/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3211 - acc: 0.8687 - val_loss: 0.3351 - val_acc: 0.8560\n",
      "Epoch 988/1000\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3212 - acc: 0.8683 - val_loss: 0.3364 - val_acc: 0.8545\n",
      "Epoch 989/1000\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3215 - acc: 0.8680 - val_loss: 0.3361 - val_acc: 0.8570\n",
      "Epoch 990/1000\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3216 - acc: 0.8695 - val_loss: 0.3382 - val_acc: 0.8565\n",
      "Epoch 991/1000\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3212 - acc: 0.8694 - val_loss: 0.3368 - val_acc: 0.8545\n",
      "Epoch 992/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3211 - acc: 0.8692 - val_loss: 0.3360 - val_acc: 0.8560\n",
      "Epoch 993/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3211 - acc: 0.8684 - val_loss: 0.3351 - val_acc: 0.8560\n",
      "Epoch 994/1000\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3211 - acc: 0.8696 - val_loss: 0.3378 - val_acc: 0.8570\n",
      "Epoch 995/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3213 - acc: 0.8681 - val_loss: 0.3378 - val_acc: 0.8555\n",
      "Epoch 996/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3212 - acc: 0.8689 - val_loss: 0.3359 - val_acc: 0.8560\n",
      "Epoch 997/1000\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3211 - acc: 0.8692 - val_loss: 0.3363 - val_acc: 0.8560\n",
      "Epoch 998/1000\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3212 - acc: 0.8691 - val_loss: 0.3368 - val_acc: 0.8570\n",
      "Epoch 999/1000\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3205 - acc: 0.869 - 0s 38us/sample - loss: 0.3212 - acc: 0.8684 - val_loss: 0.3364 - val_acc: 0.8560\n",
      "Epoch 1000/1000\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3214 - acc: 0.8679 - val_loss: 0.3360 - val_acc: 0.8555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c14dcfe4e0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=25, mode='min')\n",
    "\n",
    "# Creating the model\n",
    "model_4 = Sequential()\n",
    "\n",
    "# Input/hidder layer\n",
    "model_4.add(Dense(units=X_train.shape[1], activation='relu'))\n",
    "#model_3.add(Dropout(rate=0.2))\n",
    "\n",
    "# Hidder layer\n",
    "model_4.add(Dense(units=X_train.shape[1] // 2, activation='relu'))\n",
    "#model_3.add(Dropout(rate=0.5))\n",
    "\n",
    "# Output layer\n",
    "model_4.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling\n",
    "model_4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the model\n",
    "model_4.fit(X_train, y_train, batch_size=128, epochs=1000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising (Using neither Dropout nor EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.321675</td>\n",
       "      <td>0.867625</td>\n",
       "      <td>0.336479</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>0.321240</td>\n",
       "      <td>0.867750</td>\n",
       "      <td>0.337142</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0.321334</td>\n",
       "      <td>0.867875</td>\n",
       "      <td>0.336180</td>\n",
       "      <td>0.8550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>0.321238</td>\n",
       "      <td>0.867875</td>\n",
       "      <td>0.335451</td>\n",
       "      <td>0.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>0.321549</td>\n",
       "      <td>0.869250</td>\n",
       "      <td>0.336956</td>\n",
       "      <td>0.8550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0.321271</td>\n",
       "      <td>0.868375</td>\n",
       "      <td>0.337818</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.321502</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.336860</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0.321248</td>\n",
       "      <td>0.868375</td>\n",
       "      <td>0.335995</td>\n",
       "      <td>0.8545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.321567</td>\n",
       "      <td>0.869250</td>\n",
       "      <td>0.337102</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>0.321402</td>\n",
       "      <td>0.868250</td>\n",
       "      <td>0.335674</td>\n",
       "      <td>0.8545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>0.321250</td>\n",
       "      <td>0.870625</td>\n",
       "      <td>0.338003</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>0.321538</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.336845</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>0.321487</td>\n",
       "      <td>0.869875</td>\n",
       "      <td>0.335486</td>\n",
       "      <td>0.8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0.321364</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.336008</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>0.321423</td>\n",
       "      <td>0.868250</td>\n",
       "      <td>0.336420</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>0.321464</td>\n",
       "      <td>0.868375</td>\n",
       "      <td>0.338604</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>0.321368</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>0.8550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>0.321322</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.335800</td>\n",
       "      <td>0.8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>0.321420</td>\n",
       "      <td>0.869125</td>\n",
       "      <td>0.335372</td>\n",
       "      <td>0.8550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>0.321347</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.335816</td>\n",
       "      <td>0.8545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.321307</td>\n",
       "      <td>0.867625</td>\n",
       "      <td>0.336781</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.321292</td>\n",
       "      <td>0.869500</td>\n",
       "      <td>0.336163</td>\n",
       "      <td>0.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.321564</td>\n",
       "      <td>0.867625</td>\n",
       "      <td>0.337429</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.321577</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.337674</td>\n",
       "      <td>0.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.321440</td>\n",
       "      <td>0.868875</td>\n",
       "      <td>0.335227</td>\n",
       "      <td>0.8545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.321346</td>\n",
       "      <td>0.869375</td>\n",
       "      <td>0.335116</td>\n",
       "      <td>0.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.321267</td>\n",
       "      <td>0.869125</td>\n",
       "      <td>0.336292</td>\n",
       "      <td>0.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.321185</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.336344</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.321315</td>\n",
       "      <td>0.869375</td>\n",
       "      <td>0.338066</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.321338</td>\n",
       "      <td>0.868500</td>\n",
       "      <td>0.336026</td>\n",
       "      <td>0.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.321306</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.321321</td>\n",
       "      <td>0.868125</td>\n",
       "      <td>0.336273</td>\n",
       "      <td>0.8550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.321303</td>\n",
       "      <td>0.869750</td>\n",
       "      <td>0.337897</td>\n",
       "      <td>0.8550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.321549</td>\n",
       "      <td>0.868250</td>\n",
       "      <td>0.336254</td>\n",
       "      <td>0.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.321414</td>\n",
       "      <td>0.868125</td>\n",
       "      <td>0.336083</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.321353</td>\n",
       "      <td>0.868125</td>\n",
       "      <td>0.339128</td>\n",
       "      <td>0.8545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.321061</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.335149</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.321236</td>\n",
       "      <td>0.868250</td>\n",
       "      <td>0.336378</td>\n",
       "      <td>0.8545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.321468</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.336053</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.321627</td>\n",
       "      <td>0.869500</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.321229</td>\n",
       "      <td>0.869375</td>\n",
       "      <td>0.336847</td>\n",
       "      <td>0.8545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.321063</td>\n",
       "      <td>0.869250</td>\n",
       "      <td>0.335962</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.321053</td>\n",
       "      <td>0.868375</td>\n",
       "      <td>0.335098</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.321132</td>\n",
       "      <td>0.869625</td>\n",
       "      <td>0.337751</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.321273</td>\n",
       "      <td>0.868125</td>\n",
       "      <td>0.337809</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.321216</td>\n",
       "      <td>0.868875</td>\n",
       "      <td>0.335946</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.321069</td>\n",
       "      <td>0.869250</td>\n",
       "      <td>0.336274</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.321204</td>\n",
       "      <td>0.869125</td>\n",
       "      <td>0.336805</td>\n",
       "      <td>0.8570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.321179</td>\n",
       "      <td>0.868375</td>\n",
       "      <td>0.336392</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.321441</td>\n",
       "      <td>0.867875</td>\n",
       "      <td>0.336032</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       acc  val_loss  val_acc\n",
       "950  0.321675  0.867625  0.336479   0.8570\n",
       "951  0.321240  0.867750  0.337142   0.8570\n",
       "952  0.321334  0.867875  0.336180   0.8550\n",
       "953  0.321238  0.867875  0.335451   0.8540\n",
       "954  0.321549  0.869250  0.336956   0.8550\n",
       "955  0.321271  0.868375  0.337818   0.8565\n",
       "956  0.321502  0.868000  0.336860   0.8555\n",
       "957  0.321248  0.868375  0.335995   0.8545\n",
       "958  0.321567  0.869250  0.337102   0.8560\n",
       "959  0.321402  0.868250  0.335674   0.8545\n",
       "960  0.321250  0.870625  0.338003   0.8555\n",
       "961  0.321538  0.868750  0.336845   0.8560\n",
       "962  0.321487  0.869875  0.335486   0.8535\n",
       "963  0.321364  0.869000  0.336008   0.8565\n",
       "964  0.321423  0.868250  0.336420   0.8570\n",
       "965  0.321464  0.868375  0.338604   0.8565\n",
       "966  0.321368  0.869000  0.337544   0.8550\n",
       "967  0.321322  0.868750  0.335800   0.8535\n",
       "968  0.321420  0.869125  0.335372   0.8550\n",
       "969  0.321347  0.867500  0.335816   0.8545\n",
       "970  0.321307  0.867625  0.336781   0.8555\n",
       "971  0.321292  0.869500  0.336163   0.8540\n",
       "972  0.321564  0.867625  0.337429   0.8570\n",
       "973  0.321577  0.867500  0.337674   0.8540\n",
       "974  0.321440  0.868875  0.335227   0.8545\n",
       "975  0.321346  0.869375  0.335116   0.8540\n",
       "976  0.321267  0.869125  0.336292   0.8540\n",
       "977  0.321185  0.868750  0.336344   0.8565\n",
       "978  0.321315  0.869375  0.338066   0.8570\n",
       "979  0.321338  0.868500  0.336026   0.8540\n",
       "980  0.321306  0.869000  0.338130   0.8560\n",
       "981  0.321321  0.868125  0.336273   0.8550\n",
       "982  0.321303  0.869750  0.337897   0.8550\n",
       "983  0.321549  0.868250  0.336254   0.8530\n",
       "984  0.321414  0.868125  0.336083   0.8565\n",
       "985  0.321353  0.868125  0.339128   0.8545\n",
       "986  0.321061  0.868750  0.335149   0.8560\n",
       "987  0.321236  0.868250  0.336378   0.8545\n",
       "988  0.321468  0.868000  0.336053   0.8570\n",
       "989  0.321627  0.869500  0.338235   0.8565\n",
       "990  0.321229  0.869375  0.336847   0.8545\n",
       "991  0.321063  0.869250  0.335962   0.8560\n",
       "992  0.321053  0.868375  0.335098   0.8560\n",
       "993  0.321132  0.869625  0.337751   0.8570\n",
       "994  0.321273  0.868125  0.337809   0.8555\n",
       "995  0.321216  0.868875  0.335946   0.8560\n",
       "996  0.321069  0.869250  0.336274   0.8560\n",
       "997  0.321204  0.869125  0.336805   0.8570\n",
       "998  0.321179  0.868375  0.336392   0.8560\n",
       "999  0.321441  0.867875  0.336032   0.8555"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_4 = pd.DataFrame(model_4.history.history)\n",
    "losses_4[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c14ddd2940>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2sAAAExCAYAAADiPzooAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XeAHlW5+PHvtLdvzZZsTd/0SkuhN4EAIh0U9P7Ui3rtYsGGBZV79VoRbBeuigqCXqT3EpJACIH03rYlmy3Z8u7bpp3fH7NssumUJQs8n38g+74z58zMmZnznPPMvJpSSiGEEEIIIYQQYkjRj3YFhBBCCCGEEELsT4I1IYQQQgghhBiCJFgTQgghhBBCiCFIgjUhhBBCCCGEGIIkWBNCCCGEEEKIIUiCNSGEEEIIIYQYgiRYE0IIIYQQQoghSII1IYQQQgghhBiCJFgTQgghhBBCiCHIfLsL9H0fz1Nvd7GHZRjakKyXeHeQ9iUGm7QxMZikfYnBJO1LDLah2MYsyzii773twZrnKbq60m93sYdVWBgbkvUS7w7SvsRgkzYmBpO0LzGYpH2JwTYU21hpad4RfU/SIIUQQgghhBBiCJJgTQghhBBCCCGGIAnWhBBCCCGEEGIIkmBNCCGEEEIIIYYgCdaEEEIIIYQQYgiSYE0IIYQQQgghhiAJ1oQQQgghhBBiCJJgTQghhBBCCCGGIAnWhBBCCCGEEGIIkmBNCCGEEEK8oxldW9F7Go92Nd4aXu5o1+CtpxRarvto1+IdyTzaFRBCDFHKB03Gcw7qQPvHzaL5DiqUF/zbc0A3QdMOvh7fQ7N7gmX0vS7JXg4tl0TFSg68nJMBM7Jn3W4WLdeN0bUVr2AkKlIEnkNkwz3Ytadi7N6EMqO4lcf33zRVOB80Hb13J36kEMzoAYvSUq3odhKvaEz/toc3/AOn4nj8ghHB+jLtqGhJUB/fA91AT7Xgh/LBimF0bkZZcZRmYPQ0oKwYiRd+QO/cb+INmzigPL1rG5gRlBnB3L0RfBenak7//n5tW/z86j11TLcRqn8GP78Gt2RysG1KYe5cijdsAqH6p1G6iVc0Fq94PKDQk01Yu5aTG30OmpPCankFe8TpoGlomQ5CTYtRRijY5FACp2pu/2dGshk0DaUZeMMmEtr+JFbLUpzK2dhVc8GMYHSsJ7rmTpzyGejZbvxQHqEdL9A779ugFOEtD5KruxhlRjF2b0BzM7jDj+nfB3q2E7d0CmbbKvxIMX7hKPBdNDuJsuKYrSvR3DR+XjUoBcrDjw5DT7fjFdcdst0Z7WsJb34Qe/T7cEunYXSswxs2ATQdLdWKihSAZuxpk+nd4Globi7Yt/tSCqN7G0ozQLfwExVBOZ2bQblonoNXMAKzdSVu2TTMjvXBcbLimK3LMTvWY1fPw8+v7V8fqOCYew6al8VqfhGn8njwXdCt/npYjc/jx0oIb34Q0LBHn4NbXAdGKDhPrCh4NugWZvsa9NQu7NpT0JNNaL6LVzgagNC2J1CRQpzSaejpVoyeetzyWejJJvA9vMLRaMpFT+3CKxgZ7Bsvh9G1FWVGUdESjK6t4DtghAhvfpDcyLPwiscR3ngfXuEYnOp5hDf8Az9WApqBuXsD7rCJONXz+s9jc/dGNDeDUz4Ts30temoXmpdFy3ZhdG4mO+UavKJxA4+vUmi5rqB8zcAtnYq18yVC9U+RG30u6CZu2XT0rm1EV92BHyvDLZ+J2bEOt3AMmGGcytno3fVYrSvIjTwLq3U5fqKCUP3TaE6G3KizwbDw8kdgdG4kvO1J3OJxaJ6N3tOA5mbACOP2XSec4cehp9vwho0ntO1xQKE5GcLbHsOPl2FXn4xXODrYlx2biK5+BK9gFF7BCDQ7SajhWdySydgjzwLAbF2B2bEOvXcnmp0kO+lqvIJaNLuXyNq/kXjxZgDaPrkdq2kh4W2P4xWOxi0ai+bZOOUz0e0kek8jfrwcPbub0LbH8WPlZCdeHlyLvRzoBpF1fw/KmHBZfzvyCkeBFQOl0JPNqFAczcsRqn8WLzEco6cBr3AMWrYTs2sL2QmXodm9mG0rQQvOI6tlKe6wSdjV87BaV2G2Lid1/PWYbatAN4msvwejeztm+2p6zvkdXnw4VttK9N6dqHAhWrYTP68au2o2KlYKbobwpvvRcz24wyYQqn8Gr2AEoIhs/D+cyjmkp3+M6Mrbcctngm9jta7CKZuKnkuSnXApaAZ693Y0FKGtj+DHylGRIszWFVgtL5Oe+UncsmnElv4czbfRU604w4/FLZuG1fg81q5XsGtPxSscg1c0JjifPIfo6j/iFtfhDptEeMtDRNbfg9W6HC9/BHb1iWQnX43e04huJ0H55MZeQOyVW8iNmQ+aTnjjfahwPko3QSn8WClmx3o03yF1zGfRc93o6VaUGSWy5i9ghFDhPPTeFuzqEzF6GsCwgnOwZNJBr4XvBJpSSr2dBTqOR1dX+u0s8ogUFsYGrV7upo0YNbVokcigrP8dwU5BKD64Zezbed2H0bEhuNH03ZgPRcvsRkUKAQhteTi4AOXVBhfqQ3W83Qx6rgc/VgaaFnQ6NY38EZPoadoCmo4fLw++qxR6Tz0qWoLZsgwVLkDPdGC2Licz+RrMri340RKUEcJqeRk/Phwvrxo/XobV8gqJhd8hN/YC7Ko5GN3bcSrnEGp8DqNrK27JRPTeFtzymcRe+il+wQhyI88g/sLN+PFy3PKZePm1hJoW4pTPIrztMdySiWSmfASjp57Q1kcIb30Ut3QqXtFY3MIxuBXHomU7CW99NOh0VJ6A5vRitK8NbqCZ3ejpNpyqufiRQozu7Xj5I4is/zt27Sl4+SOwdizB7FiHn1+DXXsabulkQpsfwkg248fLMbq24keLcarmYXRuwuhpQHPSqEgBbvEEjGQTWqYdo3cHfqwcLdOBn1eFZifx4+VYLa/g5VXixytAeahIEU7ZdKzmF1HRYqymhahIEUbnZtySKahwPkbnZrz82uCG7GYxko14haPxw4WgG+TGnI+1cymh7U8C4BWMxCseR3T578GM4JZMwo8U4cfL+2/wvaf8AKtxIdH1d+PFhweBRaISP1KEsuJgRVB6GLNzA1bj82jKxy2qw09UoPc0oML5WK0rAMjVnoZTNZvwlofRPAdlxdB7GtAzHWBY+H3tRvPdAU0xqL+JnmkfeJqUzUDPdGAkG/FDeUGwluvu24YKlKbhlkzBKxxFZNN9GN3b0dxssO35QSfKj5Vi7t6AMqN4iQr0XBI904aXPwI/lMBsX4tXNA6jawtefi1u2TTCmx9EWTE0N4fm2/31UWYUt2QyWq4bPbULt3wGocYFKE0HIxx0AAGnfCaak0ZP7ULPdeGHC8nVvR9rx1L0ZN8Nf691egUjUaE8rJ0voXRzwP5xi8ZiJJv71+3l16J0E7NrK07pNIxkE3p2936ntx8uQPPs/uX6/x7KR7d7UGhoqKD8vCrMzs0HvEx4+bVo2S50uwc/XAC+h+70ApCZcm1wDjY8F2yLEUbzcihNxy2bjrF7E7rTi9J0NOUfcP3B/pqFnmzGTwxHc7NBoOGmMTq34JTNILztUTTfDdY7bBJW+2qcsumgm1gty4KydROn+kTMtlXomQ78aAl6ph2nbAZ+vBw/Phyz5WXMrm0ow0Lfa9TcS1SA8jFSu/ar22v76bUyBhybYRNwKk4g1PAseroVP1KMlutCd1J9xzaC5mZRaLhl09DT7Ri9zQc8Vn6iAmP3RrzCMRg9DfjhAox0a7Ceffbfa9t2KEoPAnfNt4MOJBooH015A47VgGWMMEo399Rft9B8Z//jVTIZPduJZicHtOWD8eLlYETAd/FjpWh2ErNry55y+/bT3uyKE7BaloJmHLAOXqICo3fnIesJ+++7w/EjRejZzoN+rnQrGCQ4yGySUzo1uGb17nhd9VGa0X9s3gpKt1BmpP+a+YbW8RbVSekhnIrjMNtWHlF7ORinZDJG784DXu/2LW/v6/ahvucnhgfX84PsI99KoPnOQY+3oq+PpVtHVOZr60Q3BpS5d7tIz7gOa/6Phlz8UVqad0Tfk2Ctz1sdrKlMBnvxQsxJk+m8/CIAzKnTCZ9yGqF5J2FU16ByWezFiwjNmRcEcr4XjIoXj9tvfdlHHsR+6hEKbvgyVtca3OHHoNDR020YyYa+kScNLdsZdJqKJ6Bld6O5WayWV1CahlNzEvge1s4lRFf9EadqLqmCuTBiKkZ2V9ARNCOYbavwCkagQgUYPdsBDbdoLCpWitG+Fs138KMlGD31eHm1aE4So2sb7rCJ6Jl2NDeLUz4LI70LpelENj1AfMl/ooww2fEXkxt3UdApjxSBEcZsXwOaQXbiZYQ3/isYZVNecHH3XbKTrurvLKtIcXATspPBCLPyg45abwtWy1L8WBmZqR8htONF3GETcEunouW6CTU+T3jrI0BwE7drTkFFCgltfwI/VoaKFGK0r8MvGIHZtirYhpIp+LFSwg3P7DmumkF28geDkU476Fxpbhq3uA493UaoaVH/Bci34uhOCoWGqpmNtnMFKA+75qRgm32vv+PwevjRYUFH/WBt7whupK91lvxQHrqdfF033wN1SPxIcRBYRgoxW15GUz7KjKG5A88pL1GJWzoVo3PzgI4FBJ0LP1aO0VMf/PsQnQUvrxo91RqMbOZ6gkB3r5uNHy4M/pZuRXMz+3UIndJpWG0r+254xwazJG4GPdeNM/yYYPR9nxuN0nRUuADQBpSljDAAmpfDLR6PMqNYrcsByI08G6N7K35eNUbXtr7UFhUELJ4N+LiFY8EIoWfaUbqFWzIJs2M9ZucmciPPItT0PJqbxY8Ow4sPh75AxGpehNG7Mwg8ehqD8gtHkz72c0EHtnsbeqYDt7gOq+UV9Ew7dvWJhOqfQk+1kpnx8aAdKYUfL8Po3Ixm96L5btA5z+7GjxSTG3cBXrwCjBDWzpfQ3Gwwslp5PHq6LdgvZgw/rzIY9XQzwexZbzNeXjVm+zrQTfxoMZobbL+ebMLPqyE98zpCDc+hp1uDWQo3g9W6ityI01GRIvRMG5lJH8RINhNddQcqnI87bCKam8Ha8RJGTz121Rz8vGpC258iPes/8PKqCG9+ED3Thp5uw8+rwY+XkxszH78vCA7VP40fHRbMLpROJbr8t1htq4K2FS/HLZ8Fmk562keDIB6F2bEBs21lEKgpn9zoc4IBl9QurNYVOJUnkB17IaGdSwjVP4XRtT0YbU5UEF33NzKTr8WPlWC2ryWy7m7cYePxhk3EbF2BCuXjDJ9FZP29WM2L8PJrydV9AK9gFNaOF3EqjsfcvR5z16t4RePwCkcHx7ZvJiy85SHcksnBfvRslJUgvO1x3NLJGB3rwQgHI9C6id93TOzak+mddyOJxTdhNS9GmRGUlYeyYjjV84LZvu7tRDbci1NxHMawkWir7+0Pstyisei9LfjxMtzhx2A1LSQz5cN9x60ds3UlyowEAz551WhultiyX5Ibfwl4NnquCy3bFQxCFY7GKZ9JePtTWE0LCTUvwhl+DG7JlKA9WVH8aEmwXKYdr2B0MCuy/amgLsV1ONVzMXoaCW1/MjhXCkdh7VwazOZa8WAmJdWKUzUHt3gcVutKvPwaNLsXI9mI3tOEXXsK8SU/BuXj1JxEdvwlmG2r8QrHoMxwMIDi5oJztGsroFC6hVdch55swujejj3idMzdmwjVP03vyTcRW/Yr9N4dpObcgNG5Jbj3xYejZztxyqbhDZtAdPnvgtnTWCnKipMbfS6ak8bs2oxbNA7NSQf7pGwGubqLCG95mMiavwT36UhRMMtjhHGq5vYF5RmsnUvxCkehdJP4Sz/FLRoXXANGnkl6xnUYvTsw21Zi156G0duM1bgQq+Vl7NrT8ApHEdr2OHquG2vnUnrnfTuYEVx/D5jRYLYsrxKvaBxatjPoVLvZvsHHYry82mCfptvx8ioIb30UpZnYI8/Ez6vCy6sBXUdPtWJ0bcbcvYmwStE9/pogOyDZAHoYL78aq+UVwpv+hR8rJTf63GB2S9Px48MJb/wnmu+hOalglj9eRmTNX4NUO+XTe/qP0TK7Mbq3o8wo0ZW3E97yENmJV+AOnxUMvOXVYnasxeiuR3MzQYaBZgQz8Hk1WDsWEwTlilDDMygrAaigb+HlQKn+9pQbfQ5G5yaUlUDzbIyuYIDWLZkMgNXyCtkJl6A5aaymRcHAYP5I4i/9BD9SiFM5h8zUDxNZ93fsmpMwepvR7BTO8Fn4icpgv+fXYCSbiay/G6tpMU7FseTqLsYPF2B2bsGumh1c3xKV+NFhfW1nMW7haELNi8mNOhtv2ARiL/4YI7UTPbULp2wGbtk08hZ8Ay9WTvJ9vwYng4qV4OWPILzpX5htq8mNnY/mOeipIKDXsl3BPiwa2zcw00Ko/qkgI8SKB7Pgmo6e3IFTNbtvMHdOsKyTDmbE86qC2cOWlwlvfhCnel5wTbTipOZ8HXQTzUkFwV+mIxjAiZVh7N4AmomfV4nRtZXcmPPw48OxdryICuVjdG4iN/JsNN8mvPlBvKIxxCefOeTiDwnWXqc3E6z5qV68jRvJ3HcvkQs/gDV5Kt2f/QTuurUHXsDQiYwpxenI4HX0YBWHSMwbRzjSQ2bpBtLpYqIzxxHVtuP0KHJNvaQagkVjZTlKpyQxwj6aobB7Tbq3xiiYXUI81IzmprGTBjk7H2d3Divu4WYMNE2RbgtRPrMHI6RIt1vs3pAg2RjFiHhYcQ/laoQKXApHpcnutsh0hEjtChMfnqXyhC6cWC07HkwTHWYTKXYwQj5OyiBS7BAv2zP64Tka3dtixEpz6KYilzTp2R6jdFoPoYSH8qFrW4xcp4Vn65RMCf6+d0aZ74GbNlC+RrjAZV8DMmTCpfhFI3BLp2Ds3kSoedF+3/fya/EKR2O2vIIfL0PLJTHSe0Z8/XAwi6bZSXLj3o+fGE5480Po6VbS0z8ezN7kerB2vUJ46yP40RI0pxc/Wtqf2qMiReRGngG6RWz5b4P1RkvITrySaNPT2IlalBkjsvGffWUWkJnxCUDhlkzC6NxMqP4Z0rM+hdWyDLdkYhBEAHbVXKydL2F0bcVsX4PmZuk59/eE6p8BTQ9mQVb9iezEy3Gq5hJqWoiXP4LEgm/ilkwiM+PjQQrR8Fno6fagvJ6G4MLftS1Ig0i3YiSbUUYIe+QZGN31GB3rcCpno7lpzN2bUVY0mFHL9WDuXIrd3IN23Nn4sTK8TRswRo3ByLWDruNHhgVpcImK4OaZS+HnV6PpwYHWexoxurag+oOQCCqUh97TiObZwU1Zqb5Bgeog9UnTCDU8R67mtCAdzbDQnBRKNwhvfginem7/jRwIUora1+AOm0hk03340RKcqrmoUAKrcQFu3ij8giCFTNOCUXJ0Ay3bibVjSdBm2lbhlM8K1mlF+1JgGoPtc3qDWVRAT+/Cj5WDlyOy7i78RBX2yDMPPROr1IE/9xz03h1BiqGbDRq7sc+ssecQalyAXXMimpOmoGw4XT1H8JyD7wXrPNRMt1Jo2U6UFT1oauSgOdg+OcD3NKd3T8rpkS53kHUZXVuDWfe+dbx2a9Te6DrfYD3wXTCsI/u67/efT4NF79qGn19LYXEeXW0daL6DnmoJ0iwHi5MOshjeiDfTDgg6oK+lB79rvMlz483szyM1mNlN/fpSRVWkaHDLeb3epn18OFqqNUgl7Msqerd5W9rY6yTB2uv0Rg6ichyS3/0m9nN7Zl7QNPTSMvzWXcTOmEv6qcUAjDy7jUihg5My6NwSp3dHGN1QhPJdeuoPfVPSIwaJY6tx0wbpV7bu/wUNUAqrUMeqKiO9trUvmtmfURgjMm44qaXBesyiKH7Wxs/sPy2vRUOEp00ku3QVeiKMYXo4uw88JZ04bTruxnVoJRVk1zWj7P0DLACjogxv5/6zSZplEK+LY3sl6GUl5JatRqWC4xEeU4byFVrZCNwdLUTOOJ3ciy+hXI/YtBH0PvYCsf/37/jtbZjTZ2Lf9xf04lIiF1+OtuIRQtOm4E44D3fLZjAMzJGjUL5P9k+/wWvvJP99M/GnnBvUY+/On++hUkmIxNGsvs6T8mH5o/g1s/AaG9HLhqNXVuO8/BJ+RwfhU09HZdLomRY8LR/n1ZfxGpopOnkuvcks1vGzg+l/uxd7xXKM8TNRdo7ck49hlA8ndOoZ5B5/FHQdr7kJvbAQ5TgYFZWEZs9BC+9JpXVWrsCoqQHTRM8Lnt1QSpH95z1o8QThM88GTSNz5/9ijq1Dr6gM0nH7tsXdtoXcU08QPuV0zHFBxyv9lz/h79xB/EtfBcdBpVJk7/8nevEwVC5H+Oxz0CJRsg/cR+7pJ3BXriD6oY/gd+4m99D96NU1JL7wZXAc3PrtuKtWYNTUEj7rHFK3/hJ8j9C8k3E3b8KoqsJ+YRFaLI4WDoNhELv2/+Fu30b2X/8gcsFFmGPr8BobsE6YDbaD39mBUVFFz1e/gN/ZSfTqa9BiMfyWFsxJk8k+/CBGZRXRS69Ai0Tw29uxX1yEt3MH0cuugpCF89ISjMoq/GQPPV/5IuaoURAKU/CLW9EsC5XJkLnrTsLnvx+jNAjEvB3N+G2tmNNmDOi8+11dOK++jHXs8eh5+dhLl+A1NeK3thKaeyLu1s2469ZiHXMsXn09RlUVWjxOaO5JqO4utIJCNHPPc2p+qjcIQiNRVDodfGYYoBRecyN6aTnOKy9jTpqMnsjD72hHi8XQi4oHXMO8lp14O5pR6TTW5Ck4q1bgt7aiV1RiTZuBnrf/DcJPJnHXrg7a6BF0HJTv43e09++jg35PKVRXF3rRoTtIyrZRto2eSBy2bAB/dweZf94bHOtEAmfJC7gb16OyWeKf/MwRrQNAZbOg62ihEOk7/4jKpIl//JMkv/et4ByrHUH8k5/pP0cA/HSK3u/fSOT89xOad9KRlZPLkvz+jUTOu4DQ3BP3+nswOn+4NHnlumTv+wf24oWETjoFf0czmbv+QuEf/4Y5OnhGyG2oJ/fwg4ROmIM1c1b/sm5DPWTSmOMn4qxZjbthHdGLLztgOX6qNzgn92oDzopXCXe24Z969kHr53d1kfr1z4M2NmFS0I5MeSz+vUb5Ps4Li7Bmz0UzjCNebih2pN+szD13Yc08BnPs/tlS7zT+7g6S3/0WiS99FaN2xNGuzhsyFNuYBGuv0xs5iLkFz5L8xleIXHwZ1rQZmJOn4Nx1C86Li8krbKF0apLObXEoqSUxJkx2wmVBioJn4xbXYfQ0YJdMw+/oJrzlAZxsBFuvIjy5GtW+C3s3mOPq0AoL0WPBKLhKp8k9/QT4Pt7OnWjRCOFz5pO9716cFctx16wOOrmTJpP5+9/w6reT/6OfBB2/WIzkd7+FSvYAkPf9mwnNmYff1orf1YleWg6Ojbt5E9bMWegFweiKs34tqZ/9BK9+G3k/+C/00jLIZEjd/jusadNxlr6Es2xpsFN0nfC552PNOhZ37Wr04mFoiQTGyFFk//VPnBcWoxUWoNJpCn71G7yGBjJ//TNaXh7OkhcgFAY7mB2If/rz+F1d2C8uQvX04Cd70AsK8Vt2HvK4aIkEKpMBLwhA9eoawqeeQebO/wUgdOLJ2IueHxDQGuPGY44cSfjc83GWLsHdugV/RzNeUyN6ZRXxT3waLR4nc+/dOIsX7iksFMIcM/bgs6j7CoWDC7dl4a549ciW6a+kgTV9Bub0mfhNTeSeeLT/I720DLNuPPaLi/u3W0skwDBQ3QPT+fTy4ehFRbjr1+35YzQabMfqVQP+RmbgszkAWl5+fxvamzV7Ln5zE15jwxFty2v1PCKGAb5/0EGI/dYbjaIZBqq3d0+9i4vB8/bbH6/Ry8pRqV5UKrVnmVgcc+IknBWvgutijBqNUVmFt6sFY3gF9rKlkMmgDysh/vnrSX7ra0e0OVpBAaq7G2PEKMJnn4PKZXFXr8RZsRxCIYyS0mA/hkJoiQSaYeK37TPIEQ5DLgeWReL6Gyh7/3zaF74YdOgXLjhM+YXopaWYY8ZiHXMc3s4d2M8/h7d5E4RCRC++DJVJYy97GX3YMPz2dhKf+xJeYwN68TCyDz8Q1NXOEb3qQ+gVlZh143HXrcXduAG/dRfu+rUYNbXow0qwFz1P7OOfxKiuJn37H4hcdDHZ+/6Bn0wSPuMs0DRyDz+IyqSJXvlB/K4uQsefgMpk8Ds6MMfVkXvmKfSCQpzVK/A72lGZLKqr7zkYXQ/aRx9r9lysqdNwXlmGddzxRC68GL+jHXfdGvA8tEQeoVNOQ9M0uj/3KdwN6widejq5hx4AoPCOO+n6tw8NaDuJz38ZlU5hHT+b9G239J9/xrg6wiefRviMs/B3dwTBn1KkbvsV0auuCfbL+nVoiTjJb3w1qN8xx2GdMAdryjR6vvkVjMpqEl/6KnplJaqri/Qdvyd66ZXYi58P9mFJKalbfo67Yf1+xzJy2ZXgOIROPZ3eH/8Iv7kJDIPEF7+CNWcemb/dSfaf94BlkX/zf9Nzw/WQyVDw+/9FC0cwampRqV78tjb0sjI6r74Us24C+T/+ObmH7if9tzvxmxrBsih+8HHI2SS/83XcLZtJXH8D4VNPByD5o++Te/iBPc3zvAuInDMfrbCAzN/vIvH564PjBGAYaLqO8n3cNavBMjHHBy+ZOdRAgbejmdyTj2HWTcCcNp3s/fehJxKEz5m/X2CoXJfUb27BKC0jcukVqJ5uuj/3KeKfv57QrGNx67eT/t2tGDUjiF33KTRNw+/cDb6P/dKLZO65i8Lb/jBggEy5Lt62rRhjx/XXU6XTwfWm799eQz09X/sSeTfeROrXv8AYM5b4pz8fXI98H69+O37rLvSiYsy68cE6fB939Uq8xgb81l2E5p6EOX7CQfeD8n2y99yFu2kD8S9+pb9/sC+/u4vc009ijBgJnkfouBPwGhvwWnYSOu4E3K1b6P3JzahMmsSXv45RXY27aSPW9JlopnnA2WWlFH5bK1oojF64/wxM9qH76b35JuKf+xLRS6/or6/X1Iiz5IXgWMXj+LtacJYtJXzu+WiGsV8fTL2W7fDatqRrwLPUAAAgAElEQVR6Sf3ip8Su/TeM6pr920ZzE+7GDYRPO2O/5d0N6/HTKYzSMvSqvkyKvrbYc+M3MCoqiH/i0/3H063fjjlh4puaVfd2tdB56YWETj+TvBtvOuIZcLehHmN4BVoo9PrKa2rE3bKZ8CmnoTzvgIHyvvt0wPI7mvG2be0ffHLWrEbZOfS8PIwx40jd8nOyf/8bkcuuJHrlB9HzC/Bbd+E1N2HNmEX69t+DaRL76L+D7x9R/Q9az30yBg6X5bDf9w+ScSDB2uvwbgrWkt+/EXvxQoofeAwzWU/+o//e/9B9tu5i3NIpONXzjuiFFoNBZbP4rbsGjIIo10WlU8FMRN+N4ojWpRTYdjADsu9nrrunY1Zw6OlzZdtgWeC6e2ar+tbvrlmFOW489vPPoldUYU2est/yfqqX7H3/JHz6mfi7d+O8vITIhR/Aa2wEXcNZsZzI/Avxtm8NRrVmHUv6j7ejOnejl5Xht7aCaWJNnY45ZSrWrGPJ3PlHvB1N+DsPHQQCYBhEr/wQuUcfglAIa8o0nNUriV5xNSqXI3P3X4hceDHuxvU4ixcS/fBHsSZNxnv8IfzhVahsFnfzJnAd3I0bwHHQy8qJf+YLoGkkv9nXmZt1LObkKai+zqzf0YGzagW5Z55E7T74g8BaLE74nPOwjj0ee8Ez5B59GC2RIHHDt/Ea6kn/9tcA6FXVRC78AKE5c+m69qpg4XCYyLnn425Yj3Jd9Px8vMZ6jDHjsKZMJXPP3UHnOBIJOq6ug+rqJPfYIyS+cSPmpCmQy5H61c8gGsVvbyc06xi0vDyyjzyE395O5Nz5mJMmY44dR+/PfkL41NPRwhH8VC/mqNHknnsGa/IUzLoJ2K+8DLZN6te/wN/VgjllKpGLL8PbshmjqhpjXB2pW36Bu+JVEl/7Jn53N+Gzz8FvaiRz91/RS0rRy4cTmj0XlcuSuesvaJZF6OTTUL1J0n/5E9akKRAOY44eg714IUZ1DX5bK+72bfhNjZgzZuEufwXr+NlBkP/MU7hbNwczjckkKpslcvGl5B59CL+1FS0Wx5o5i9DcE/Fad6GSSeLX/QfO+rWYo8eSe/yRPbN048aTfeRB/B1BqqsxegyhOSfi79qJ19aKOWoMynHwO9rB87COOY7s/92LOa4OY1wdflMjRk0t9tKXcFet2NMGiouJnHch1vQZoGlk7/sHelU1ekkp7rq16Hl5OK8uw2uoH9h4IhHM0WPxW3fht7cF7aSkFL2kZGBgD2BZhN93Hu7K5fuvBzBGjsKcOJncs09BLtcfsAxoq8XF6HkFePXbgmXG1aGZZjDwcaBg3jTBddGrazBHj8Hv6sSaNhN3yyY0ywo6G5s3Hfi8SCQGBO4QDOKonm5UT9/Ag2Fgjh13wIDoQCIXXRJ0QFetCILmvQLGgw1oABgjRvVv836s4EUL2DkIhcAemMmQ+OZ36b3pxkPWK/H1b5N7/FGcl18K/qBphM9834DBnSNh1E3A2zhwXxi1I1COjd+xO8joyOWwZs8j+oFL6PnWDcE1tunAr06PXn0N2YfuB89DLysPBhy379kPWiLotEQuugS/vQ134wb0YcOwjp+NUV6OSmfo/dl/Bfua4Pi9VpY+rITQGWfht7ehkkn87m5Ub7L/3IpeFQTemb/diTFmLJELLiJz5x/723nia98EIPXbW1Gde66vkYsuwWvZiTV1Otb0GWQfvJ/cow9hzTqG8LkXkH3wPtwVyzFGjiL+mS/gLFtK5q9/3n9f1tQSuexKvMYGsvfc1f93c/wErJnH4DU1Dhxg0TQil1+FNWESXmM97qaNaHn5hE4+FbOmFnvJC6R++dO+un+LyPwL8Fp34Tc3Y06ajL10Cek7/oC3feuANpT49vfo/fGPwLYp+OVvSP7oe8E54Djow0rAzuG3tmLNmYc1aQqZe+9Gi0QInXwqsQ9eS+aeu8j8857+Qbzw2edijKvDHDOWzF/+FAzSrl+L/XzwcpzYR6/Da2og99gjA/fHXudA/HNfInze+RTmR+lxdfxkD8nvfgvn1VcwamqI/b9/x5p5DOk7fk/2nrvQioqDwMow8Hc0oZcNR8vLI/ndb4Gdo+C2P6CXlpH6+U9wt28j9qGP0Hvz9weUr1fXkPeVb6DFYnR97NpgW867AK+hHnfLJshkiF77b5hjxpK9759EPnBJMHA3dhy5Jx7Drd9O4ktfRTNNnLVrsJ9/jtAJs7FmzMLdvJHUb2/FqKom+4+/B+WVlpH/01+Re+JR9OJhQaZEYwPe9q3EP/slUrf9CqN8OJH3X0zXR68hPP8CEtffQPL7N2LU1BC96kPkHvgXfnc33vatxD72CXLPPEXkvPPR8gvQEwk6r74Ur7GB8PwLyD32CObkqcQ//gm8+npyixYEA6lNjeT/508xp0wlecOXQdNIfONG9Lx8Os49HTyPwj/8EWP0WDpOn7f/SQxo+fmonh6s42cHfYXuLoxx4/E2bdjzpXCY/O/+EK2wkPRvbyV87nz8ri6Mqqqgr2YY2E8/gbtxA6ETTyFxwzfBV0HAuX4t6f/9H/J/9BOsSZPJLVxA7803BffyOXMJHXM8elUVqZ//BGPUaFRvL7lHH0avrAzuu1u3YC9dEgSdnoezbCmhU04jevW1lEybOOTiDwnWXqfXE6xlH7qf1O9uRe3eTfjsc6icmySy/h78cAG9p/woeL2t+R5+8+MQo2wbv2Unek0tfusutHjigKlWfldXkI5YUxt07CwLr7mJ6CWX427ZjN+yE6OqGrNuPCqdRvn+QVO2lO/jt7dhlAVvfjxQ+1Kui/3CIkLHn9A/eus1NQad0CnTDrlNXnsbmmWhFxSSW/Q8flsrekEB1glzBoyyOiuXoxUWYfYF7PYLizDHTwhuGH3cbVuDGYPJUw9Zpp9MolnW2/5WU3fDepL/9UPyb7oZo6JywGfK91HdXehFxW9pmUop/NZWjPJyvJad6KVlh0zp8dpaydz5RyIXXYI56sgHZ5RtB6PsVdVveBRXeR72s08T6u0kF4oRPvN9AwZCDia3cAHYOdz164j928fRotH+9eUefwRMM1iXpmEvXYKzbCmR91+M39mJPqwk6EC7Lu6G9WixKM6K5eiJBKEzzu7fFr+nGzwfrbAQ58XFeM1NmFOmBiO4c09EiyfwW4NnR/Wy8qADtnMHWn4BzopX0UwTvaiY7EP3E/vIR1Geh15YdND0OqUUyRuuxzr2eLSCArytW3GWLUWlejFGjiJ0wlzMyVOwX1yEu25t0EH2PIr/72H0kuAnEuzFC8k9+zTWrGNwXnoxGBRathRr7ono+fm4WzYTvfwqIufMD8pMp3G3bib7r/9DSyTwOzuxn3qc2Cf+Ixh8WvAszisv93ekEl/4Mn5XF+6qlfjJHsKnnkHyphsx6yaA66I8l/App9H7y5+hujoJzZ6LMXJUUP/jTqDzo9fibVxP3o034W7eSPa+fxD72CfIPnAf1qxjg4Ef38d+YRF+cxPWscdhjq0jc+/dpH7x3wDEPvVZ/OZG9JKyIJW1qhqvqSG4Hs2Zh59MYj/9JJErrg46Qw/dPyCAjn3qs4RmHUPy+9/Bb2tFpVMQjVL4m9vp+vBVB290Zt/PWDj7vzjIHD8BLRbHWf4KWjyBOXUa/o4dAwJbc9IUEl++ge7PfhKV7CH20evQS8v2dMZNE718OEZ50IG3ZszC3bCO3KMP71/epCnEP389vT/+0YCOplZYhDmuDmfpkuDf+wTeoVNOw3llGSrZg1ZQSGT+BeSeeyaY0dxH6MST0aKx/QJla/bcICg0TNyN64NBwKuvIXzameglpfTc8CXcFcsPvh8B64Q5eA3b8XfuxDp+Ns6ry/bbr3pFBeakqdhPPb7PwlbwXV2n4Oe34ie7+2d9jbHj+gc9rGOOQ4tGg4wN98CPNhySpg3IhjCnTcddGQwsafn54HpB23nt630ZB+g64dPPxH5h0YBMh7fcPtkjWjyOdcxx+J2dewbADjBoAsF+0ktKg3bSd16YU6bhNWzfMwD0JrwWFB1WJII5avSA7J7X0uv9juDtpnpFJeaYsdgLF6BX1xA5+5xgJqzvMy0aw9savLlWKx6GOXYczksvYoweg7c1eBFY+Jz5+D3dAzOL9qIPK+kvTyso2HPcdP2A+w8IAstHH0ZL5KG6u/b7fO+2eKS0vHyU60A2i15SijF6DM6rrxA+7XRqfvLjIRd/SLD2Oh1psOZu3kjXxz4cpC+dcSbFldvJ23A7uTHzSR1//QHf5CjEUJx+F+8u0sZePz/Zg9/aijlm7EG/o5SCbLY/mD2cIKVtFeaUqf2pOEop/F0t6CWlR/wcl/L9IANhn3Qiv7srSA0dPSao2z5ZCodcp+virl6JNWPWob+Xy+Ju3Ig1dRrKcXDXr6Ogupzuhh2469YSueTy/jL93l6y//oHoePnYI6rQ+Wy+Lt3Yy9cQPic83DXrkELhck99zThs89Fs6wB6Vp+6y6MyioIh4NUxN5etEikfz/5uzvwdu1CZTNYU6cHs6/bt6Eymf5UNWfNaoyKiuBZu30Gk5RtY7+4CGwbY8Qoso89jFFdQ+T9FwflJZPkHnkwmA2eMrV/sKv3lz/F3bSRgv/6GX53F/aSF4IZvHknodIp3LVrMCdMRM/LR+Vy5J58HJXqxZw2HZVKkXvoAeJf/AqaFcy++Dt3onJZIvMvHHBMVSYTPDO5V9aKn+oNUtJNE31YCaqrE6+5CS0SDQZAlCIy/0Iy995N+g+/AdfFnDgZvawcLRrB7+4m/slPY1RWo4XDqFyW7i9+Bj2/gMjlVwXP1z7/LNbseVgTg9+fsl9+Ca+5icgFF+G8/BLmmLHBbBvB883Jb3wVc8YsrMlTcbdsCjIGVq1AdXXid3YSPue84DGLXI78798MISsIYhwHr7kZv6uT0Jx5QUrirp3o5RVophk85uC4sH4N2U0bQUH0iquJffBa3E0b6b7+c1gzjyE061jCZ56Ns2pFMLiwcwf2c8/gLH+V8JlnY9TU4u3cgb+rBa2wCL+5icj7PxA8Z/WVr6MPr0AvKMDb0YwxYhS5Jx/DWbqE6KVXBss2NmBOn9Gfnpt76nHwfELzTsR5+SVUKoW96HmMEaPQy8uDz7PZYFb1k58he///YS9eiF5eQfis9+GseBVr2gy8xgaUY+Nt2kjkgovQ8vPxtm5Br6lFMy0yf/lj/+BS9p67gmfgFy/sy9yZSvTqa8k9+xTmmLH4nZ0oO4e/oxlz3HjSf7odvbwCXAe/vZ28m25GdXcROmEuCkXu4QcxRo3GmnUsmqaRe+oJkt/5BhBk4eTf/N8k/+sH4LrEP/N5jIoqUrf8DGf1KkInnkLejd+HXA536+bguG/eRPpPtxP78EdJ/e5WzNFjCZ87n+7PXEfiC1/B27YVLS+P8JnvI33770DTiH3kY9hLl4Bj47e1YR0/m9RP/xNr9lziH/sE9ksvkrzpO1iTp2DUjsDdvi14JGPjhv4BgvgXv0L27r9ijB0Hvk/q5z/BnDCR0KlnoBcUYIwYBZaJu34dkQs/EBzDXLZ/EFz1PS5QVJwYcvdICdZepyPt6PR862s4S5dQ9Pf7KHr2k4QaF5CZfA29p/zg3fX2KPGWko60GGzSxsRgeq+1r0M93zPUeA31wQzJIYL2N7s9R7L8mymjsDBGZ2cwG7PvM3KHWueb/fyd7I1sm7ejmd6f3EzopFOIfuDSQarZoe1b79e7Hf7uDrRE3ut+rm8oXsOONFiTVzW9DvZLL2I/+zTRD3+USPtiQo0L6J37TTIzrhsSr10VQgghxJv3TurgH8nb+d7s9hzJ8oNRxuHW+WY/fyd7I9tmVFZR8NNfDUJtjty+9X6927H3YxzvFTIVdISctWtIfusGjBEjKZw3nLxnv45bOJrM9I9JoCaEEEIIIYR4y0mwdoQyf/0ThEKUfvp8Cp/+D5Su03Pe7aDL5KQQQgghhBDirSeRxhFwt27BXvAs0fPPJX/DLbjF4+m84jEJ1IQQQgghhBCDRmbWDsNZuSL4HQ7DoCT8LJqdJHn6f0ugJoQQQgghhBhUEqwdgrejmZ6vfxm9fDiVXzufhLmZnrNvxS2fcbSrJoQQQgghhHiXk2DtEFK/uQVch4L//CnxjsexK2fjjDjtaFdLCCGEEEII8R4gwdpBeG2t2AueJXLBBwiHOjA7N5Mbd9HRrpYQQgghhBDiPUIevDoIZ8kL4HmEz5tP/IWv4keKyY278GhXSwghhBBCCPEeITNrB+FuWI8WixOxWgnteJHUcZ9HhfOPdrWEEEIIIYQQ7xESrB2Eu2E9Rt14Ystvw48UkZ141dGukhBCCCGEEOI9RIK1A1C2jbtlE+GqfML1T5OecR1Y0aNdLSGEEEIIIcR7iARrB5B77mmwbfJDq/ESFWSmf+xoV0kIIYQQQgjxHiPB2gFk/3EPZkmCgtBKMjOuAzNytKskhBBCCCGEeI+RYG0f7oZ1uGtWMaymGXv0+8hM/uDRrpIQQgghhBDiPUiCtX1kH3sEzTIoGJUmecqPwJRn1YQQQgghhBBvPwnW9uFt20qoGPzq6ah42dGujhBCCCGEEOI9SoK1ffjbNxGOJMlOvOJoV0UIIYQQQgjxHibB2l5ULovX3olVZJKdcNnRro4QQgghhBDiPUyCtb14zc0AGLWj5A2QQgghhBBCiKPqsMGa7/t8+9vf5oorruCaa66hvr5+wOf/8z//w8UXX8wll1zCE088MWgVfTv4W9YBoI+ZcpRrIoQQQgghhHivMw/3hSeffBLbtrn77rtZvnw5N998M7fddhsAPT09/PnPf+bxxx8nk8lw0UUXcdZZZw16pQeLu/hJdNNHm37S0a6KEEIIIYQQ4j3usMHasmXLOOmkIHiZMWMGq1ev7v8sGo1SWVlJJpMhk8mgadphCzQMjcLC2Juo8uDQdQ371ZXEynPEJ54EsaFXR/HOZRj6kGz34t1D2pgYTNK+xGCS9iUG2zu5jR02WOvt7SWRSPT/2zAMXNfFNINFKyoqmD9/Pp7ncd111x22QM9TdHWl30SVB0c81Ynb0UtsXowuOwr20KujeOcqLIwNyXYv3j2kjYnBJO1LDCZpX2KwDcU2Vlqad0TfO+wza4lEglQq1f9v3/f7A7UFCxbQ2trKU089xbPPPsuTTz7JypUr32CVjy57y2YAjDHjjnJNhBBCCCGEEOIIgrVZs2axYMECAJYvX05dXV3/ZwUFBUQiEUKhEOFwmLy8PHp6egavtoPI3rAGAG3CsUe5JkIIIYQQQghxBGmQZ511FosWLeLKK69EKcUPf/hD7rjjDmpraznjjDNYvHgxl19+ObquM2vWLObNm/d21PstZ29chxHx0IaPOdpVEUIIIYQQQgg0pZR6Owt0HG/I5YwC9H78SvTd6yj4+S04NfI2SPHWGoq50uLdRdqYGEzSvsRgkvYlBttQbGNv2TNr7xVuWwdW3ENFCo92VYQQQgghhBBCgrXX+LkcuqnwwxKsCSGEEEIIIY4+Cdb6qJyDbvgysyaEEEIIIYQYEiRYA5TvoxwPzdRQVuLwCwghhBBCCCHEIJNgDSCXA0CLREDTjnJlhBBCCCGEEEKCNQBUNhP8TyR6dCsihBBCCCGEEH0kWANUNguAFo0d5ZoIIYQQQgghRECCNfYEa0TleTUhhBBCCCHE0CDBGqByfTNrsfhRrokQQgghhBBCBCRYA3htZi0UPrr1EEIIIYQQQog+Eqyx1zNrYfMo10QIIYQQQgghAhKssSdY00PWUa6JEEIIIYQQQgQkWGPvmbXQUa6JEEIIIYQQQgQkWGPPC0aQmTUhhBBCCCHEECHBGkAm+FFsPSIvGBFCCCGEEEIMDRKssder+2VmTQghhBBCCDFESLAGqGwONAWWPLMmhBBCCCGEGBokWANUNoNuKtCMo10VIYQQQgghhAAkWAOCt0HqhgJdgjUhhBBCCCHE0CC/Ag2YI0cQLsuBJrtDCCGEEEIIMTTIzBoQvfgSquZ2oXTZHUIIIYQQQoihQaITQFNu3//IzJoQQgghhBBiaJBgDcD3gv/KM2tCCCGEEEKIIUKCNQAVBGtK3gYphBBCCCGEGCIkWAM0vy8NUpc0SCGEEEIIIcTQIMEa9M+sSRqkEEIIIYQQYqiQYA36n1mTNEghhBBCCCHEUCHBGsjMmhBCCCGEEGLIkWAN0F57G6TMrAkhhBBCCCGGCAnWAHz5nTUhhBBCCCHE0CLBGux5db+kQQohhBBCCCGGCAnWAE1JGqQQQgghhBBiaJFgDfrfBim/syaEEEIIIYQYKiRYgz1pkJrsDiGEEEIIIcTQINEJoL32ghGZWRNCCCGEEEIMERKsgfzOmhBCCCGEEGLIOexUku/7fOc732HDhg2EQiFuuukmRowYAcC6dev44Q9/2P/d5cuX8+tf/5qTTz558Go8GOR31oQQQgghhBBDzGGDtSeffBLbtrn77rtZvnw5N998M7fddhsAEydO5M9//jMAjzzyCGVlZe+8QA32enW/pEEKIYQQQgghhobDRifLli3jpJNOAmDGjBmsXr16v++k02l+9atfceedd771NXwbaP0za5IVKoQQQgghhBgaDhus9fb2kkgk+v9tGAau62Kaexa99957OeeccyguLj5sgYahUVgYe4PVHRxaNEh/TOQnYIjVTbw7GIY+5Nq9eHeRNiYGk7QvMZikfYnB9k5uY4cN1hKJBKlUqv/fvu8PCNQAHnjgAX75y18eUYGep+jqSr/Oag6uUG+aAiCZcvCGWN3Eu0NhYWzItXvx7iJtTAwmaV9iMEn7EoNtKLax0tK8I/reYfP+Zs2axYIFC4DgBSJ1dXUDPk8mk9i2TUVFxRuo5tCgyQtGhBBCCCGEEEPMYWfWzjrrLBYtWsSVV16JUoof/vCH3HHHHdTW1nLGGWewbds2qqqq3o66Dp7+V/fLC0aEEEIIIYQQQ8NhoxNd1/ne97434G9jxozp//9p06Zx6623vvU1ezup4EexlfzOmhBCCCGEEGKIkNcfgvzOmhBCCCGEEGLIkWAN0PrTICVYE0IIIYQQQgwNEqyBzKwJIYQQQgghhhwJ1gD8155ZkxeMCCGEEEIIIYYGCdbYKw1SZtaEEEIIIYQQQ4QEa7AnDVKeWRNCCCGEEEIMERKsQf/vrClN0iCFEEIIIYQQQ4MEa4DWP7Mmu0P8f/buO0CO+r7//3PK9r29XtR7r4huEL0LjLEBy9iQYAfydYKT2PzixE4CGBPADklcAENsB8cNMNWYZkw3AiRQAdTrnXQ6Xa/bd2fm98eeDgQCFXTak3g9/pFudnbmvbufnd3XfD7zWRERERGRoUHpBAZ+FBv1rImIiIiIyBChsAbvmbpfT4eIiIiIiAwNSicAnoNnWGAYxa5EREREREQEUFgD+qfu12+siYiIiIjIEKKEAoVhkAprIiIiIiL7xHHydHW1kc9ni13Kh2ppMfA8ryj7tm0/5eXVWNb+ZQ0lFAA3r5kgRURERET2UVdXG8FgmEikDmOIXlJkWSaO4x70/XqeRyLRS1dXG1VVw/ZrG0ooaBikiIiIiMj+yOezRCKxIRvUiskwDCKR2MfqdVRYg8IwSMMqdhUiIiIiIoccBbUP93GfG4U1APWsiYiIiIjIEKOwBv0TjKhnTURERETkUPPkk3/gJz/5cbHLGBTqTgKyZgjLX1bsMkRERERERAYorAH/mb+EjZlT+WGxCxEREREROUQ9saqFx1Y2H9BtfnpmHQtm1O7Vuvfe+2uee+4ZLMtizpwj+Ju/+TvefnsFd9zxAyzLpqSkhOuvv4n29nZuvvk72LaNZVn8679+h+rqmgNa94GisAZ0u0E2ZaLFLkNERERERPZDY+NWli17k7vu+l8sy+Jf/uWbLFr0Z1asWMYpp5zG5z//JV555WV6e/t4443FTJkyla997Ru89dZy+vp6FdaGMts0yTvF+aE8EREREZHDwYIZtXvdC3agbdiwnk99aj62XYg3c+bMZcuWTVx++ZX86lf38Pd//1Wqq2uYPn0m559/Ib/5zf9x7bVfIxKJ8td//bdFqXlvaIIRwDYN8q7CmoiIiIjIoWjSpMmsXr2SfD6P53msWLGcUaPG8Kc/PcWCBRfw4x/fzbhx43nssYd55ZWXmDPnCH74w59w6qmn85vf/F+xy/9Q6lkDLNMg7x78XzUXEREREZGPb+TI0cyaNYevfvUreJ7H7NlzOOmkU1i9ehXf/e51hEJhbNvmm9/8FzzP48Yb/w3LsjBNk6997RvFLv9DKazR37OmYZAiIiIiIoec8867YOD/Cxd+aZfbZsyYyS9+8VscZ9eOmbvvvueg1PZxaRgkYFsaBikiIiIiIkOLwhqFnjXH9fA8BTYRERERERkaFNYozAYJqHdNRERERESGDIU1ChOMADgKayIiIiIiMkQorFEYBgnqWRMRERERkaFDYY33hDXNCCkiIiIiIkOEwhqF2SAB/daaiIiIiIgMGQpraBikiIiIiIgMPfpRbN6dYERhTURERERk/wTWPkhwzX0HdJvpaQvJTL34I9dJJOLceutNxON99PR0c8EFFzF58lR++MPb8DyPmpoarrvuu2zcuHFgWXV1Dddf/10CgeABrfdAU1hDU/eLiIiIiByqGhsbOeOMszj55NNob2/jmmuuJhAI8p3v3MzYseN49NEHqa+v5/vf//eBZQ8//AD19fVMmTK12OV/JIU1NAxSREREROTjyky9eI+9YIOhsrKS3/3ut7z00guEwxHy+TzJZCdjx44D4HOfuxTHcenqenfZZz97yUGvc3/omjXeDWuOZoMUERERETmk3Hvvr5g5czbXXfddTjvtDDzPo6qqim3btgLwq1/9gpdeemGXZb/+dWHZULfHnjXXdbnhhhtYt24dfr+fm266iTFjxgzc/tJLL3HHHXcAMH36dE81qL0AACAASURBVK6//noMwxi8igeBZoMUERERETk0nXDCSdx22y0888xTlJaWYlkW1177LW655UZM06SqqoqLL15ITU3NwLLKykouvfSyYpe+R3sMa88++yzZbJb777+fFStWcOutt/KTn/wEgHg8zn/8x3/wy1/+koqKCn7605/S1dVFRUXFoBd+IGmCERERERGRQ9O8eUfx298+9IHld975MwAsy8RxXKZNmzGw7FCxx2GQS5cuZf78+QDMnTuXlStXDty2fPlyJk+ezPe+9z0uu+wyqqqqDrmgBrpmTUREREREhp499qzF43Gi0ejA35Zlkc/nsW2brq4uFi9ezKOPPko4HOaLX/wic+fOZdy4cR+6PcsyKCsLH5jqD5Cy7jQAwbB/yNUmhwfLMtW2ZFCpjclgUvuSwaT2dWhraTGwrKE/DUYxazSM/c8/ewxr0WiURCIx8Lfruth24W5lZWXMmjWL6upqAI466ijWrFnzkWHNcTy6u5P7VexgSSezAHT3podcbXJ4KCsLq23JoFIbk8Gk9iWDSe3r0OZ5Ho4ztOd92DkMslg874P5p7q6ZK/uu8eIOW/ePF5++WUAVqxYweTJkwdumzlzJuvXr6ezs5N8Ps9bb73FxIkT96X2IWFgghHNBikiIiIiIkPEHnvWzjzzTBYtWsTChQvxPI+bb76Ze+65h9GjR3P66adz7bXX8ld/9VcAnHPOObuEuUOF1T97peMprImIiIiIyNCwx7BmmiY33njjLssmTJgw8P8FCxawYMGCA1/ZQRR3OjADzeSdof0L5iIiIiIi8skx9K8GPAieaPotwRG/0WyQIiIiIiIyZCisAR4OhplRWBMREREROUxdc83VNDTUf+jtF198AZlM5uAVtBf2OAzyk8Bn2mA4CmsiIiIiIvvpmcaneKrx8QO6zXNHns9ZI889oNs8lCisAT7Th2HkcRTWREREREQOKd/+9j9yySULOeKII1mzZhV33vkjysrKicf76Onp5sILP8uFF35ur7e3Y0cTt976XfL5PIZh8Pd///8xadJk/v3fb2D79kay2Sxf+MKXOP30s7j77jtYtuxNXNflzDPP5tJLLzugj01hDfCbPjBc9ayJiIiIiOyns0aeW5ResAsu+AxPPfU4RxxxJE8++Tjz5h3F+PETOPnk02hvb+Oaa67ep7B2xx0/4OKLP8/8+aewYcM6br31u/z4x3exbNmb/Oxnv8IwDJYseR2AP/7xSW6//X+oqqrmySf/cMAfm8Ia4LN8hWGQQ/wH/UREREREZFfHHns8d975Q3p7e3j77eXcdtuPuOuu23nppRcIhyPk8/l92l59fT1z5swDYNKkKbS2thAOR/j617/J97//7ySTCc46qxBKb7jh37n77tvp6OjguOM+dcAfm8IaELB8GIZLznGKXYqIiIiIiOwD0zQ59dQzuO22W5k//xTuu+/XzJw5m4suuphly97k9ddf2aftjR07lrffXs6JJ57Mhg3rqKiopL29nXXr1nDLLbeRyWT43OcWcOaZ5/DCC89xww0343kel19+KWeccTZ1dcMO2GNTWKN/GCSQdfctdYuIiIiISPEtWPBpLr30Qu677xF27Gjitttu4ZlnnqK0tBTLsslms3u9rb/923/ge9+7iXvv/TX5fJ5vfevfqKyspLOzgyuvvIxQKMzChV/C7/cTi8X4y7+8jJKSEo4++jhqa+sO6OMyPM87qBdq5XIO3d3Jg7nLPbp/82+5e+3tXBT7OV87cVqxy5HDUFlZeMi1ezm8qI3JYFL7ksGk9nVoa25uoK5uTLHL+EiWZeIU8XKn3T1H1dUle3Vf9azRP3U/kHVzRa5EREREREQGy+rVK7nzzh99YPnpp5/FRRddXISKPprCGmAbhWGQOUfDIEVEREREDlfTp8/k9tv/p9hl7DWz2AUMBb7+a9Zy7t6PZRURERERERlMCmuAZVoA5DTBiIiIiIiIDBEKa4CvfxhkXmFNRERERESGCIU1wB4YBqkJRkREREREZGhQWANsQ7NBioiIiIgczq655moaGuqLXcY+0WyQgN0/db+GQYqIiIiI7J/000+QfuIPB3SbwQUXEDxnwQHd5qFEYY13Z4PMOupZExERERE5lHz72//IJZcs5IgjjmTNmlXceeePKCsrJx7vo6enmwsv/CwXXvi5PW7nhRee5eGHH8DzPABuuun7xGIxfvCD/2DNmlXkcnm+8pWrOeGEkz6wbP78UwblsSms8e4wSPWsiYiIiIjsn+A5C4rSC3bBBZ/hqace54gjjuTJJx9n3ryjGD9+AieffBrt7W1cc83VexXWtm3byn/8xw8JBoN8//v/zpIlrxEIBOnp6eanP/0lHR3tPPTQ73Bd7wPLFNYG0c5hkDlPPWsiIiIiIoeSY489njvv/CG9vT28/fZybrvtR9x11+289NILhMMR8vm965ApL6/gppuuJxwO09BQz8yZs2lpaWDGjNkAVFZWcfXVf8OvfvWLDywbLJpghPf+KLZ61kREREREDiWmaXLqqWdw2223Mn/+Kdx336+ZOXM21133XU477QzA2+M24vE4P//53XznOzfzT//0rwQCATzPY+zYsaxdu3pgnW9845rdLhss6lkDrP5hkI561kREREREDjkLFnyaSy+9kPvue4QdO5q47bZbeOaZpygtLcWybLLZ7EfePxKJMGvWHL785S8RCoUoKSmhvb2N8867gDffXMJXv/oVHMfhyiuv4rjjPvWBZYPF8HZeQXeQ5HIO3d3Jg7nLPdqeaOTyly6lpPdL/H7h4HVjyidXWVl4yLV7ObyojclgUvuSwaT2dWhrbm6grm5Mscv4SJZl4jhu0fa/u+eourpkr+6rnjXevWbN8ZwiVyIiIiIiIoNl9eqV3Hnnjz6w/PTTz+Kiiy4uQkUfTWGNd2eDdPSj2CIiIiIi+8TzPAzDKHYZe2X69Jncfvv/HLT9fdxBjJpgBLD7JxjJe5pgRERERERkb9m2n0Si92OHksOR53kkEr3Ytn+/t6GeNcDXPwzSVVgTEREREdlr5eXVdHW1EY93F7uUD2UYRtHCpG37KS+v3v/7H8BaDlkDP4qNwpqIiIiIyN6yLJuqqmHFLuMjHcqT2GgYJGCpZ01ERERERIYYhTXAMiwMTFwcXI23FRERERGRIUBhrZ9p2BiGQ85RWBMRERERkeJTWOtnYYPhkCviD+aJiIiIiIjspLDWzzJsQGFNRERERESGBoW1fpaxs2dNwyBFRERERKT4FNb6WaaNYeTJqmdNRERERESGAIW1fj4zAGaevHrWRERERERkCFBY6+c3/RhGTj1rIiIiIiIyJNh7WsF1XW644QbWrVuH3+/npptuYsyYMQO333TTTSxbtoxIJALAnXfeSUlJyeBVPEj8ZgDMrCYYERERERGRIWGPYe3ZZ58lm81y//33s2LFCm699VZ+8pOfDNy+atUqfvazn1FRUTGohQ42vxXAMBKaYERERERERIaEPQ6DXLp0KfPnzwdg7ty5rFy5cuA213VpaGjguuuuY+HChTz44IODV+kgC1iFnjUNgxQRERERkaFgjz1r8XicaDQ68LdlWeTzeWzbJplM8qUvfYkrr7wSx3G44oormDlzJlOnTv3Q7VmWQVlZ+MBUfwCF7BAYeQIh/5CsTw5tlmWqXcmgUhuTwaT2JYNJ7UsG26HcxvYY1qLRKIlEYuBv13Wx7cLdQqEQV1xxBaFQCIDjjjuOtWvXfmRYcxyP7u7kx637gPObAQwzR1dPakjWJ4e2srKw2pUMKrUxGUxqXzKY1L5ksA3FNlZdvXdzfOxxGOS8efN4+eWXAVixYgWTJ08euK2+vp7LLrsMx3HI5XIsW7aMGTNm7GfJxRWyg2DkyLm6Zk1ERERERIpvjz1rZ555JosWLWLhwoV4nsfNN9/MPffcw+jRozn99NO54IILuPTSS/H5fFx44YVMmjTpYNR9wAXtQs+aZoMUEREREZGhYI9hzTRNbrzxxl2WTZgwYeD/V111FVddddWBr+wg29mzlsk5xS5FREREREREP4q9U9QfwjA84rlssUsRERERERFRWNupJFCYISaeTRW5EhEREREREYW1AWFfEFBYExERERGRoUFhrV/ACgDQl1NYExERERGR4lNY6xewCj1riVy6yJWIiIiIiIgorA0I9oe1pMKaiIiIiIgMAQpr/YJ2YRhkMq+wJiIiIiIixaew1m/nNWtphTURERERERkCFNb67bxmLe1kilyJiIiIiIiIwtqA4EBYU8+aiIiIiIgUn8Jav0D/NWtZVz1rIiIiIiJSfApr/Up8JQBkvQSe5xW5GhERERER+aRTWOsX9UUxscBMkMm7xS5HREREREQ+4RTW+hmGQdAsxbTjJHNOscsREREREZFPOIW194hYMQwrSSKjsCYiIiIiIsWlsPYeMX8ZhpWgM5ktdikiIiIiIvIJp7D2HpWBcgw7QUufZoQUEREREZHiUlh7j9pwBYYVpzWunjURERERESkuhbX3qAyVY1gZdvTGi12KiIiIiIh8wimsvUeZvxyApnhHkSsREREREZFPOoW196gMVgHQkmotciUiIiIiIvJJp7D2HiPCIwFozzQVuRIREREREfmkU1h7j+Hh4YBBwmuhL50vdjkiIiIiIvIJprD2Hn4rQKldhenvYFN7otjliIiIiIjIJ5jC2vuMjIzE9HWwUWFNRERERESKSGHtfcbFRmMG2tjQpun7RURERESkeBTW3mdS6RQMK8VbrfXFLkVERERERD7BFNbeZ0rpNAC2JtbRm84VuRoREREREfmkUlh7n/ElE7ANH2aokRXbe4tdjoiIiIiIfEIprL2PbdpMiE3CDjWydFt3scsREREREZFPKIW13ZhWNh0r1MTSbV3FLkVERERERD6hFNZ2Y2rpNDwjw8aeLfpxbBERERERKQqFtd2YUlaYZMQIbmNxg3rXRERERETk4FNY241RkdGU+soIx7bw0qaOYpcjIiIiIiKfQApru2EaJvOqjsKObuCVze3kHbfYJYmIiIiIyCeMwtqHOKrqGHL0kmQ7Sxt7il2OiIiIiIh8wiisfYijqo4BIFiykRc3tBe5GhERERER+aTZY1hzXZfrrruOz3/+81x++eU0NDTsdp2/+qu/4t577x2UIouhOlTDmOg4yqu28Nx6DYUUEREREZGDa49h7dlnnyWbzXL//fdz7bXXcuutt35gnR/84Af09Bx+QwWPrjqGpLmBrkycRVs0K6SIiIiIiBw8ewxrS5cuZf78+QDMnTuXlStX7nL7008/jWEYnHTSSYNTYRGdUHcSeS9HWcUGnljdUuxyRERERETkE8Te0wrxeJxoNDrwt2VZ5PN5bNtm/fr1PP744/zoRz/ijjvu2KsdWpZBWVl4/yseJJZlfqCuE2PHUbmiktDwDbyyahae36Y87C9ShXIo2137EjmQ1MZkMKl9yWBS+5LBdii3sT2GtWg0SiKRGPjbdV1su3C3Rx99lJaWFv7iL/6C7du34/P5GDFixEf2sjmOR3d38gCUfmCVlYV3W9cJNSfxdOOT5NwFPLhkK5fMHV6E6uRQ92HtS+RAURuTwaT2JYNJ7UsG21BsY9XVJXu13h7D2rx583jhhRc477zzWLFiBZMnTx647Zvf/ObA/3/84x9TVVV12A2HPKnuVB7b+gijhjfwxKpKhTURERERETko9njN2plnnonf72fhwoXccsstfOtb3+Kee+7hueeeOxj1Fd2cirnEfKVUVq9jVXMf9R1DK5WLiIiIiMjhaY89a6ZpcuONN+6ybMKECR9Y72tf+9qBq2oIsUybE+tO4oWm57DMs3l8dQvXzB9X7LJEREREROQwpx/F3gsn151KykkyfXwTT61uwXG9YpckIiIiIiKHOYW1vTCv8ijK/eUEylbQGs/y5tbuYpckIiIiIiKHOYW1vWCZNqcOP5NNyTcpCeb5w6rmYpckIiIiIiKHOYW1vXRK3WnkvRyzJzbx4sYO+tL5YpckIiIiIiKHMYW1vTStfAbl/nJ8sdVk8i7PrGstdkkiIiIiInIYU1jbS5ZhcXztiazpXcLEaj9/WNlS7JJEREREROQwprC2D06sPYmkk+SIie2sau5jY3ui2CWJiIiIiMhhSmFtH8yrPIqgFcILr8I2Df6wUhONiIiIiIjI4FBY2wd+K8Ax1cfyZsciTpxQzlOrW8k7brHLEhERERGRw5DC2j46ofYkOjLtzJvQQ1cqxyubO4tdkoiIiIiIHIYU1vbR8TUn4DP9tLOEmqif+5dvL3ZJIiIiIiJyGFJY20dRXwnHVX+KF3c8x8J5dby5rYd3mnqLXZaIiIiIiBxmFNb2w7mjzqcr20lZ9UpKgza/WLKt2CWJiIiIiMhhRmFtPxxbfTwTY5N4oOHXXDJ3GC9v6mB1c1+xyxIRERERkcOIwtp+MAyDL074CxoTWxkzagPlIR//+cImHNcrdmkiIiIiInKYUFjbT/PrTmF0ZAwPNvyavz95HG839fK/r28tdlkiIiIiInKYUFjbT6ZhctnEK9jct5Hyqo2cN72Gn77WwAsb2otdmoiIiIiIHAYU1j6G04edybDQcH698Rd887SJTK8r4Z8eW829yzSdv4iIiIiIfDwKax+DZdp8ceJfsLZnNb/f9lvuunQ2J0+s5L9e2MT1T62lI5EtdokiIiIiInKIUlj7mM4deT6nDz+Ln62/iyXtL3PrBdP58nGjeWZtG5//xZs8ubpFE4+IiIiIiMg+s2644YYbDuYOXdcjnc4dzF3ulWDQt191GYbBcdXHs6xjKY9tfQQMj0jJdv7+2NN5a3sP9y9v4rn17aRyDkGfRWXYh2EYg/AIZCjb3/ZVTFknS9JJELACxS5F9sKh2Mbk0KH2JYNJ7UsG21BsY5HI3n2/Uljr93FeRMu0Oa7mBF5tfYUXdzzH0o43mFU1nr87/gTGV0VY3dzHE6tbefjtHTz01g42tidI5x0qI35CPusAP5LDT9bJYhrmxw65nlfo4TQMg6yT5anGxwlZYUr9pXu9jbZ0G7es+A5vtC3m2JrjsYzC65fMJ3i0/iFGRkaRc7O80vISlYEqTEzW9KxmQ99aTNdmXc9aXtzxHKZh0pzaQam/jM19m6gMVrGpdyMRO0J7po0blv0LKSfFlNKp5L38wH7eL5FLsLp7JXXhYQBsjdezuW8Tw8LDcTyHW9/6Lpv7NjG3ct5u7++4efJuns5MB9e8dhVjo+MGtvXfq77PT9b8mFnlc4j5YlimvVfPUWNiGx4QtIKknTSvty6iIlCJ/32hz/M80k6KLX2bqQxW4XkeDfF6TMP6yIDoeu5AW0g7abYlGigPVOxVbfsr42ToyLQT9UU/dJ2+XC9+079X7XRFxzJa0s3UhYYdkPoWt75GLBTBct593pqTO9iW2Ep1sOaA7OP9PM+jMbFtn94/B5rjOZjGuwNE4rk+kvkkQTu0X9tb272arfEGhoWHH6gSB3ied1BO1L33OLc7jpsnkY/v80mYPX1Gup7L8o6leHiU+GL7tO1i8DyP+vhmyvzlOoHaL5VPknfz+Ezffm8j5+Z4uvEJ6kLDcLw8ralWHtv6MDPLZ3/k83ywvkjHc3H6cr2E7TAAHel2HC+/y/uhObmDqK+EtlQr63rWUBuq26828nHf8/FcHMMwPvTz/71czyWRT7A1UU/ICu3Xa/j+4+kut7l5Xmh6lmHhYaTyKSzD+tB191bWyRLPxwlawX2+byqfZEnba4yKjMYwjL16rg/lsGZ4O4/sB0ku59DdnTyYu9wrZWXhj11X2knzducKfrH+Z6zrWcO8yqOoClZz5eSrMJwyFjd08Xp9F4sbuulOFRrMlJoox40tZ+6IGDPrYkQDFrZ16I1ObU21sK5nLSMjo0g7aaaVTd/tei2pZkr9ZQNvTsdzaEu37vKl1fM8tiUaGBEZRVuqla/8+XK+MuWv+ezYS3A9l3U9a4nnerFNH/FcnM5MO/PrTsUyTJ5pfIqlHW9QFajmy1OuZkXHMoJWiJgvxl1rb6c328PE0sms7V5Nc2oHMV+M04efxfZkIyErzKrud8i5OUaER+Lh0Znp4Jjq43HcPDkvx45kEyu73h6otSZYi8/04eHRlNxOdbCGrJulJ9u9V89bRaCSzkwHU0uns7Zn9W7XMTDw8BgRHskJtSeR9/Lk3Bw5N8vi1lfpynZR7q9gVsVs3mxfQjKfpCJQiWVYtKVbARgWHs6I8EjSTpr6vi1YpkVloIr6+BZMDPJefmB/J9TOpzZUx8P1D+xSx9TS6VQHaygLlBPP9dKZ6aQn282RVcewPbGNTX0bqQnVsqZ7NTFfCacMO4NXWl6iPd3G8PAILMMiaIUYGRnF+p61JPNJLNOiPd3GJeMW8nbnCtb1rCViR7l43OfpSLezpns1tmkxtWwG46Lj2dS3kWe3/5Grp36Vxa2vsbp7Fb25HoJWiKpAFZdNvILpZTPoy/XxRttiInaEs0cu6A/HTWScDKMiY9iWaGBRy8tMLZ3O2JJx3Lf5N4wvmcjG3vV0Z7v41pzraEm1sLj1VTw8HthyL4l8gt+c8iCO59CRaWdrvIGRkVFMKZ3K5r7N/MPrf8Ow0DC+MOFyZpbPYnR0LDk3h4lByknzSMMDRO0STqo7hUue/zQAj535R97qXEHICjGv6iiaUztI5OK4nkvSSdKWauXYmuN5vulZzhpxDh4efjPAA1vuJWyHuXDM51jS9jr//MY3CFpBvn/MD5lQMpGgFeQzz55DX66P+059hMpAJVk3y23v3MKx1Z+iIlDJ7Io5WKZNT7abikDlh7bRrFO49tY0TBzPYXnHUrYltrKo5WXe7lzBtbP+mbc6ljG/7lTm151MPBfHMizi+ThdmU4ml04BYHuikW2JBuK5OCs6l/H1md/ExGRz3yZ+tOo/mVQ6hXJ/OQvHf5GmZBNPNT7O250r+FTtiVw24YqBelL5FC2pZha1vMwvN/4vw8MjGRMdy7iS8TzX9CcaE1v53tH/zYjISJa1v8mIyEhCVogNvesZGRnFmOg4yv3lPL/jT8wsn0081wdAVbCGi549F4Cfz/81zzf9iZebXyDqK+HqqX/DqMgYXtzxLBNik5hQMpHWVCvNqR3MrphLyAoOnMzY+aXB9Vwcz8Fn+vjhqv/k1ZY/U+ovZW7FPGaWz6YuPIzJpVN5fOvv6c32cPG4hfgtP1kny+utizi6+lgsw8Y2bUzDJOtk+fn6u+nN9lAVrGZEZCRb+jZz/qgLeX7Hnziu+lO83fUW/7fhZ1wy7gv8xaSvsD3RiIfHkrbXqApUc0zN8fzTkq9TH9/M3Sf+gtpgHYvbXiVohZhbOY/WVAvPN/0JDINkPkGZv4yx0fHUhuqYXDeOlU1rqQsNJ2gFeatzOeNKJhCygjSnmnli2+95YMt9AJT7K/h/067hzBHnsLF3PQ9t+R1XTr6Ktd2raUu3cu6o8wnbEbb0beLPzS8RtiN4nsuJdSfzdOMTlPhiROwILi4n151KyA7TkW7nxuX/SkO8gSsmfZlLxi2kJ9tDS6qZsdGxLO9YRsbNUBGo5LWWVzi6+lj+sPURjq85kTJ/OV3ZTtrTbZxQO5/GRCO/b3iIN9oXc0LtSXx7znWE7DBdmU66s92k8kke3/Z7jqk+jk/VnIjfCpB38yzvWErICpHzcswom8WyjjdpT7cxJjqWWRVzcDwHz/N4s30JFYFKbl/938yvO4VLxi0EYEvfJp7Y9hjH15zIy80vckTlkdiGhWXYdGU7ebbpj0TsKOeMPI+jq47FZ/pZ1vEmT257jLST4cZ5N2MaFol8gjtW/4ANvev41pzrmRCbCBSCkm3Y5NwcyzreoCHewOK2V/nypKuJ+kr4w9ZHmFE+i1kVc6kOVvPglvt5pOEByv0VfH78F/np2jvx8Lh+3k1E7RL+uP1JhodHMLN8NiW+EgJWkM29GxkWHsHWRAOTY1N4tfUVwGN0pPAefGLbY/zXyu8BEPPFSDlpcm6W78y7hapgFZWBKl5vfZWZ5bNpTbcQtsPMKJ+FHXbp683wauufmRybyobedWScDGePPA/Hc2hJNXP90m9xyfgv8HrrIioDVRxVdQxHVB5FxBdhXfcaVnW/Q1WwhmXtb9Cb66UuVMeCURfyTtdbHFV1DNcv+zZb+jZjGzZ3nvAzakN1nP30yZT7K/jGrG/S0FfP8o6lLO14g0vHXcZjWx8h7aS4fOKVHFN9HBWBSmpDdfx03U+oDdZx4ZjPYhgGLalmInZk4PP1zfYlxHN9vNz8IqZhsnD8F/ncuM+zpnsVLzQ9S0OinuNrTmRJ22tcMOozBO0QM8tnAXDbO7dy5vBzmFo2jb98+QvkXYerpnyVJe2vU+orZXh4BJNLp/LTdT/hvFHnc9GYS0jk4/zb0n/mrc7lA8fJ8SUTOHfk+ViGTdpJUR6oYF3PWkZFRpNx0oyIjOKR+geYX3cKZ488l//b8L+81vIKd57wcyJ2hG2JBpqS23m99VVGRUbz2NZH2JbYyjHVx7Gqq/A96dyR5zMhNpGT6k5jRcdSjqs5gZVdb7O+Zy0nDzuNZR1v8lzTM5xcdxp+08+OVBOvty7ib6f9A1PLpvNPb3ydtd2ruWb61zl/9IVs6FnHlr7NvN72KgEzwLWz/pmWVDM/X383fdleticbcT2XGeUzaU23sqrrHb4z7xZaUs38ZtP/cfWUv2Fa2Qz+e+X3KfWXccWkK2lMbGN0ZCxjS8ZRUR4dcvmjurpkr9ZTWOt3IMLaTql8ip+vv5uXdjxPR6YdA4MyfxlXTPoylYEq1vWsZUroNDbsCPB6fRdvt20B3w7yyQngBqmJ+hlRFiAcyDGsIkm5v4ZYrBvsTuoiFZxYdxzJXJaSQCGRr+tZQ3e2m7mV81jdtZIjKo8kkU/weusiTh52Gp7nDjTsezf9I9pPIAAAIABJREFUiopgJbXBOs4YcTZHVh1Nxsngei6h/rPRrakWlra/QVWwiqgvxqstf+aNtsUcXX0sC8d/iScb/8Bpw87gjfbFTCmdxpvtS/jp2jt3+cJ/1wn3sLlvI37TT8pJURcaxu8bHuaVlpcKPSdmgPl1J5N1s7y44zlmls9mauk0OjOdrOlexY5UE0dUHknGSbO6exUAM8pn0dBXTzzf94HnPGiFCFkhurKd2Ia9Sy3vrhPE8RyCVpBRkdEcUXkkv9n0SwwMxpdMpCfXzazy2UTtEjb1baA7203ULmFHqjC7Z1//l7prpv8Dm/s2sbZ7NZNiU2hKbiflpKgKVvN66yLGRMeyYNSFLG57lbXdqxlXMoFvHv2PPLnxaSJ2lJ5sN3/c/iQXjL6IP21/mpGRUbzduYLxJROZVTEHy7A4onIer7UsYkXnMoaFR7Ck7TUAfKYPv+nHb/qxTJt0Pk3AClAeKKcpuZ2QFabMX45tWoyKjGF8yQTq41toTbXQle0i62SYEJtEd7aLZD7JsdXHk3ZSPNLwIDXBWqpDNWyLb6U314OBQcgOkczv+r7wmX5qg7WUBypwPIfV3SsZHRnDhNhEmpJN+EwfjuewoWcdw8LDOXXYGTyx7TE6Mu2U+ssI22FivhjVwVqWtL1G1i2EgZpgLeeMXMCjDQ/Rm+sZ2F/ICmMYfKCOgBlgZsVsaoK1WIbF8o6lbE827sM79cAwMAhaIVLOrvXVBGvpyXbjeM5u2yO82/sIML5kIpv7Nn5gnZivlN5cDxE7QjKfxG/6ybgZAOZUHMHa7tUDfwOYhkVFoIL2dFv//WM4nkMin9hluyYmLi4AU0qn0ZPtxjAMhodGEPOXsj3RSHWomiVti8m5WYJWCL/pozfXCxS+kHdlO3fZZmWgis5MBwAehY+W80ddSIkvxkP19w+81u8+ttjA9nY6uupYNvSuo/s9JzzmVsyjKbmdmL+U+r7NA8/nhJJJbOrbsNvn9sP4TB/DwyNpiG/5wPPwUQJmYJfn+f2ml80g6ivh7c63qA3Vkeo/GTGn4giebnxiYL2d+/OZfj49+iIeqr8fKDx3syvmsLT9TXpzPcR8MeL5BOX+cqaXzWRZx5sk8vG9fpxnjziP55qe2aXtjY6MYWuiASi0zzJ/Oet71/Y/L35y7odPirXzpFHYDlMXGsbmvk0DJ912tuH3H3vHRcfTm+ulI7PrT9qU+yvwmT5a0y273ceHidgRxpVMYGXX24TtMDk3/5E17w0Tk5AdpiJQ0T8qYNf9jy+ZyKzy2Sxue43m1I6B5UErRNpJDfw9MTaJpuT2DxynoPDalgfK2dj70W11ZHgUXdlOEvnEbp+LwudckK5s18CyqF3C8bUn0JjYxpruVZT7y+nL9X3oMaewnSAn1Z3KM9ufYlrZDLozXexINX1kbRE7Qk2wli3xzQPLyvxlu7xP3//6l/rL9urEZdQu2e3n+ntZhoXjOR9YbhoWoyKj2Bpv+Mi2s9PE2GQ29q7f43pQaBvVoRpaUs0DyyJ2ZOBYOiI8Ep/p6z/pWRj9894aT6idT87Ns6TttT0+xspA1UCg8Zt+yvzltKZbGBkeRWNy224ft+s5TIxNpjGxdeA9uFN1sGbgZO2HidhREv09WzvvPzY6DtdzB44T+2tn+60MVO3y/jf7p8qwTXuXz4Mx0XEDx+SdqoLVA59je+vDjmOfHn0RN5x4/ZDLHwpr++hAhrX32pFs4unGJ1jS9jrretYMLDcxKfHHKPHFaEu1knHTBI0yquzJ9OY66fU2g7H7LxBOejimvx3TC2Bg4FqFLzu2FyVvxAkYUQxM0l7vB+5bExxOa7oJn+nH81zGxyayvqfwYV3uryDlpHb5ANppSulU1vWvtzsn1p7MtLLp3L/5Nx/48vV+x9ecSNAK8MKO5z5wW2Wgihnls2hO7mB971rCdpj5tafwx+1PMqFkEpXBKsaXTGBMdCxZN0tdqI6KQCU/XXcXiXycKyddxdzKeSzvWMr9m3/D58Z+Hg8X1/OYXjYDF48SX8nAEIFNvRuoDFRRFij/yJqhMFwi62Y/dIiU53n9vVzvDqvJu3kMw6CyvGSX9pV1MrsMC/yoLnzP82hNt1AbqtvtbQdiCE9Tcjvl/gpCdqgQLtw8XZlOor4oASuIZVg0xOvxmT5GRkbtct+cm9vjkIu8myftpHc7jLAt1UpTajvTSmfgt/yk8kn6cn00JrbRlGzk/NGfwfEcOtMdlPhjdGY6eKPtdT5VM5/q0LtD/OK5Pt5sX0LaSRO0ghxVdSzNqSZea12E3wxQG6ojaAXY0rcZz/P49JjPsqrrHdrSLf0f4BuYVjaDvlwvq7reIZGPc+m4ywhYAdrSrXRlu3hxx/PUBmuJ+kqYV3XUwBekjb3rOW/kp0k6Cd5sW0I834ffDBDzxbBN38CHR02olnc636I318vnxl46MJx2dddK1vasYWu8gRGRkf29Mnka4vXk3BzH15yIz/RhGzZ+y8+x1cezsXc9v294hNkVc/jGrH+izdtOe083a7vXsKl3A6OiY5hRPotfbvg5w8LDeb31VYaFhjO7Yi7jYxPZ3LuRp7c/yfSyGdiGTVmgHNuwWN+zjrSTZkRkJC2pZsaXTGRS6WRaUs3k3Tzz605mbHQ8IyIj2Z5o5H/X/w8eHht71lMRrCRkhejL9bG6eyUn153GS83PY/afgDix9iReaXmZrJPFMAxGhkcxuXQqM8pn8vuGh+nKdvFayyuMiIzk0vGX4XkujzY8TNAKMiw8nKbkdiaXTmVm2SyGhYczrWwGr7S8jOPl6Ui388ftT/KZMRcTskKs711HZ6YDz/NY17OGU4edwfDICNZ1r2F5x1Jq+t9PETtC1s3iM31UB2s4b9QFPL7196zpXsW5o84n5+R4svExJsemcsHoz9CQqGd5+1Ji/lKOqjqaDb3raUk284dtjzImOo6ppdNoSTXTmm6hKbmdgBngnFHnE7WjjImOZXLpFNZ2r+Hh+gdY37uWkZHRXDXlq/x64y/Y1LeRE2vnUxWsoSvTwfDwCN7pepu3O1dgYnLa8DP58uSreatzOfdv/g3VwRoaE9v42oxvsKjlZQJWkAWjLuDaxV+jO9tN0ApxfM0JfHbsJbyw4zkerv8dF47+LGeOOIcfrLqNjb3r+cL4y/uHhmeI+Us5ffhZ2IZNyknRkWlnR7IJA4NOt5WIV8r63rVsTzQyqXRK4Yup51EVrObV1lf459n/xtL2N5hYOpn1PWtZ1PIy63rW8OnRn8Vn+phTcQSWYfFow0MYhsGs8jmcNvzMgZMaj9Y/SGmgjLNHnIeHR3NyB/+98vvMqTyCikAlpw47nbHRcdz81nfozfYyMjKKUdHRNCd3ML18FjFfjMe2PkxtqA7X8zh75Ln8euMvOKrqGDJOhoAVpD6+mWOqjydsR5gcm1KYzbnhIV5qfpHPjPkcI8Ijebbpj1wz/eu0ppq5c82PCj3y0dGcN/ICfKYP0zBZ1PJnjqv5FLPK5/Dnlpd4vulPTIhNpL5vS/+x0ubmo25jUcvLvNT8Ir3Zbo6sOroQXtPt3Hr0f7GpdyPlgXIczyFshxkbHU/GzfBO5woWtfyZpxqfYHzJBL4+85u81bGMVd3v0JnppMxfPrDvn6+/mzXdqyj1l3Fs9XFsS2zj9dZFfHXa3zG/7mQWt77G7at/wMTYJM4ffSEBK8j/rL2DpuR2Tht2Jv84+9v0ZLv57aZfcurwM6gKVLO47VVaUs18duylbE80sqF3PS/ueJbGxDamlk5natl0QnaIF3c8z/iSCcyqmMP6nnU0xLfQk+1hauk0mlM7+O6R32NZx5ts7F3Pmq5VjI9NZHHrq3xp4l/ycP0DnDrsdKqC1bzWuohxFWPwciZjouPY3LeREjuG3/LTkWnHwqIz28H82lPY1LcRn+kbOMG8Ld7Apt6NjC0Zz1FVx+B4DsPDI6iPb6Yj3cH25DaS+SSvtLzMp0dfxJWTr6K+bwt3rPkBWSdL2A5TGayixBejKbGdDb3ruGD0Z8i6WcZEx3Fk1VEsbn2NqK+E7YltrOhcXrg8wc3zwJb7qA5WM6VsGnWhYaSd1EBPdEemnTOGnw3AXWtvpyG+hVOGnU5Ptodjqo+jN9vD5NKprO9Zy45UE883/Ymsm+WEmvnUx7fQmeng6OpjuXD0Z7l9zQ/JOGlmls9mXMl4NvZuYE7FEbzc/AIvN7/IpNhkLhp7MUvaXifmi3HuyPPBMHi0/kEmlk5mUmwybek22tNtPNf0DNPLZuB4DmeNOJcNvev5xfqfMSIyklGR0Tyz/Wli/hinDiu0hbyXZ2n7EqaVzWBa2Qze6lxOiS9GTbCGsSXjeKj+dzQnd9Cc2kFrqoWvTPl/TIpN5vcND1HqL+MLEy5necdSOjMdNMTrOXvEeTzZ+Afybp4TauczvWwmv9p4Dxt61zGjfBajI2OYXTGXh+t/x0vNL3J8zac4ZdjpdGe6qQsPoy/Xi23YbOzdQNpJ8VbnCo6oPJLTh5/JG+2LeaT+Qb444QrK/OXUx7cwKTaZhkQ946LjOXrMEUMufyis7aPBCms7uZ7LO11v4XoulYEqnm/6Ez3Zbnr7r3M5uvpYHt/6e9rTbZQGyvCbfjrS7fhMP5Ni06iz59KTzrK8+wWasqvwGxFMpxzTLcFxIWVuJW92gZHF8yyc1CgMM41hpcn3zsbNVOPmS3ASkzGsJJ5nER79v4BBKD8NA4tAsAufZeE4JlXOKQQCaSxfD062Ais3lnTkKRpyr1Djm0bAiFFiVZC0NjI8MJka9yx29GaZVhOlyXuJDV2NzCg9gtpoCWk3zp/bHuOEqgVMq5hEMhljeGmQt3v+jEWAkeEJ9GZ7mVk1Cb9pURqyMQyD9nQbETtCyA6TyCWI+CKD9voMtsFuX3J4SjtperM91IRq97juntpYKp/8wPWAhS+wB34CGcfN05Zuoy48jM5MJxE7stf7SeQSBK3AXl8jOVTEc31Efbt+8Lal2whZwQ8sh8KJlp5sNzF/aWGIqZunO9tNZbDqA+sl88mBkQ/vv07kw07YZJwMtmnvcr3L2u7VTIxNxjZtPM+jN9e719ccHu7HsKyTxW/5D9j2HM8ZeO4dz8Fx8wMn6Pb2JFtXppMSXwx7H98Lrufu0k7e/7fj5sm6WUL9120NBYdi+zpY16HKgTEU25jC2j4aii/i/ujLpunLxAlbpXSnc6SyeTpTeXJ5Fw9o6cvgt01a+zKFCR7yLs29GSzToC2eIZ5x8NsmOcclkXXoTeeoCPvxWQaN3WnKQz7a4pn+azI8dv4qgQGUhXx09V+LZ8BeDEjYPZ9l4LdMbNPAb5v4LBNf//9DPotUzsH1PHymScA2CfpMgrZF0GeSybsksw51sQC+/m3YponPMrBN491l1rv/L9z27jp2//5sy8Bnmrv8a5sGmbzLpvYENdEAVVE/iaxDxG9RFvJhGgaZvEM0YA88N7Zp4Av5cTM5PM/DcT0s09jlIJ93PSzjwycFENmTw+UYJkOT2pcMJrUvGWxDsY3tbVg7tE5dyh6V+IOU+AvXEZSF939Gp4+Sdz1MAxIZh7ZEBsf1GFUWIuizqO9I0pXKMa02Sms8S3sig+dBNGDTkcjSncpREw3Q0pch47iEfRa2aWAYsKM3gwF0JnPkXZds3iXneORcl2zeKwTInENp0MYyDfJuIWwmsw6dyRyZfGHYaMhnUd+ZJO965N3C/XJO4f/FFPFbpPNuIawZYFsmEb+F43qkcg6mYRCwC2c/fda7IdQwwPW8gQDbkcwRsAuBMuu4VEcDbO9OkXE8ykI2saCP9niGYbEghgGZvIttGnSlcgRsi+B7Au6O3jQ+y6QkYBMNWLhe4fWtCPtoi2eJBe2B0J3KOnQkstiWQVXET18m31+TSXnYV3hNnMJr4LdNaqKB/n2axDN5In4LwzBIZBySuXzhWs6QTdhvk8jmSedcqiJ+LHPnEFKPvOsS8lm09mWJBizKwz7KQz4wDNI5h1TOGXjd/ZZJRX8dBYUgvqUjybDSIGGfSc7xMA2DdN7BcT1s0yDoswrtzHHxWSbdqSyVET8lAZtkziGRcSgN2WTzHrFg4ZBZWxIg3b/fRDaPzzIxgIqwDwODvOvietCWyBLxW0T9FmG/jYdHwC60eQDH9XA9r/898O7jTmUdMo5LxF84M9/Sl2FMeWivw/zONp/Nu4N2HBAREZHBp561fkMxccuBtbNXqxDgCkFgZxjMOx4518Pp//u9t+ddj/z7At/kmgjbutOkcw5hn0VnKkcikyfvegR9FuncuxcZp/Mu5dEAjR0JQr5CD+DOINqbzmNb74a0nOPhed5AEE3nHDwPDKNwW9ZxKQ/5yPWHUNs06EgUwkVpyEdPKkdPKkdJsNADapsmftsgm3epCPvJOi6ZvEsq55DMOtSUBPCAeDpPPJvHNAwsw2B7T4rqaICc42L296Lalklp0MZvmbQnsoT7g6bjerTGMxgUej89zyOTd0nnXSzTwHE9ArY5EKqCtknYXwiGvekcrgeWUQh4qdzur9P0WwZZ5/D5cflAf+/1e88f7OxR3hnody5zvUKoq476MWCXkxCFtulhmgbRgE1F2EfOcWnsTrMz1g0rDZJzXGLBQpDvTefwmSbJnDOwz0S20F5DPouw3yLit/A86E7lMA0D24TSkI903iXvuPhtk85EjpDfwvM8qiJ+Av0/Q/JuVC6028L/C20j77qEfYXQ2pvOE7RNKiN+ulM58v3hedde7kKvtuN5tPRlqAj7KAv58DzIOi4NnSkmVkdw3EKbC/stSgI2hgEdiSw10QCdqRzdqRzjKsKk+3/vsrC+gweUBGxKQz46k1n8lklfOk8i61Ae9lER9tGZzFEVKfSg+/p75P1WoUafaZL3CseHna+L03+yoyuVwzJ2rt/fY99/n2T/+882DTwgmc1TEfZjWwauC07/scr1CseT0qBNPFMYUWD2P6klQXvgGFAe8hHPOuBBbyZPadCmO5Uj7LcoD/vpSeXIOS6VET/NvRliQXvgWJBzPEoCFpX9j7E9nsU0DWIBm5KgTWcyS3nYT1VFhO7uJOmcQzzrDJxo81nvnmjYeZIg6DPpTeeJ+i1yrjfQbsN+i3TOJeQrTMaQybv4LWO/RhTkHfcDIxR2clyPRDZPLLjvJyp2jnJwPAZOqsjg03cwGWxDsY1pGOQ+Goovohw+Dvf29f6x+57n0ZPOEwvaZPIuQdvEec+w0J1cr9D7szOsJvvDKYBpGJj9PYOxoE3O8ehO5ehK5XA9j7DPIuSzsMzCb6w4/eFiZ1egS2Hb1dEAbfFCD69tFfYdtK3+3tlCz6xlvhtaaksCdCSy9GYKXzZDPouuVI6Qz6IvnSfnuAM9ZoYBAdsinsnjswy6kjk8rxDG8q7HsFiQdM4hkc0TzzgYBqRzhbC884u/aRR6SHOOS9bxCNqFnkq/ZbK9J43PMigL+VjfGsfqDzM7g4zdPzzXdT3yhkFjRwLLNBhbER54rus7k/itwpfnnnSOaMAm73rEAoUv7Fmn0HtpGUahJzHrkMo6OJ5H5f/f3r2GWFX9fQD/rr325VxnjqPm/28+9m8yH4oIsZACNSHoQvXG7EpTEISWYnc0wzIaJKs3pRD1IgI1KCrqVXShYpLSF5I9TEQ+YY/geMmZcS7nnNln39bzYu2952hjozjTnKPfDwSdOfuM68z+nX3277d+a++cjUgphErhz+EaHFOi4EjUgghFR+9baQj0Vjz4YZTuO4XR+30l3EAn/iNxIUMnGPrvUnAkTEMnc2nh5JSZ8KJjolwLTmqvzlqnT/DrnUtbdrM70/c+VgGh/neYUsAQIk1IE9IQiD9WkIbAiD9apKlnCKSvz5gGWrMWjg3XYAi9bx3TSG9pI4RIk/0kOU2OB8WMiaoXYtANUHR0wpq39ex41Q/TQsOJER+tGRMtGRNDboCsJZG1JYbcAIbQM/G21J+fE1UfVS/Ev1sdHBpwkTH15+XiUgY5S8e7EIAXqrQzQgihk0UAhiHS92cao0WXWhAiZ5vwgiguhBhp54N+jf48HBmq4b9KmbSg1Zqx4EcRKrUQbhCi6OjbwxQdPbPv+rrVvuLpz2ukVLpcwJKjrfyWNBAphUMDbtol0VuuQQFoy9kYibsTMqZES8ZE1pIIldLHNgj0VWpw4+O3EALTcpZO5oX+POdtiUE3wPS8jX+3ODjQW4UfKVzalsXASAAv1Md2L4gwLWfBjN9zqBRknKxbUqBcC+ErwDaAQwMuZrdmMC1rxUXKCMfKHgq2RMHRXTVDbgApgLxj6mNf/X/x8WzQ9XFxaxb9VQ+mIZC1JBSAo0MuZrVkYBoCVS9Eb8VDMS5MtMTHRlvqY5Hev/p7IvlbHhuuYXDEx7yZBfRXPFhSxAXQCMWMXgtacEwcL3uIlELW0sdMx5SIIgUhgN97K/BDhctm5DAz76SFWTcI0ZazkbGM9PV5Wx9nk6UmyXcYoAtSjqm/t6peCMMQyFsSQVzc0/vbw4yCjSBS+N8/y/hPWw59VQ+uH2FmwUbelqj6EYZdH9PzNiypO2GU0gXU6XkbliHSAlJ9UcoQusBX8cK0I+fYcA2zig7CSKHshSg6JoIwQhgXmmxpYNDVhSxpiPg7Lf7/+LPeV7fPcraEJQ24fohI6WNR2QsQRioufktUagGGayHmlDJxMU+fD6j4u6vqhbjyX0Vc/9+zGu48jMnaWTrfT6ZpajG+aLI1S4ypeK1rkmR7oUqT9VO3S04MgOSkIIAX6JuiG0K3V/dXPGQsCVvqGathV89wt8SzS205C0XHxP/1j8AxDT0bHJ+QSkNguBbgRNVHKWshjF9XcEwcHa5hyNU/Pz7soZS1dHt2PMMdxK2zMk2cR084/ix7mJHXF6uo3zaZEbelgWJGnxhCATlboq+iT86S35EkACPxiVQmTqiFAFQ8g+ZIAxU/RNkNkHf0zGYpq2cDS1kTfRUftSBEKatn7f7oq2JOawYRAEfq2U5b6iSpZ9BFwTExt5RFqPTM58CIn87Ym5ZEdcSHNASm5+10ZrfihXHXgj6xvqjopGud3SCEaeiTdQW9r4uOiRNVH/1VDxe3ZhApheGaThqSE3Sl/yyI4tOTKD7x8kOFEyM+LEOgmNHJSmvGjIsfBnKWxMCIjwjArIKN/qqeVZ2et9OW+aRIMdplEaUnyIcHXcws6PHPbs3i8KCLWhDCMQ1ECmmB5aSTwUjfpkLPhOpZPTcIEYQq3cemIdJ/f6Dq4V8tGf3+IgXbNDAta+F/Dg/hP236NiWDbgDH1G3ytjQwVAtgCoGhmi4WZUyJWhAi75g6joUY7QhJ40zFybdeptBb8WDFreIDI7qjIVlSMOgGiOJujiSJCZXC9Lytk4FaADfQSxNmFGx4gYqTXD3r6vohDg2MFpbKtQCtWQuW1PveNg0MjvjpZ8+Ib2KcFLXytoli1sJg1cO0nIWjQzV4cfHHELrtPElI/PgzGsXJQLKkIFlnbgidzLXlLL3OPmdBCoGKp48Lpax+/yJedjCrYKPshRhyAwy7AWS8vCBJ2JKkxY2XKlhSF9P6KnqsgyN6X03L6fctDYFhV8+U6wQ/QjmO72TJx4y8jWk5Gwd6Kxh0A9hSt+M7poH+iodQAQVHpgmtbepEsVw7+dYFWWv075ezJYJ4ttwQIr1+QMGR6etaMyaGa7rI0ZazcXTYhRdEyFg6Ee6veghClR5L/FClBYS/kxQswkjBkgL+OF0whsCYRaEzfX4sYxWI6t21YDY233l1w31Hcs0aERE1HCFGZ2L0CdPYrWZCiPjkePRnedtE/pQL9s0ojF5l0jYNlLKjrW/T6zaeN3Psq8nOLDjAGPcEn+eMfj22T2/eK9FOlGYpBlBzatb4ipSKZ4H/vmU2mYk6tQMlKVwlvHgW15J/LWAFkV4moZRulc7WHxxP4fohhBAnLSGwpUhn2ZPlDTrBMtL3kjyXSLpVTDlajKqfZdfJni6CJeu7k7XqWUt3nZiGASF0UucGEVrjtd+h0gWLdNYuVFBQaI2P4a4foeoF8EKFrGXEST6QsfSF59xAd4Fk4w6YI0MuKjWdVBsGYEAnx1lLYmZh4q70OhWYrBERERERnSVjnCQtUZ+QJeoLVwl7jC6DhF5CcGb/XqYukasviNW/2hACRt0Axnov9cWvscZjxhfBMqRAKafH3pYbTYxOXTdaPy5TQE+jnUbO1m2Qp6OLd6NpzMWt2dNu2+xOHxVEREREREQ0ZZisERERERERNSAma0RERERERA2IyRoREREREVEDGjdZi6IIL7zwAu655x50dHTg4MGDJz2/c+dO3HnnnVixYgW+/fbbSRsoERERERHRhWTcq0F+/fXX8DwPH3zwAfbt24dXXnkFb731FgCgv78f77//Pj799FPUajXcdtttWLZs2biXMCUiIiIiIqK/N+7M2t69e7FkyRIAwIIFC9Dd3Z0+19bWhs8++wyWZaG3txctLS1M1IiIiIiIiCbAuDNr5XIZhUIhfSylRBAEME39UtM0sWPHDmzduhUdHR3j/oNSCpRKuXMY8uSQ0mjIcdH5gfFFk40xRpOJ8UWTifFFk62ZY2zcZK1QKKBSqaSPoyhKE7XEAw88gLvvvhuPPPIIdu/ejeuuu+60vy8MVUPepb5UyjXkuOj8wPiiycYYo8nE+KLJxPiiydaIMTZzZvGMthu3DXLhwoXo6uoCAOzbtw/z589Pnztw4ADWrFkDpRQsy4Jt2zAMXmCSiIiIiIjoXAmllPq7DaIowqZNm7B//34opbB582Z0dXVh7ty5uPHGG7Ft2zZ0dXVBCIElS5ZgzZo1/9TYiYiIiIiIzlvjJmtERERERET0z2PPIhERERERUQNiskZERERERNSAmKwRERERERE1ICZrREREREREDYjJGhERERERUQMa96bY57vk1gReMh9rAAAEoElEQVS//fYbbNtGZ2cnLrnkkqkeFjUZ3/exYcMG9PT0wPM8PProo5g3bx7Wr18PIQQuv/xyvPjiizAMA9u2bcN3330H0zSxYcMGXH311VM9fGoifX19WL58Od59912YpskYownz9ttv45tvvoHv+7jvvvuwaNEixhdNGN/3sX79evT09MAwDLz88ss8htGE+Pnnn/H6669j+/btOHjw4BnH1Om2bTjqAvfFF1+odevWKaWU+umnn9SqVaumeETUjD766CPV2dmplFKqv79f3XDDDWrlypVq9+7dSimlNm7cqL788kvV3d2tOjo6VBRFqqenRy1fvnwqh01NxvM89dhjj6mbbrpJ/f7774wxmjC7d+9WK1euVGEYqnK5rN58803GF02or776Sq1du1YppdSuXbvUmjVrGGN0zt555x11++23q7vuuksppc4qpsbathE1YPr4z9q7dy+WLFkCAFiwYAG6u7uneETUjG655RY8/vjj6WMpJX755RcsWrQIALB06VL88MMP2Lt3LxYvXgwhBGbPno0wDNHf3z9Vw6Yms2XLFtx777246KKLAIAxRhNm165dmD9/PlavXo1Vq1Zh2bJljC+aUJdeeinCMEQURSiXyzBNkzFG52zu3LnYunVr+vhsYmqsbRvRBZ+slctlFAqF9LGUEkEQTOGIqBnl83kUCgWUy2WsXbsWTzzxBJRSEEKkzw8PD/8l3pKfE43nk08+QVtbW1pcAsAYowlz4sQJdHd344033sBLL72EZ555hvFFEyqXy6Gnpwe33norNm7ciI6ODsYYnbObb74Zpjm6qutsYmqsbRvRBb9mrVAooFKppI+jKDpppxOdqSNHjmD16tW4//77cccdd+C1115Ln6tUKmhpaflLvFUqFRSLxakYLjWZjz/+GEII/Pjjj/j111+xbt26k6rNjDE6F6VSCe3t7bBtG+3t7XAcB0ePHk2fZ3zRuXrvvfewePFiPP300zhy5Ageeugh+L6fPs8Yo4lQv+ZsvJgaa9tGdMHPrC1cuBBdXV0AgH379mH+/PlTPCJqRr29vXj44Yfx7LPPYsWKFQCAK6+8Env27AEAdHV14dprr8XChQuxa9cuRFGEw4cPI4oitLW1TeXQqUns3LkTO3bswPbt23HFFVdgy5YtWLp0KWOMJsQ111yD77//HkopHDt2DCMjI7j++usZXzRhWlpa0qSrtbUVQRDwe5Im3NnE1FjbNiKhlFJTPYiplFwNcv/+/VBKYfPmzbjsssumeljUZDo7O/H555+jvb09/dnzzz+Pzs5O+L6P9vZ2dHZ2QkqJrVu3oqurC1EU4bnnnmvYgwM1ro6ODmzatAmGYWDjxo2MMZoQr776Kvbs2QOlFJ588knMmTOH8UUTplKpYMOGDTh+/Dh838eDDz6Iq666ijFG5+zQoUN46qmn8OGHH+KPP/4445g63baN5oJP1oiIiIiIiBrRBd8GSURERERE1IiYrBERERERETUgJmtEREREREQNiMkaERERERFRA2KyRkRERERE1ICYrBERERERETUgJmtEREREREQNiMkaERERERFRA/p/9qqejL9da3IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_4.plot(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary:\n",
    "\n",
    "# Dropout and EarlyStopping\n",
    "# Epochs = 167\n",
    "# Loss = 0.40\n",
    "# Val_loss = 0.35\n",
    "\n",
    "# EarlyStopping\n",
    "# Epochs = 218\n",
    "# Loss = 0.32\n",
    "# Val_loss = 0.33\n",
    "\n",
    "# Dropout\n",
    "# Epochs = 1000\n",
    "# Loss = 0.38\n",
    "# Val_loss = 0.38\n",
    "\n",
    "# Nor Dropout nor EarlyStopping\n",
    "# Epochs = 1000\n",
    "# Loss = 0.32\n",
    "# Val_loss = 0.34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1577   18]\n",
      " [ 265  140]]\n",
      "Accuracy: 0.8585\n",
      "Precision: 0.8860759493670886\n",
      "Recall: 0.345679012345679\n",
      "F1-Score: 0.4973357015985789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      1595\n",
      "           1       0.89      0.35      0.50       405\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.87      0.67      0.71      2000\n",
      "weighted avg       0.86      0.86      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision:', metrics.precision_score(y_test, y_pred))\n",
    "print('Recall:', metrics.recall_score(y_test, y_pred))\n",
    "print('F1-Score:', metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred)) # Better for multiclass problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1530   65]\n",
      " [ 197  208]]\n",
      "Accuracy: 0.869\n",
      "Precision: 0.7619047619047619\n",
      "Recall: 0.5135802469135803\n",
      "F1-Score: 0.6135693215339233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      1595\n",
      "           1       0.76      0.51      0.61       405\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.82      0.74      0.77      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(y_test, y_pred_rf))\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_pred_rf))\n",
    "print('Precision:', metrics.precision_score(y_test, y_pred_rf))\n",
    "print('Recall:', metrics.recall_score(y_test, y_pred_rf))\n",
    "print('F1-Score:', metrics.f1_score(y_test, y_pred_rf))\n",
    "print(metrics.classification_report(y_test, y_pred_rf)) # Better for multiclass problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
